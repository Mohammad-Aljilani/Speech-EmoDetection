{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Enterface.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vwz_Ii_JC0j",
        "colab_type": "code",
        "outputId": "9fe9379e-4293-4589-94af-878ffca4eae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root_path = 'drive/My Drive/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fr1ygTcJNx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/project2_database.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIrOP1DrKdCy",
        "colab_type": "code",
        "outputId": "097256af-8e89-485a-db32-2a76c8631b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!pip install moviepy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from moviepy) (1.16.4)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.28.1)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio<3.0,>=2.1.2->moviepy) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbPNQj_wNyGP",
        "colab_type": "code",
        "outputId": "739dfcae-91a9-4830-de8a-d9fd0c337362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!pip install soundfile"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/68/64/1191352221e2ec90db7492b4bf0c04fd9d2508de67b3f39cbf093cd6bd86/SoundFile-0.10.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.12.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.19)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn9UKnP7PAcl",
        "colab_type": "code",
        "outputId": "85d9672e-9b8a-4940-da73-21d36bca75b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install ffmpeg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ffmpeg\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/cc/3b7408b8ecf7c1d20ad480c3eaed7619857bf1054b690226e906fdf14258/ffmpeg-1.4.tar.gz\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/68/c3/a05a35f647ba871e5572b9bbfc0b95fd1c6637a2219f959e7a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFc03auWi_1L",
        "colab_type": "code",
        "outputId": "b6142129-0f6a-44da-9336-2a3f0f454f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.23.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg23oRQ46LiS",
        "colab_type": "code",
        "outputId": "6980d4da-4533-4638-942b-32240b80737f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "!pip install Signal_Analysis"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Signal_Analysis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/77/f395f3d5a70394de295889b70551497852787e19f4cf5940fa9709151497/Signal_Analysis-0.1.26.tar.gz (378kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from Signal_Analysis) (1.16.4)\n",
            "Collecting peakutils (from Signal_Analysis)\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/e0/a45948450946a87dae44d936ea7646d862e1014753c496468a05f20e95c5/PeakUtils-1.3.2.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from peakutils->Signal_Analysis) (1.3.0)\n",
            "Building wheels for collected packages: Signal-Analysis, peakutils\n",
            "  Building wheel for Signal-Analysis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/06/bb/04aa9ef50b93b5961b9817600ca1ff379f7091e63e09831655\n",
            "  Building wheel for peakutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/52/9c/94cff100c9dd4ec0c72762947b8d5da6f6c0762cd5312b04ec\n",
            "Successfully built Signal-Analysis peakutils\n",
            "Installing collected packages: peakutils, Signal-Analysis\n",
            "Successfully installed Signal-Analysis-0.1.26 peakutils-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQUWLgcI6VIZ",
        "colab_type": "code",
        "outputId": "4a6cc634-0167-4fb7-88ab-00609b618496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install python_speech_features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tMVBy2k6H7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Signal_Analysis\n",
        "from Signal_Analysis import features\n",
        "from Signal_Analysis.features import signal\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wavfile\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pickle \n",
        "import os,sys\n",
        "import sklearn.mixture\n",
        "from sklearn import preprocessing\n",
        "import python_speech_features as mfcc\n",
        "import scipy\n",
        "from scipy.fftpack import dct\n",
        "#import ffmpeg\n",
        "#import pydub\n",
        "#from pydub import AudioSegment\n",
        "#import moviepy.editor as mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HouPmkxz8nJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_mfcc(audio,rate):\n",
        "    mfcc_feature = mfcc.mfcc(audio,rate, 0.025, 0.01,20,nfft = 1200, appendEnergy = True) \n",
        "    #mfcc_feature = preprocessing.scale(mfcc_feature)\n",
        "    mfcc_feature=np.mean(mfcc_feature,axis=0)\n",
        "    return mfcc_feature\n",
        "#def extract_mfcc(audio,sr):\n",
        "  #return np.transpose(librosa.feature.mfcc(audio, sr, n_mfcc=20))\n",
        "  #mfccs = librosa.feature.mfcc(audio, sr, n_mfcc=40) \n",
        "  #return mfccs\n",
        "#  mfcc = np.mean(librosa.feature.mfcc(audio,sr,n_mfcc=20).T,axis=0)\n",
        "#  return mfcc\n",
        "\n",
        "\n",
        "#def extract_dmfcc(audio,sr):\n",
        "   \n",
        "#    mfcc = np.transpose(librosa.feature.mfcc(audio, sr, n_mfcc=20))\n",
        "    #mfcc = scipy.fftpack.dct(mfcc)\n",
        "#    delta = np.mean(librosa.feature.delta(mfcc),axis=0)\n",
        "#    return delta\n",
        "\n",
        "  \n",
        "def extract_dmfcc(audio,rate):\n",
        "    mfcc_feature = mfcc.mfcc(audio,rate, 0.025, 0.01,20,nfft = 1200, appendEnergy = True)\n",
        "    dmfcc_feature=librosa.feature.delta(mfcc_feature)\n",
        "    #dmfcc_feature = preprocessing.scale(dmfcc_feature)\n",
        "    dmfcc_feature=np.mean(dmfcc_feature,axis=0)\n",
        "    return dmfcc_feature\n",
        "  \n",
        "def extract_log(audio,rate):\n",
        "    a= mfcc.logfbank(audio,rate,0.025,0.01,20,nfft=1200)\n",
        "    #a=preprocessing.scale(a)\n",
        "    a=np.mean(a,axis=0)\n",
        "    return a\n",
        "  \n",
        "#def extract_filt(audio,rate):\n",
        "#  b=np.mean( preprocessing.normalize(mfcc.fbank(audio,rate,0.025,0.01,20,nfft=1200), axis = 0))\n",
        "#    b=preprocessing.scale(b)\n",
        "#    b=dct(b.transpose()).transpose()\n",
        "  #b=np.mean(b,axis = 0)\n",
        "#  return b\n",
        "  \n",
        "#def extract_chroma(audio,sr):\n",
        "  \n",
        "def extract_spec_cent(audio,sr):\n",
        "  a=np.mean(librosa.feature.spectral_centroid(audio,sr))\n",
        "  return np.array([a*2/sr])\n",
        "                                                            \n",
        "def extract_flatness(audio,sr):       #returns value in [0,1] per frame\n",
        "    return np.array([np.mean(librosa.feature.spectral_flatness(audio))])\n",
        "  \n",
        "#def extract_pitch(audio,sr):     #returns pitch per audio in Hz\n",
        "#    pitch = Signal_Analysis.features.signal.get_F_0(audio,sr)\n",
        "#    return np.array([pitch[0]])\n",
        "  \n",
        "def extract_HNR(audio,sr):   #returns HNR per audio\n",
        "    hnr = Signal_Analysis.features.signal.get_HNR(audio,sr)\n",
        "    return np.array([hnr])\n",
        "  \n",
        "#def extract_tonnetz(audio,sr):\n",
        "#  return np.mean(np.transpose(librosa.feature.tonnetz(audio,sr)),axis = 0)\n",
        "  \n",
        "def extract_srolloff(audio,sr):   #returns per frame in Hz\n",
        "    return np.array([np.mean(librosa.feature.spectral_rolloff(audio,sr))])\n",
        "  \n",
        "\n",
        "def extract_zcr(audio,sr):\n",
        "  return np.array([np.mean(librosa.feature.zero_crossing_rate(audio))])\n",
        "\n",
        "def extract_chroma(audio,sr):\n",
        "  chroma = np.mean(np.transpose(librosa.feature.chroma_stft(audio,sr)),axis = 0)\n",
        "  #chroma = scipy.fftpack.dct(chroma)\n",
        "  #chroma = np.mean(chroma,axis = 0)\n",
        "  return np.array(chroma)\n",
        "\n",
        "def extract_mel(audio,sr):\n",
        "  return np.mean(np.transpose(librosa.feature.melspectrogram(audio, sr)),axis=0)\n",
        "\n",
        "def extract_lfcc(signal,sample_rate):\n",
        "    emphasized_signal = signal #np.append(signal[0], signal[1:] - 0.97 * signal[:-1])\n",
        "    frame_length, frame_step = 0.025 * sample_rate, 0.01 * sample_rate  # Convert from seconds to samples\n",
        "    signal_length = len(emphasized_signal)\n",
        "    frame_length = int(round(frame_length))\n",
        "    frame_step = int(round(frame_step))\n",
        "    num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
        "\n",
        "    pad_signal_length = num_frames * frame_step + frame_length\n",
        "    z = np.zeros((pad_signal_length - signal_length))\n",
        "    pad_signal = np.append(emphasized_signal, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
        "\n",
        "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
        "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
        "    \n",
        "    frames *= np.hamming(frame_length)\n",
        "    \n",
        "    NFFT=512\n",
        "    mag_frames = np.absolute(np.fft.rfft(frames, NFFT))  # Magnitude of the FFT\n",
        "    pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))  # Power Spectrum\n",
        "    \n",
        "    nfilt=40\n",
        "    low_freq_mel = 0\n",
        "    high_freq_mel = (sample_rate / 2)   \n",
        "    hz_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in hz scale\n",
        "\n",
        "    bin = np.floor((NFFT + 1) * hz_points / sample_rate)\n",
        "\n",
        "    fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))\n",
        "    for m in range(1, nfilt + 1):\n",
        "        f_m_minus = int(bin[m - 1])   # left\n",
        "        f_m = int(bin[m])             # center\n",
        "        f_m_plus = int(bin[m + 1])    # right\n",
        "\n",
        "        for k in range(f_m_minus, f_m):\n",
        "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
        "        for k in range(f_m, f_m_plus):\n",
        "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
        "    filter_banks = np.dot(pow_frames, fbank.T)\n",
        "    filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)  # Numerical Stability\n",
        "    filter_banks = 20 * np.log10(filter_banks)  # dB\n",
        "    \n",
        "    num_ceps = 20\n",
        "    lfcc = dct(filter_banks, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)]\n",
        "    \n",
        "    cep_lifter=22\n",
        "    (nframes, ncoeff) = lfcc.shape\n",
        "    n = np.arange(ncoeff)\n",
        "    lift = 1 + (cep_lifter / 2) * np.sin(np.pi * n / cep_lifter)\n",
        "    lfcc *= lift  \n",
        "    \n",
        "    #lfcc -= (numpy.mean(lfcc, axis=0) + 1e-8)\n",
        "    #lfcc=preprocessing.scale(lfcc)\n",
        "    lfcc=np.mean(lfcc,axis=0)\n",
        "    return lfcc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzf39PPdvIZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_noise(audio,sr):\n",
        "  audio_w = audio**2\n",
        "  target_snr_db = 20\n",
        "  # Calculate signal power and convert to dB \n",
        "  sig_avg_watts = np.mean(audio_w)\n",
        "  sig_avg_db = 10 * np.log10(sig_avg_watts)\n",
        "    # Calculate noise according to [2] then convert to watts\n",
        "  noise_avg_db = sig_avg_db - target_snr_db\n",
        "  noise_avg_watts = 10 ** (noise_avg_db / 10)\n",
        "    # Generate an sample of white noise\n",
        "  mean_noise = 0\n",
        "  noise_volts = np.random.normal(mean_noise, np.sqrt(noise_avg_watts), len(audio_w))\n",
        "    # Noise up the original signal\n",
        "  y_volts = audio + noise_volts\n",
        "  return y_volts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nfVtUDCPFZ4",
        "colab_type": "text"
      },
      "source": [
        "#Extracting audio from video "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKiXj6qLFJDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emo = ['anger','disgust','fear','happiness','sadness','surprise']\n",
        "ind = ['an','di','fe','ha','sa','su']\n",
        "count = 0\n",
        "dest = \"drive/My Drive/Enterface/\"\n",
        "y = []\n",
        "f  = []\n",
        "\n",
        "for i in range(1,45):\n",
        "  for j in emo:\n",
        "    for k in ind:\n",
        "      for l in range(1,6):\n",
        "        file = \"enterface database/subject \"+str(i)+\"/\"+j+\"/\"+\"sentence \"+str(l)+\"/\"+\"s\"+str(i)+\"_\"+k+\"_\"+str(l)+\".avi\"\n",
        "        if os.path.isfile(file):\n",
        "          clip = mp.VideoFileClip(file)\n",
        "          clip.audio.write_audiofile(dest+\"s\"+str(i)+\"_\"+k+\"_\"+str(l)+\".wav\")\n",
        "#audio,sr = sf.read(audioclip)\n",
        "          audio,sr = sf.read(dest+\"s\"+str(i)+\"_\"+k+\"_\"+str(l)+\".wav\")\n",
        "          sound = AudioSegment.from_wav(dest+\"s\"+str(i)+\"_\"+k+\"_\"+str(l)+\".wav\")\n",
        "          sound = sound.set_channels(1)\n",
        "          sound.export(dest+\"s\"+str(i)+\"_\"+k+\"_\"+str(l)+\".wav\", format=\"wav\")\n",
        "          audio,sr = sf.read(dest+\"s\"+str(i)+\"_\"+k+\"_\"+str(l)+\".wav\")\n",
        "          count+=1\n",
        "print(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV9ifJ2PLid9",
        "colab_type": "code",
        "outputId": "31b04978-a3fa-42a3-da05-b27d50f82ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y = []\n",
        "f  = []\n",
        "count = 0\n",
        "source = \"drive/My Drive/Enterface/\"\n",
        "ind = ['an','di','fe','ha','sa','su']\n",
        "path = os.listdir(source)\n",
        "for file in path:\n",
        "    audio,sr=sf.read(source+file)\n",
        "    lens = len(audio)/sr\n",
        "    if(not(lens>=5)):\n",
        "      aud=  []\n",
        "      for z in range(len(audio)-1):\n",
        "        aud.append(audio[z]- 0.97*audio[z-1])\n",
        "      aud = np.array(aud)\n",
        "     \n",
        "      l1=[]\n",
        "      l2 = []\n",
        "      l1=extract_mfcc(audio,sr).tolist()\n",
        "      l1.extend(extract_dmfcc(audio,sr).tolist())\n",
        "      l1.extend(extract_log(audio,sr).tolist())\n",
        "      l1.extend(extract_HNR(audio,sr).tolist())\n",
        "      l1.extend(extract_lfcc(audio,sr).tolist())\n",
        "                          #l1.extend(extract_filt(aud,sr).tolist())\n",
        "                       \n",
        "      l1.extend(extract_spec_cent(audio,sr).tolist())\n",
        "      l1.extend(extract_srolloff(audio,sr).tolist())\n",
        "      l1.extend(extract_chroma(audio,sr).tolist())\n",
        "      l1.extend(extract_flatness(audio,sr).tolist())\n",
        "      l1.extend(extract_zcr(audio,sr).tolist())\n",
        "      l1.extend(extract_mel(audio,sr).tolist())\n",
        "                          \n",
        "      \n",
        "      f.append(l1)\n",
        "      \n",
        "      y.append(np.array(ind.index(file.split('_')[1]))) \n",
        "      count+=1\n",
        "      print(count)\n",
        "print(len(y)) \n",
        "print(len(f))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n",
            "1107\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1111\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1115\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1119\n",
            "1120\n",
            "1121\n",
            "1122\n",
            "1123\n",
            "1124\n",
            "1125\n",
            "1126\n",
            "1127\n",
            "1128\n",
            "1129\n",
            "1130\n",
            "1131\n",
            "1132\n",
            "1133\n",
            "1134\n",
            "1135\n",
            "1136\n",
            "1137\n",
            "1138\n",
            "1139\n",
            "1140\n",
            "1141\n",
            "1142\n",
            "1143\n",
            "1144\n",
            "1145\n",
            "1146\n",
            "1147\n",
            "1148\n",
            "1149\n",
            "1150\n",
            "1151\n",
            "1152\n",
            "1153\n",
            "1154\n",
            "1155\n",
            "1156\n",
            "1157\n",
            "1158\n",
            "1159\n",
            "1160\n",
            "1161\n",
            "1162\n",
            "1163\n",
            "1164\n",
            "1165\n",
            "1166\n",
            "1167\n",
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1178\n",
            "1179\n",
            "1180\n",
            "1181\n",
            "1182\n",
            "1183\n",
            "1184\n",
            "1185\n",
            "1186\n",
            "1187\n",
            "1188\n",
            "1189\n",
            "1190\n",
            "1191\n",
            "1192\n",
            "1193\n",
            "1194\n",
            "1195\n",
            "1196\n",
            "1197\n",
            "1198\n",
            "1199\n",
            "1200\n",
            "1201\n",
            "1202\n",
            "1203\n",
            "1204\n",
            "1205\n",
            "1206\n",
            "1207\n",
            "1208\n",
            "1209\n",
            "1209\n",
            "1209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV27USH7h3s7",
        "colab_type": "code",
        "outputId": "1245cccd-f1b7-431f-ed34-ec1e9beeab69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x=np.expand_dims(np.array(f),axis=2)\n",
        "print(x.shape)\n",
        "y=np.array(y)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1209, 225, 1)\n",
            "(1209,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAdRSLk8OJWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mupNYNlM9-5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T59_kmYnSu58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rL2abFf-CnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import Dense,Dropout,LSTM,Masking,CuDNNLSTM,Input,concatenate,Conv1D, MaxPooling1D,Flatten,Activation, AveragePooling1D, BatchNormalization\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6tWQufLlREm",
        "colab_type": "code",
        "outputId": "c22c7bb4-3c0a-4249-ba68-5c353cbc209d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "x1 = Input(shape = (225,1))\n",
        "y1 = Conv1D(100,5, padding = 'same', activation = 'relu')(x1)\n",
        "y1 = BatchNormalization(axis=1)(y1)\n",
        "y1 = Dropout(0.4)(y1)\n",
        "\n",
        "y2 = Conv1D(32,5, padding = 'same', activation = 'relu')(x1)\n",
        "y2 = BatchNormalization(axis=1)(y2)\n",
        "y2 = Dropout(0.4)(y2)\n",
        "\n",
        "y1 = AveragePooling1D(pool_size=(4))(y1)\n",
        "y1 = Flatten()(y1)\n",
        "y2 = AveragePooling1D(pool_size=(4))(y2)\n",
        "\n",
        "y3 = Conv1D(250,5, padding = 'same',activation = 'relu')(y2)\n",
        "y3 = BatchNormalization(axis=1)(y3)\n",
        "y3 = Dropout(0.4)(y3)\n",
        "y3 = AveragePooling1D(pool_size = (4))(y3)\n",
        "y3 = Flatten()(y3)\n",
        "\n",
        "merged_vector = concatenate([y1,y3])\n",
        "\n",
        "a1 = Dense(1024, activation = 'relu')(merged_vector)\n",
        "a1 = Dropout(0.8)(a1)\n",
        "b1 = Dense(512,activation='relu')(a1)\n",
        "b1 = Dropout(0.3)(b1)\n",
        "c1 = Dense(128,activation='relu')(b1)\n",
        "c1 = Dropout(0.0)(c1)\n",
        "d1 = Dense(64,activation = 'relu')(c1)\n",
        "d1 = Dropout(0.0)(d1)\n",
        "out = Dense(6,activation='softmax')(d1)\n",
        "model=Model(inputs=x1 , outputs=out)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0702 05:45:44.782817 140188086884224 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0702 05:45:45.419345 140188086884224 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGCRX1nh-FSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1 = Input(shape = (225,1))\n",
        "\n",
        "y1 = Conv1D(64,11, padding = 'same', activation = 'relu')(x1)\n",
        "y1 = BatchNormalization(axis=1)(y1)\n",
        "y1 = Dropout(0.4)(y1)\n",
        "y1 = AveragePooling1D(pool_size=(4))(y1)\n",
        "y1 = Flatten()(y1)\n",
        "\n",
        "d1 = Dense(64, activation = 'relu')(y1)\n",
        "d1 = Dropout(0.2)(d1)\n",
        "\n",
        "y2 = Conv1D(32,11, padding = 'same', activation = 'relu')(x1)\n",
        "y2 = BatchNormalization(axis=1)(y2)\n",
        "y2 = Dropout(0.2)(y2)\n",
        "y2 = MaxPooling1D(pool_size=(4))(y2)\n",
        "\n",
        "y3 = Conv1D(64,11, padding = 'same', activation = 'relu')(y2)\n",
        "y3 = Dropout(0.2)(y3)\n",
        "y3 = Flatten()(y3)\n",
        "\n",
        "d2 = Dense(512, activation = 'relu')(y3)\n",
        "d2 = Dropout(0.4)(d2)\n",
        "\n",
        "d3 = Dense(64, activation = 'relu')(d2)\n",
        "d3 = Dropout(0.2)(d3)\n",
        "\n",
        "merged_vector = concatenate([d1,d3])\n",
        "\n",
        "out = Dense(6,activation='softmax')(merged_vector)\n",
        "model=Model(inputs=x1 , outputs=out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEzcRpwW-IzM",
        "colab_type": "code",
        "outputId": "a6c331e1-d17b-4935-b46a-d6c2e255b8a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 225, 1)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 225, 32)      192         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 225, 32)      900         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 225, 32)      0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_1 (AveragePoo (None, 56, 32)       0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 225, 100)     600         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 56, 250)      40250       average_pooling1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 225, 100)     900         conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 56, 250)      224         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 225, 100)     0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 56, 250)      0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d (AveragePooli (None, 56, 100)      0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_2 (AveragePoo (None, 14, 250)      0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 5600)         0           average_pooling1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 3500)         0           average_pooling1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 9100)         0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         9319424     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          524800      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          65664       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           8256        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 6)            390         dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 9,961,600\n",
            "Trainable params: 9,960,588\n",
            "Non-trainable params: 1,012\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRsNfUD9-MFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(lr=1e-3 , decay= 1e-4,clipnorm=1.0,clipvalue=0.5)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzvlhcUq-PiC",
        "colab_type": "code",
        "outputId": "7a859f9f-1194-42a3-d10d-3b28a1eeb18d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train,y_train, epochs = 1000, validation_data = (x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 967 samples, validate on 242 samples\n",
            "Epoch 1/1000\n",
            "967/967 [==============================] - 1s 558us/sample - loss: 0.0366 - acc: 0.9866 - val_loss: 2.4753 - val_acc: 0.5909\n",
            "Epoch 2/1000\n",
            "967/967 [==============================] - 1s 618us/sample - loss: 0.0576 - acc: 0.9824 - val_loss: 2.5473 - val_acc: 0.5868\n",
            "Epoch 3/1000\n",
            "967/967 [==============================] - 1s 609us/sample - loss: 0.0500 - acc: 0.9876 - val_loss: 2.5491 - val_acc: 0.5702\n",
            "Epoch 4/1000\n",
            "967/967 [==============================] - 1s 612us/sample - loss: 0.0405 - acc: 0.9855 - val_loss: 2.5392 - val_acc: 0.5744\n",
            "Epoch 5/1000\n",
            "967/967 [==============================] - 1s 572us/sample - loss: 0.0587 - acc: 0.9845 - val_loss: 2.5223 - val_acc: 0.6033\n",
            "Epoch 6/1000\n",
            "967/967 [==============================] - 0s 511us/sample - loss: 0.0632 - acc: 0.9835 - val_loss: 2.5652 - val_acc: 0.5702\n",
            "Epoch 7/1000\n",
            "967/967 [==============================] - 0s 492us/sample - loss: 0.0400 - acc: 0.9866 - val_loss: 2.5466 - val_acc: 0.5826\n",
            "Epoch 8/1000\n",
            "967/967 [==============================] - 1s 589us/sample - loss: 0.0454 - acc: 0.9814 - val_loss: 2.5332 - val_acc: 0.5785\n",
            "Epoch 9/1000\n",
            "967/967 [==============================] - 1s 552us/sample - loss: 0.0373 - acc: 0.9866 - val_loss: 2.5118 - val_acc: 0.5909\n",
            "Epoch 10/1000\n",
            "967/967 [==============================] - 1s 600us/sample - loss: 0.0806 - acc: 0.9741 - val_loss: 2.4995 - val_acc: 0.5909\n",
            "Epoch 11/1000\n",
            "967/967 [==============================] - 1s 565us/sample - loss: 0.0533 - acc: 0.9876 - val_loss: 2.5074 - val_acc: 0.5744\n",
            "Epoch 12/1000\n",
            "967/967 [==============================] - 1s 594us/sample - loss: 0.0545 - acc: 0.9824 - val_loss: 2.5369 - val_acc: 0.5785\n",
            "Epoch 13/1000\n",
            "967/967 [==============================] - 1s 563us/sample - loss: 0.0392 - acc: 0.9835 - val_loss: 2.5580 - val_acc: 0.5620\n",
            "Epoch 14/1000\n",
            "967/967 [==============================] - 1s 577us/sample - loss: 0.0383 - acc: 0.9855 - val_loss: 2.5315 - val_acc: 0.5744\n",
            "Epoch 15/1000\n",
            "967/967 [==============================] - 1s 571us/sample - loss: 0.0639 - acc: 0.9835 - val_loss: 2.5096 - val_acc: 0.5785\n",
            "Epoch 16/1000\n",
            "967/967 [==============================] - 1s 599us/sample - loss: 0.0728 - acc: 0.9804 - val_loss: 2.4976 - val_acc: 0.5702\n",
            "Epoch 17/1000\n",
            "967/967 [==============================] - 1s 526us/sample - loss: 0.0726 - acc: 0.9793 - val_loss: 2.4941 - val_acc: 0.5950\n",
            "Epoch 18/1000\n",
            "967/967 [==============================] - 1s 610us/sample - loss: 0.0556 - acc: 0.9876 - val_loss: 2.4235 - val_acc: 0.5950\n",
            "Epoch 19/1000\n",
            "967/967 [==============================] - 1s 523us/sample - loss: 0.0659 - acc: 0.9866 - val_loss: 2.4195 - val_acc: 0.5868\n",
            "Epoch 20/1000\n",
            "967/967 [==============================] - 1s 568us/sample - loss: 0.0352 - acc: 0.9917 - val_loss: 2.4737 - val_acc: 0.5992\n",
            "Epoch 21/1000\n",
            "967/967 [==============================] - 0s 490us/sample - loss: 0.0552 - acc: 0.9845 - val_loss: 2.5009 - val_acc: 0.5785\n",
            "Epoch 22/1000\n",
            "967/967 [==============================] - 1s 540us/sample - loss: 0.0336 - acc: 0.9886 - val_loss: 2.5157 - val_acc: 0.5702\n",
            "Epoch 23/1000\n",
            "967/967 [==============================] - 0s 506us/sample - loss: 0.0462 - acc: 0.9835 - val_loss: 2.5311 - val_acc: 0.5661\n",
            "Epoch 24/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0439 - acc: 0.9876 - val_loss: 2.4961 - val_acc: 0.5744\n",
            "Epoch 25/1000\n",
            "967/967 [==============================] - 1s 592us/sample - loss: 0.0608 - acc: 0.9855 - val_loss: 2.5360 - val_acc: 0.5537\n",
            "Epoch 26/1000\n",
            "967/967 [==============================] - 1s 583us/sample - loss: 0.0404 - acc: 0.9824 - val_loss: 2.5763 - val_acc: 0.5744\n",
            "Epoch 27/1000\n",
            "967/967 [==============================] - 1s 585us/sample - loss: 0.0570 - acc: 0.9855 - val_loss: 2.5638 - val_acc: 0.5785\n",
            "Epoch 28/1000\n",
            "967/967 [==============================] - 1s 581us/sample - loss: 0.0302 - acc: 0.9907 - val_loss: 2.6178 - val_acc: 0.5620\n",
            "Epoch 29/1000\n",
            "967/967 [==============================] - 1s 581us/sample - loss: 0.0511 - acc: 0.9824 - val_loss: 2.6479 - val_acc: 0.5661\n",
            "Epoch 30/1000\n",
            "967/967 [==============================] - 1s 614us/sample - loss: 0.0622 - acc: 0.9824 - val_loss: 2.6053 - val_acc: 0.5661\n",
            "Epoch 31/1000\n",
            "967/967 [==============================] - 0s 484us/sample - loss: 0.0503 - acc: 0.9824 - val_loss: 2.5803 - val_acc: 0.5826\n",
            "Epoch 32/1000\n",
            "967/967 [==============================] - 1s 558us/sample - loss: 0.0341 - acc: 0.9907 - val_loss: 2.5646 - val_acc: 0.5702\n",
            "Epoch 33/1000\n",
            "967/967 [==============================] - 1s 625us/sample - loss: 0.0528 - acc: 0.9876 - val_loss: 2.5380 - val_acc: 0.5785\n",
            "Epoch 34/1000\n",
            "967/967 [==============================] - 1s 621us/sample - loss: 0.0502 - acc: 0.9866 - val_loss: 2.5366 - val_acc: 0.5744\n",
            "Epoch 35/1000\n",
            "967/967 [==============================] - 1s 572us/sample - loss: 0.0572 - acc: 0.9804 - val_loss: 2.5637 - val_acc: 0.5785\n",
            "Epoch 36/1000\n",
            "967/967 [==============================] - 1s 541us/sample - loss: 0.0335 - acc: 0.9824 - val_loss: 2.5957 - val_acc: 0.5620\n",
            "Epoch 37/1000\n",
            "967/967 [==============================] - 1s 558us/sample - loss: 0.0328 - acc: 0.9866 - val_loss: 2.5743 - val_acc: 0.5702\n",
            "Epoch 38/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0544 - acc: 0.9814 - val_loss: 2.5743 - val_acc: 0.5579\n",
            "Epoch 39/1000\n",
            "967/967 [==============================] - 1s 608us/sample - loss: 0.0373 - acc: 0.9866 - val_loss: 2.5431 - val_acc: 0.5744\n",
            "Epoch 40/1000\n",
            "967/967 [==============================] - 1s 598us/sample - loss: 0.0489 - acc: 0.9814 - val_loss: 2.5318 - val_acc: 0.5826\n",
            "Epoch 41/1000\n",
            "967/967 [==============================] - 1s 599us/sample - loss: 0.0595 - acc: 0.9824 - val_loss: 2.5233 - val_acc: 0.5909\n",
            "Epoch 42/1000\n",
            "967/967 [==============================] - 1s 557us/sample - loss: 0.0537 - acc: 0.9793 - val_loss: 2.5010 - val_acc: 0.5826\n",
            "Epoch 43/1000\n",
            "967/967 [==============================] - 1s 585us/sample - loss: 0.0363 - acc: 0.9845 - val_loss: 2.5255 - val_acc: 0.5661\n",
            "Epoch 44/1000\n",
            "967/967 [==============================] - 1s 582us/sample - loss: 0.0418 - acc: 0.9886 - val_loss: 2.5535 - val_acc: 0.5702\n",
            "Epoch 45/1000\n",
            "967/967 [==============================] - 1s 591us/sample - loss: 0.0565 - acc: 0.9824 - val_loss: 2.5654 - val_acc: 0.5909\n",
            "Epoch 46/1000\n",
            "967/967 [==============================] - 1s 605us/sample - loss: 0.0624 - acc: 0.9824 - val_loss: 2.5530 - val_acc: 0.5620\n",
            "Epoch 47/1000\n",
            "967/967 [==============================] - 1s 599us/sample - loss: 0.0502 - acc: 0.9814 - val_loss: 2.5457 - val_acc: 0.5620\n",
            "Epoch 48/1000\n",
            "967/967 [==============================] - 1s 599us/sample - loss: 0.0456 - acc: 0.9876 - val_loss: 2.5238 - val_acc: 0.5702\n",
            "Epoch 49/1000\n",
            "967/967 [==============================] - 1s 579us/sample - loss: 0.0320 - acc: 0.9897 - val_loss: 2.5210 - val_acc: 0.5579\n",
            "Epoch 50/1000\n",
            "967/967 [==============================] - 0s 514us/sample - loss: 0.0777 - acc: 0.9762 - val_loss: 2.5089 - val_acc: 0.5785\n",
            "Epoch 51/1000\n",
            "967/967 [==============================] - 1s 552us/sample - loss: 0.0561 - acc: 0.9793 - val_loss: 2.4813 - val_acc: 0.5826\n",
            "Epoch 52/1000\n",
            "967/967 [==============================] - 1s 585us/sample - loss: 0.0555 - acc: 0.9835 - val_loss: 2.5098 - val_acc: 0.5785\n",
            "Epoch 53/1000\n",
            "967/967 [==============================] - 1s 566us/sample - loss: 0.0457 - acc: 0.9845 - val_loss: 2.5210 - val_acc: 0.5826\n",
            "Epoch 54/1000\n",
            "967/967 [==============================] - 1s 582us/sample - loss: 0.0321 - acc: 0.9886 - val_loss: 2.5534 - val_acc: 0.5868\n",
            "Epoch 55/1000\n",
            "967/967 [==============================] - 1s 530us/sample - loss: 0.0553 - acc: 0.9824 - val_loss: 2.5750 - val_acc: 0.5868\n",
            "Epoch 56/1000\n",
            "967/967 [==============================] - 0s 512us/sample - loss: 0.0599 - acc: 0.9835 - val_loss: 2.5807 - val_acc: 0.5620\n",
            "Epoch 57/1000\n",
            "967/967 [==============================] - 1s 531us/sample - loss: 0.0448 - acc: 0.9855 - val_loss: 2.5960 - val_acc: 0.5661\n",
            "Epoch 58/1000\n",
            "967/967 [==============================] - 1s 619us/sample - loss: 0.0516 - acc: 0.9835 - val_loss: 2.6478 - val_acc: 0.5868\n",
            "Epoch 59/1000\n",
            "967/967 [==============================] - 1s 557us/sample - loss: 0.0461 - acc: 0.9845 - val_loss: 2.6187 - val_acc: 0.5661\n",
            "Epoch 60/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0466 - acc: 0.9876 - val_loss: 2.5693 - val_acc: 0.5744\n",
            "Epoch 61/1000\n",
            "967/967 [==============================] - 1s 527us/sample - loss: 0.0367 - acc: 0.9907 - val_loss: 2.5727 - val_acc: 0.5744\n",
            "Epoch 62/1000\n",
            "967/967 [==============================] - 1s 577us/sample - loss: 0.0360 - acc: 0.9917 - val_loss: 2.5615 - val_acc: 0.5661\n",
            "Epoch 63/1000\n",
            "967/967 [==============================] - 1s 636us/sample - loss: 0.0331 - acc: 0.9876 - val_loss: 2.5301 - val_acc: 0.5579\n",
            "Epoch 64/1000\n",
            "967/967 [==============================] - 0s 489us/sample - loss: 0.0434 - acc: 0.9876 - val_loss: 2.5593 - val_acc: 0.5537\n",
            "Epoch 65/1000\n",
            "967/967 [==============================] - 1s 539us/sample - loss: 0.0464 - acc: 0.9866 - val_loss: 2.5705 - val_acc: 0.5579\n",
            "Epoch 66/1000\n",
            "967/967 [==============================] - 1s 519us/sample - loss: 0.0606 - acc: 0.9855 - val_loss: 2.5599 - val_acc: 0.5661\n",
            "Epoch 67/1000\n",
            "967/967 [==============================] - 1s 559us/sample - loss: 0.0600 - acc: 0.9762 - val_loss: 2.5611 - val_acc: 0.5661\n",
            "Epoch 68/1000\n",
            "967/967 [==============================] - 1s 540us/sample - loss: 0.0466 - acc: 0.9866 - val_loss: 2.5524 - val_acc: 0.5702\n",
            "Epoch 69/1000\n",
            "967/967 [==============================] - 0s 513us/sample - loss: 0.0464 - acc: 0.9783 - val_loss: 2.5465 - val_acc: 0.5661\n",
            "Epoch 70/1000\n",
            "967/967 [==============================] - 0s 492us/sample - loss: 0.0512 - acc: 0.9866 - val_loss: 2.5362 - val_acc: 0.5744\n",
            "Epoch 71/1000\n",
            "967/967 [==============================] - 1s 530us/sample - loss: 0.0538 - acc: 0.9804 - val_loss: 2.5631 - val_acc: 0.5579\n",
            "Epoch 72/1000\n",
            "967/967 [==============================] - 1s 588us/sample - loss: 0.0534 - acc: 0.9814 - val_loss: 2.5142 - val_acc: 0.5702\n",
            "Epoch 73/1000\n",
            "967/967 [==============================] - 1s 596us/sample - loss: 0.0434 - acc: 0.9897 - val_loss: 2.5088 - val_acc: 0.5661\n",
            "Epoch 74/1000\n",
            "967/967 [==============================] - 1s 602us/sample - loss: 0.0254 - acc: 0.9917 - val_loss: 2.5230 - val_acc: 0.5785\n",
            "Epoch 75/1000\n",
            "967/967 [==============================] - 1s 583us/sample - loss: 0.0564 - acc: 0.9855 - val_loss: 2.5097 - val_acc: 0.5785\n",
            "Epoch 76/1000\n",
            "967/967 [==============================] - 1s 525us/sample - loss: 0.0324 - acc: 0.9886 - val_loss: 2.4924 - val_acc: 0.5826\n",
            "Epoch 77/1000\n",
            "967/967 [==============================] - 1s 542us/sample - loss: 0.0403 - acc: 0.9897 - val_loss: 2.4988 - val_acc: 0.5785\n",
            "Epoch 78/1000\n",
            "967/967 [==============================] - 0s 500us/sample - loss: 0.0575 - acc: 0.9835 - val_loss: 2.5332 - val_acc: 0.5744\n",
            "Epoch 79/1000\n",
            "967/967 [==============================] - 0s 514us/sample - loss: 0.0441 - acc: 0.9855 - val_loss: 2.5430 - val_acc: 0.5826\n",
            "Epoch 80/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0387 - acc: 0.9897 - val_loss: 2.5584 - val_acc: 0.5744\n",
            "Epoch 81/1000\n",
            "967/967 [==============================] - 1s 620us/sample - loss: 0.0536 - acc: 0.9793 - val_loss: 2.5627 - val_acc: 0.5826\n",
            "Epoch 82/1000\n",
            "967/967 [==============================] - 1s 577us/sample - loss: 0.0584 - acc: 0.9824 - val_loss: 2.5546 - val_acc: 0.5868\n",
            "Epoch 83/1000\n",
            "967/967 [==============================] - 1s 555us/sample - loss: 0.0400 - acc: 0.9835 - val_loss: 2.5695 - val_acc: 0.5785\n",
            "Epoch 84/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0456 - acc: 0.9855 - val_loss: 2.6317 - val_acc: 0.5702\n",
            "Epoch 85/1000\n",
            "967/967 [==============================] - 1s 566us/sample - loss: 0.0551 - acc: 0.9845 - val_loss: 2.6337 - val_acc: 0.5661\n",
            "Epoch 86/1000\n",
            "967/967 [==============================] - 1s 543us/sample - loss: 0.0275 - acc: 0.9897 - val_loss: 2.5941 - val_acc: 0.5826\n",
            "Epoch 87/1000\n",
            "967/967 [==============================] - 1s 560us/sample - loss: 0.0679 - acc: 0.9855 - val_loss: 2.5996 - val_acc: 0.5826\n",
            "Epoch 88/1000\n",
            "967/967 [==============================] - 1s 561us/sample - loss: 0.0301 - acc: 0.9917 - val_loss: 2.6040 - val_acc: 0.5620\n",
            "Epoch 89/1000\n",
            "967/967 [==============================] - 1s 613us/sample - loss: 0.0546 - acc: 0.9845 - val_loss: 2.6232 - val_acc: 0.5744\n",
            "Epoch 90/1000\n",
            "967/967 [==============================] - 1s 568us/sample - loss: 0.0464 - acc: 0.9845 - val_loss: 2.5806 - val_acc: 0.5785\n",
            "Epoch 91/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.1066 - acc: 0.9762 - val_loss: 2.5688 - val_acc: 0.5826\n",
            "Epoch 92/1000\n",
            "967/967 [==============================] - 1s 568us/sample - loss: 0.0597 - acc: 0.9866 - val_loss: 2.5907 - val_acc: 0.5702\n",
            "Epoch 93/1000\n",
            "967/967 [==============================] - 1s 603us/sample - loss: 0.0522 - acc: 0.9804 - val_loss: 2.5705 - val_acc: 0.5702\n",
            "Epoch 94/1000\n",
            "967/967 [==============================] - 1s 528us/sample - loss: 0.0369 - acc: 0.9835 - val_loss: 2.5483 - val_acc: 0.5661\n",
            "Epoch 95/1000\n",
            "967/967 [==============================] - 1s 573us/sample - loss: 0.0416 - acc: 0.9866 - val_loss: 2.5961 - val_acc: 0.5744\n",
            "Epoch 96/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0519 - acc: 0.9845 - val_loss: 2.6031 - val_acc: 0.5826\n",
            "Epoch 97/1000\n",
            "967/967 [==============================] - 1s 544us/sample - loss: 0.0623 - acc: 0.9845 - val_loss: 2.5872 - val_acc: 0.5702\n",
            "Epoch 98/1000\n",
            "967/967 [==============================] - 1s 582us/sample - loss: 0.0604 - acc: 0.9886 - val_loss: 2.5688 - val_acc: 0.5702\n",
            "Epoch 99/1000\n",
            "967/967 [==============================] - 0s 516us/sample - loss: 0.0563 - acc: 0.9855 - val_loss: 2.5948 - val_acc: 0.5702\n",
            "Epoch 100/1000\n",
            "967/967 [==============================] - 1s 619us/sample - loss: 0.0768 - acc: 0.9793 - val_loss: 2.4956 - val_acc: 0.5702\n",
            "Epoch 101/1000\n",
            "967/967 [==============================] - 1s 625us/sample - loss: 0.0581 - acc: 0.9772 - val_loss: 2.4651 - val_acc: 0.5620\n",
            "Epoch 102/1000\n",
            "967/967 [==============================] - 1s 537us/sample - loss: 0.0319 - acc: 0.9897 - val_loss: 2.4874 - val_acc: 0.5496\n",
            "Epoch 103/1000\n",
            "967/967 [==============================] - 1s 640us/sample - loss: 0.0434 - acc: 0.9845 - val_loss: 2.4963 - val_acc: 0.5702\n",
            "Epoch 104/1000\n",
            "967/967 [==============================] - 1s 557us/sample - loss: 0.0701 - acc: 0.9845 - val_loss: 2.4579 - val_acc: 0.5702\n",
            "Epoch 105/1000\n",
            "967/967 [==============================] - 1s 570us/sample - loss: 0.0461 - acc: 0.9845 - val_loss: 2.4728 - val_acc: 0.5785\n",
            "Epoch 106/1000\n",
            "967/967 [==============================] - 1s 544us/sample - loss: 0.0589 - acc: 0.9897 - val_loss: 2.5292 - val_acc: 0.5579\n",
            "Epoch 107/1000\n",
            "967/967 [==============================] - 1s 591us/sample - loss: 0.0386 - acc: 0.9866 - val_loss: 2.5403 - val_acc: 0.5702\n",
            "Epoch 108/1000\n",
            "967/967 [==============================] - 1s 615us/sample - loss: 0.0651 - acc: 0.9855 - val_loss: 2.5520 - val_acc: 0.5620\n",
            "Epoch 109/1000\n",
            "967/967 [==============================] - 1s 538us/sample - loss: 0.0478 - acc: 0.9845 - val_loss: 2.6046 - val_acc: 0.5496\n",
            "Epoch 110/1000\n",
            "967/967 [==============================] - 0s 507us/sample - loss: 0.0346 - acc: 0.9917 - val_loss: 2.6501 - val_acc: 0.5413\n",
            "Epoch 111/1000\n",
            "967/967 [==============================] - 1s 567us/sample - loss: 0.0417 - acc: 0.9866 - val_loss: 2.6710 - val_acc: 0.5537\n",
            "Epoch 112/1000\n",
            "967/967 [==============================] - 1s 564us/sample - loss: 0.0387 - acc: 0.9845 - val_loss: 2.6274 - val_acc: 0.5620\n",
            "Epoch 113/1000\n",
            "967/967 [==============================] - 1s 566us/sample - loss: 0.0575 - acc: 0.9804 - val_loss: 2.6038 - val_acc: 0.5620\n",
            "Epoch 114/1000\n",
            "967/967 [==============================] - 0s 516us/sample - loss: 0.0833 - acc: 0.9824 - val_loss: 2.5725 - val_acc: 0.5702\n",
            "Epoch 115/1000\n",
            "967/967 [==============================] - 0s 517us/sample - loss: 0.0577 - acc: 0.9855 - val_loss: 2.5369 - val_acc: 0.5661\n",
            "Epoch 116/1000\n",
            "967/967 [==============================] - 1s 546us/sample - loss: 0.0527 - acc: 0.9855 - val_loss: 2.5705 - val_acc: 0.5661\n",
            "Epoch 117/1000\n",
            "967/967 [==============================] - 1s 618us/sample - loss: 0.0479 - acc: 0.9835 - val_loss: 2.5927 - val_acc: 0.5702\n",
            "Epoch 118/1000\n",
            "967/967 [==============================] - 1s 569us/sample - loss: 0.0571 - acc: 0.9783 - val_loss: 2.5878 - val_acc: 0.5620\n",
            "Epoch 119/1000\n",
            "967/967 [==============================] - 1s 624us/sample - loss: 0.0454 - acc: 0.9866 - val_loss: 2.6275 - val_acc: 0.5661\n",
            "Epoch 120/1000\n",
            "967/967 [==============================] - 1s 573us/sample - loss: 0.0542 - acc: 0.9783 - val_loss: 2.6368 - val_acc: 0.5620\n",
            "Epoch 121/1000\n",
            "967/967 [==============================] - 0s 510us/sample - loss: 0.0354 - acc: 0.9886 - val_loss: 2.5944 - val_acc: 0.5620\n",
            "Epoch 122/1000\n",
            "967/967 [==============================] - 1s 661us/sample - loss: 0.0462 - acc: 0.9824 - val_loss: 2.5407 - val_acc: 0.5537\n",
            "Epoch 123/1000\n",
            "967/967 [==============================] - 1s 622us/sample - loss: 0.0300 - acc: 0.9907 - val_loss: 2.5622 - val_acc: 0.5537\n",
            "Epoch 124/1000\n",
            "967/967 [==============================] - 1s 608us/sample - loss: 0.0428 - acc: 0.9886 - val_loss: 2.5849 - val_acc: 0.5579\n",
            "Epoch 125/1000\n",
            "967/967 [==============================] - 1s 531us/sample - loss: 0.0340 - acc: 0.9897 - val_loss: 2.5801 - val_acc: 0.5620\n",
            "Epoch 126/1000\n",
            "967/967 [==============================] - 1s 571us/sample - loss: 0.0646 - acc: 0.9762 - val_loss: 2.5174 - val_acc: 0.5785\n",
            "Epoch 127/1000\n",
            "967/967 [==============================] - 1s 519us/sample - loss: 0.0572 - acc: 0.9824 - val_loss: 2.5336 - val_acc: 0.5785\n",
            "Epoch 128/1000\n",
            "967/967 [==============================] - 1s 646us/sample - loss: 0.0270 - acc: 0.9907 - val_loss: 2.5726 - val_acc: 0.5785\n",
            "Epoch 129/1000\n",
            "967/967 [==============================] - 0s 502us/sample - loss: 0.0504 - acc: 0.9824 - val_loss: 2.5608 - val_acc: 0.5661\n",
            "Epoch 130/1000\n",
            "967/967 [==============================] - 1s 607us/sample - loss: 0.0734 - acc: 0.9866 - val_loss: 2.5612 - val_acc: 0.5702\n",
            "Epoch 131/1000\n",
            "967/967 [==============================] - 1s 535us/sample - loss: 0.0407 - acc: 0.9855 - val_loss: 2.5226 - val_acc: 0.5537\n",
            "Epoch 132/1000\n",
            "967/967 [==============================] - 1s 607us/sample - loss: 0.0636 - acc: 0.9835 - val_loss: 2.5398 - val_acc: 0.5702\n",
            "Epoch 133/1000\n",
            "967/967 [==============================] - 1s 587us/sample - loss: 0.0503 - acc: 0.9876 - val_loss: 2.5381 - val_acc: 0.5868\n",
            "Epoch 134/1000\n",
            "967/967 [==============================] - 1s 596us/sample - loss: 0.0402 - acc: 0.9835 - val_loss: 2.5763 - val_acc: 0.5744\n",
            "Epoch 135/1000\n",
            "967/967 [==============================] - 1s 580us/sample - loss: 0.0253 - acc: 0.9948 - val_loss: 2.6527 - val_acc: 0.5455\n",
            "Epoch 136/1000\n",
            "967/967 [==============================] - 1s 607us/sample - loss: 0.0540 - acc: 0.9866 - val_loss: 2.6479 - val_acc: 0.5455\n",
            "Epoch 137/1000\n",
            "967/967 [==============================] - 1s 599us/sample - loss: 0.0438 - acc: 0.9866 - val_loss: 2.6791 - val_acc: 0.5496\n",
            "Epoch 138/1000\n",
            "967/967 [==============================] - 1s 627us/sample - loss: 0.0488 - acc: 0.9866 - val_loss: 2.6667 - val_acc: 0.5620\n",
            "Epoch 139/1000\n",
            "967/967 [==============================] - 1s 546us/sample - loss: 0.0398 - acc: 0.9845 - val_loss: 2.5887 - val_acc: 0.5744\n",
            "Epoch 140/1000\n",
            "967/967 [==============================] - 1s 624us/sample - loss: 0.0529 - acc: 0.9866 - val_loss: 2.5652 - val_acc: 0.5579\n",
            "Epoch 141/1000\n",
            "967/967 [==============================] - 1s 527us/sample - loss: 0.0531 - acc: 0.9845 - val_loss: 2.5328 - val_acc: 0.5702\n",
            "Epoch 142/1000\n",
            "967/967 [==============================] - 1s 517us/sample - loss: 0.0510 - acc: 0.9845 - val_loss: 2.5329 - val_acc: 0.5579\n",
            "Epoch 143/1000\n",
            "967/967 [==============================] - 0s 492us/sample - loss: 0.0599 - acc: 0.9814 - val_loss: 2.5137 - val_acc: 0.5661\n",
            "Epoch 144/1000\n",
            "967/967 [==============================] - 0s 492us/sample - loss: 0.0418 - acc: 0.9876 - val_loss: 2.5024 - val_acc: 0.5661\n",
            "Epoch 145/1000\n",
            "967/967 [==============================] - 0s 506us/sample - loss: 0.0888 - acc: 0.9783 - val_loss: 2.5208 - val_acc: 0.5702\n",
            "Epoch 146/1000\n",
            "967/967 [==============================] - 1s 561us/sample - loss: 0.0395 - acc: 0.9886 - val_loss: 2.5029 - val_acc: 0.5661\n",
            "Epoch 147/1000\n",
            "967/967 [==============================] - 1s 601us/sample - loss: 0.0343 - acc: 0.9897 - val_loss: 2.4982 - val_acc: 0.5702\n",
            "Epoch 148/1000\n",
            "967/967 [==============================] - 1s 534us/sample - loss: 0.0446 - acc: 0.9835 - val_loss: 2.5161 - val_acc: 0.5620\n",
            "Epoch 149/1000\n",
            "967/967 [==============================] - 1s 531us/sample - loss: 0.0488 - acc: 0.9855 - val_loss: 2.5243 - val_acc: 0.5537\n",
            "Epoch 150/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0607 - acc: 0.9804 - val_loss: 2.5539 - val_acc: 0.5579\n",
            "Epoch 151/1000\n",
            "967/967 [==============================] - 0s 506us/sample - loss: 0.0501 - acc: 0.9876 - val_loss: 2.5704 - val_acc: 0.5661\n",
            "Epoch 152/1000\n",
            "967/967 [==============================] - 1s 582us/sample - loss: 0.0447 - acc: 0.9897 - val_loss: 2.5922 - val_acc: 0.5620\n",
            "Epoch 153/1000\n",
            "967/967 [==============================] - 1s 555us/sample - loss: 0.0372 - acc: 0.9876 - val_loss: 2.5808 - val_acc: 0.5537\n",
            "Epoch 154/1000\n",
            "967/967 [==============================] - 1s 560us/sample - loss: 0.0697 - acc: 0.9793 - val_loss: 2.5496 - val_acc: 0.5661\n",
            "Epoch 155/1000\n",
            "967/967 [==============================] - 1s 652us/sample - loss: 0.0219 - acc: 0.9938 - val_loss: 2.6017 - val_acc: 0.5744\n",
            "Epoch 156/1000\n",
            "967/967 [==============================] - 0s 512us/sample - loss: 0.0413 - acc: 0.9876 - val_loss: 2.6218 - val_acc: 0.5744\n",
            "Epoch 157/1000\n",
            "967/967 [==============================] - 1s 524us/sample - loss: 0.0561 - acc: 0.9814 - val_loss: 2.6393 - val_acc: 0.5702\n",
            "Epoch 158/1000\n",
            "967/967 [==============================] - 1s 520us/sample - loss: 0.0362 - acc: 0.9886 - val_loss: 2.6040 - val_acc: 0.5455\n",
            "Epoch 159/1000\n",
            "967/967 [==============================] - 1s 568us/sample - loss: 0.0647 - acc: 0.9876 - val_loss: 2.5863 - val_acc: 0.5702\n",
            "Epoch 160/1000\n",
            "967/967 [==============================] - 1s 566us/sample - loss: 0.0516 - acc: 0.9845 - val_loss: 2.6102 - val_acc: 0.5661\n",
            "Epoch 161/1000\n",
            "967/967 [==============================] - 1s 519us/sample - loss: 0.0417 - acc: 0.9835 - val_loss: 2.6089 - val_acc: 0.5455\n",
            "Epoch 162/1000\n",
            "967/967 [==============================] - 1s 562us/sample - loss: 0.0471 - acc: 0.9845 - val_loss: 2.6229 - val_acc: 0.5496\n",
            "Epoch 163/1000\n",
            "967/967 [==============================] - 1s 567us/sample - loss: 0.0318 - acc: 0.9886 - val_loss: 2.6257 - val_acc: 0.5455\n",
            "Epoch 164/1000\n",
            "967/967 [==============================] - 1s 584us/sample - loss: 0.0416 - acc: 0.9866 - val_loss: 2.6445 - val_acc: 0.5372\n",
            "Epoch 165/1000\n",
            "967/967 [==============================] - 1s 606us/sample - loss: 0.0394 - acc: 0.9824 - val_loss: 2.6154 - val_acc: 0.5620\n",
            "Epoch 166/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0442 - acc: 0.9866 - val_loss: 2.6050 - val_acc: 0.5579\n",
            "Epoch 167/1000\n",
            "967/967 [==============================] - 1s 607us/sample - loss: 0.0578 - acc: 0.9897 - val_loss: 2.6243 - val_acc: 0.5620\n",
            "Epoch 168/1000\n",
            "967/967 [==============================] - 1s 598us/sample - loss: 0.0372 - acc: 0.9814 - val_loss: 2.5978 - val_acc: 0.5579\n",
            "Epoch 169/1000\n",
            "967/967 [==============================] - 0s 503us/sample - loss: 0.0578 - acc: 0.9876 - val_loss: 2.5555 - val_acc: 0.5620\n",
            "Epoch 170/1000\n",
            "967/967 [==============================] - 0s 499us/sample - loss: 0.0268 - acc: 0.9917 - val_loss: 2.5636 - val_acc: 0.5537\n",
            "Epoch 171/1000\n",
            "967/967 [==============================] - 0s 501us/sample - loss: 0.0729 - acc: 0.9824 - val_loss: 2.5463 - val_acc: 0.5537\n",
            "Epoch 172/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0347 - acc: 0.9897 - val_loss: 2.5114 - val_acc: 0.5496\n",
            "Epoch 173/1000\n",
            "967/967 [==============================] - 1s 598us/sample - loss: 0.0305 - acc: 0.9897 - val_loss: 2.4919 - val_acc: 0.5579\n",
            "Epoch 174/1000\n",
            "967/967 [==============================] - 1s 611us/sample - loss: 0.0391 - acc: 0.9917 - val_loss: 2.5119 - val_acc: 0.5620\n",
            "Epoch 175/1000\n",
            "967/967 [==============================] - 1s 526us/sample - loss: 0.0754 - acc: 0.9814 - val_loss: 2.5082 - val_acc: 0.5661\n",
            "Epoch 176/1000\n",
            "967/967 [==============================] - 1s 585us/sample - loss: 0.0451 - acc: 0.9835 - val_loss: 2.5049 - val_acc: 0.5702\n",
            "Epoch 177/1000\n",
            "967/967 [==============================] - 1s 601us/sample - loss: 0.0486 - acc: 0.9804 - val_loss: 2.4871 - val_acc: 0.5661\n",
            "Epoch 178/1000\n",
            "967/967 [==============================] - 0s 500us/sample - loss: 0.0449 - acc: 0.9824 - val_loss: 2.5137 - val_acc: 0.5661\n",
            "Epoch 179/1000\n",
            "967/967 [==============================] - 1s 564us/sample - loss: 0.0562 - acc: 0.9824 - val_loss: 2.5247 - val_acc: 0.5537\n",
            "Epoch 180/1000\n",
            "967/967 [==============================] - 1s 633us/sample - loss: 0.0293 - acc: 0.9876 - val_loss: 2.5614 - val_acc: 0.5744\n",
            "Epoch 181/1000\n",
            "967/967 [==============================] - 1s 531us/sample - loss: 0.0602 - acc: 0.9804 - val_loss: 2.5444 - val_acc: 0.5950\n",
            "Epoch 182/1000\n",
            "967/967 [==============================] - 1s 562us/sample - loss: 0.0340 - acc: 0.9886 - val_loss: 2.5262 - val_acc: 0.5826\n",
            "Epoch 183/1000\n",
            "967/967 [==============================] - 1s 572us/sample - loss: 0.0529 - acc: 0.9855 - val_loss: 2.5287 - val_acc: 0.5661\n",
            "Epoch 184/1000\n",
            "967/967 [==============================] - 1s 560us/sample - loss: 0.0521 - acc: 0.9824 - val_loss: 2.4886 - val_acc: 0.5702\n",
            "Epoch 185/1000\n",
            "967/967 [==============================] - 1s 602us/sample - loss: 0.0561 - acc: 0.9783 - val_loss: 2.5026 - val_acc: 0.5702\n",
            "Epoch 186/1000\n",
            "967/967 [==============================] - 0s 508us/sample - loss: 0.0406 - acc: 0.9855 - val_loss: 2.5346 - val_acc: 0.5702\n",
            "Epoch 187/1000\n",
            "967/967 [==============================] - 1s 551us/sample - loss: 0.0254 - acc: 0.9907 - val_loss: 2.5612 - val_acc: 0.5620\n",
            "Epoch 188/1000\n",
            "967/967 [==============================] - 0s 516us/sample - loss: 0.0495 - acc: 0.9855 - val_loss: 2.5787 - val_acc: 0.5579\n",
            "Epoch 189/1000\n",
            "967/967 [==============================] - 1s 543us/sample - loss: 0.0575 - acc: 0.9835 - val_loss: 2.5657 - val_acc: 0.5579\n",
            "Epoch 190/1000\n",
            "967/967 [==============================] - 1s 650us/sample - loss: 0.0587 - acc: 0.9772 - val_loss: 2.5670 - val_acc: 0.5744\n",
            "Epoch 191/1000\n",
            "967/967 [==============================] - 1s 615us/sample - loss: 0.0458 - acc: 0.9876 - val_loss: 2.5467 - val_acc: 0.5785\n",
            "Epoch 192/1000\n",
            "967/967 [==============================] - 1s 571us/sample - loss: 0.0686 - acc: 0.9814 - val_loss: 2.5455 - val_acc: 0.5744\n",
            "Epoch 193/1000\n",
            "967/967 [==============================] - 1s 562us/sample - loss: 0.0475 - acc: 0.9845 - val_loss: 2.5569 - val_acc: 0.5661\n",
            "Epoch 194/1000\n",
            "967/967 [==============================] - 1s 601us/sample - loss: 0.0540 - acc: 0.9855 - val_loss: 2.5548 - val_acc: 0.5702\n",
            "Epoch 195/1000\n",
            "967/967 [==============================] - 1s 587us/sample - loss: 0.0531 - acc: 0.9804 - val_loss: 2.5807 - val_acc: 0.5702\n",
            "Epoch 196/1000\n",
            "967/967 [==============================] - 0s 516us/sample - loss: 0.0404 - acc: 0.9886 - val_loss: 2.5928 - val_acc: 0.5579\n",
            "Epoch 197/1000\n",
            "967/967 [==============================] - 0s 516us/sample - loss: 0.0444 - acc: 0.9855 - val_loss: 2.5920 - val_acc: 0.5702\n",
            "Epoch 198/1000\n",
            "967/967 [==============================] - 1s 580us/sample - loss: 0.0571 - acc: 0.9824 - val_loss: 2.5758 - val_acc: 0.5620\n",
            "Epoch 199/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0684 - acc: 0.9845 - val_loss: 2.5380 - val_acc: 0.5744\n",
            "Epoch 200/1000\n",
            "967/967 [==============================] - 1s 550us/sample - loss: 0.0408 - acc: 0.9866 - val_loss: 2.5589 - val_acc: 0.5661\n",
            "Epoch 201/1000\n",
            "967/967 [==============================] - 1s 519us/sample - loss: 0.0573 - acc: 0.9804 - val_loss: 2.5336 - val_acc: 0.5620\n",
            "Epoch 202/1000\n",
            "967/967 [==============================] - 1s 520us/sample - loss: 0.0402 - acc: 0.9845 - val_loss: 2.5307 - val_acc: 0.5702\n",
            "Epoch 203/1000\n",
            "967/967 [==============================] - 0s 508us/sample - loss: 0.0339 - acc: 0.9886 - val_loss: 2.5375 - val_acc: 0.5785\n",
            "Epoch 204/1000\n",
            "967/967 [==============================] - 1s 597us/sample - loss: 0.0432 - acc: 0.9855 - val_loss: 2.5325 - val_acc: 0.5826\n",
            "Epoch 205/1000\n",
            "967/967 [==============================] - 1s 561us/sample - loss: 0.0551 - acc: 0.9814 - val_loss: 2.5337 - val_acc: 0.5868\n",
            "Epoch 206/1000\n",
            "967/967 [==============================] - 1s 565us/sample - loss: 0.0542 - acc: 0.9824 - val_loss: 2.5250 - val_acc: 0.5785\n",
            "Epoch 207/1000\n",
            "967/967 [==============================] - 1s 641us/sample - loss: 0.0225 - acc: 0.9948 - val_loss: 2.5087 - val_acc: 0.5826\n",
            "Epoch 208/1000\n",
            "967/967 [==============================] - 1s 559us/sample - loss: 0.0798 - acc: 0.9762 - val_loss: 2.4824 - val_acc: 0.5661\n",
            "Epoch 209/1000\n",
            "967/967 [==============================] - 1s 588us/sample - loss: 0.0227 - acc: 0.9948 - val_loss: 2.5363 - val_acc: 0.5620\n",
            "Epoch 210/1000\n",
            "967/967 [==============================] - 0s 500us/sample - loss: 0.0335 - acc: 0.9907 - val_loss: 2.5323 - val_acc: 0.5661\n",
            "Epoch 211/1000\n",
            "967/967 [==============================] - 0s 493us/sample - loss: 0.0312 - acc: 0.9876 - val_loss: 2.5426 - val_acc: 0.5579\n",
            "Epoch 212/1000\n",
            "967/967 [==============================] - 0s 485us/sample - loss: 0.0384 - acc: 0.9866 - val_loss: 2.5582 - val_acc: 0.5661\n",
            "Epoch 213/1000\n",
            "967/967 [==============================] - 1s 568us/sample - loss: 0.0353 - acc: 0.9897 - val_loss: 2.5791 - val_acc: 0.5744\n",
            "Epoch 214/1000\n",
            "967/967 [==============================] - 1s 534us/sample - loss: 0.0331 - acc: 0.9866 - val_loss: 2.5701 - val_acc: 0.5785\n",
            "Epoch 215/1000\n",
            "967/967 [==============================] - 0s 507us/sample - loss: 0.0605 - acc: 0.9793 - val_loss: 2.6101 - val_acc: 0.5702\n",
            "Epoch 216/1000\n",
            "967/967 [==============================] - 1s 614us/sample - loss: 0.0552 - acc: 0.9783 - val_loss: 2.5967 - val_acc: 0.5785\n",
            "Epoch 217/1000\n",
            "967/967 [==============================] - 1s 560us/sample - loss: 0.0590 - acc: 0.9824 - val_loss: 2.5709 - val_acc: 0.5826\n",
            "Epoch 218/1000\n",
            "967/967 [==============================] - 1s 558us/sample - loss: 0.0540 - acc: 0.9824 - val_loss: 2.5356 - val_acc: 0.5785\n",
            "Epoch 219/1000\n",
            "967/967 [==============================] - 1s 648us/sample - loss: 0.0266 - acc: 0.9907 - val_loss: 2.5325 - val_acc: 0.5826\n",
            "Epoch 220/1000\n",
            "967/967 [==============================] - 1s 573us/sample - loss: 0.0509 - acc: 0.9866 - val_loss: 2.5302 - val_acc: 0.5702\n",
            "Epoch 221/1000\n",
            "967/967 [==============================] - 0s 504us/sample - loss: 0.0391 - acc: 0.9897 - val_loss: 2.5487 - val_acc: 0.5661\n",
            "Epoch 222/1000\n",
            "967/967 [==============================] - 1s 590us/sample - loss: 0.0644 - acc: 0.9886 - val_loss: 2.5704 - val_acc: 0.5992\n",
            "Epoch 223/1000\n",
            "967/967 [==============================] - 1s 557us/sample - loss: 0.0681 - acc: 0.9793 - val_loss: 2.5316 - val_acc: 0.5950\n",
            "Epoch 224/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0324 - acc: 0.9907 - val_loss: 2.5256 - val_acc: 0.5992\n",
            "Epoch 225/1000\n",
            "967/967 [==============================] - 1s 538us/sample - loss: 0.0584 - acc: 0.9824 - val_loss: 2.5010 - val_acc: 0.5909\n",
            "Epoch 226/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0438 - acc: 0.9824 - val_loss: 2.5009 - val_acc: 0.5950\n",
            "Epoch 227/1000\n",
            "967/967 [==============================] - 1s 557us/sample - loss: 0.0312 - acc: 0.9866 - val_loss: 2.5305 - val_acc: 0.5950\n",
            "Epoch 228/1000\n",
            "967/967 [==============================] - 1s 580us/sample - loss: 0.0346 - acc: 0.9855 - val_loss: 2.5661 - val_acc: 0.5950\n",
            "Epoch 229/1000\n",
            "967/967 [==============================] - 1s 606us/sample - loss: 0.0526 - acc: 0.9876 - val_loss: 2.5645 - val_acc: 0.6033\n",
            "Epoch 230/1000\n",
            "967/967 [==============================] - 1s 567us/sample - loss: 0.0568 - acc: 0.9824 - val_loss: 2.5705 - val_acc: 0.5826\n",
            "Epoch 231/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0315 - acc: 0.9866 - val_loss: 2.5654 - val_acc: 0.5950\n",
            "Epoch 232/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0510 - acc: 0.9814 - val_loss: 2.5304 - val_acc: 0.5826\n",
            "Epoch 233/1000\n",
            "967/967 [==============================] - 1s 577us/sample - loss: 0.0349 - acc: 0.9917 - val_loss: 2.5488 - val_acc: 0.5702\n",
            "Epoch 234/1000\n",
            "967/967 [==============================] - 1s 621us/sample - loss: 0.0428 - acc: 0.9855 - val_loss: 2.5551 - val_acc: 0.5785\n",
            "Epoch 235/1000\n",
            "967/967 [==============================] - 1s 631us/sample - loss: 0.0469 - acc: 0.9845 - val_loss: 2.5508 - val_acc: 0.5868\n",
            "Epoch 236/1000\n",
            "967/967 [==============================] - 1s 526us/sample - loss: 0.0384 - acc: 0.9876 - val_loss: 2.5228 - val_acc: 0.5868\n",
            "Epoch 237/1000\n",
            "967/967 [==============================] - 1s 553us/sample - loss: 0.0432 - acc: 0.9866 - val_loss: 2.5478 - val_acc: 0.5826\n",
            "Epoch 238/1000\n",
            "967/967 [==============================] - 1s 581us/sample - loss: 0.0652 - acc: 0.9824 - val_loss: 2.5620 - val_acc: 0.5785\n",
            "Epoch 239/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0578 - acc: 0.9855 - val_loss: 2.5804 - val_acc: 0.5702\n",
            "Epoch 240/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0440 - acc: 0.9835 - val_loss: 2.5810 - val_acc: 0.5744\n",
            "Epoch 241/1000\n",
            "967/967 [==============================] - 1s 573us/sample - loss: 0.0500 - acc: 0.9804 - val_loss: 2.5683 - val_acc: 0.5579\n",
            "Epoch 242/1000\n",
            "967/967 [==============================] - 1s 567us/sample - loss: 0.0563 - acc: 0.9793 - val_loss: 2.5716 - val_acc: 0.5702\n",
            "Epoch 243/1000\n",
            "967/967 [==============================] - 1s 591us/sample - loss: 0.0531 - acc: 0.9824 - val_loss: 2.5725 - val_acc: 0.5744\n",
            "Epoch 244/1000\n",
            "967/967 [==============================] - 1s 609us/sample - loss: 0.0625 - acc: 0.9772 - val_loss: 2.5885 - val_acc: 0.5661\n",
            "Epoch 245/1000\n",
            "967/967 [==============================] - 1s 597us/sample - loss: 0.0333 - acc: 0.9907 - val_loss: 2.5997 - val_acc: 0.5785\n",
            "Epoch 246/1000\n",
            "967/967 [==============================] - 1s 583us/sample - loss: 0.0450 - acc: 0.9866 - val_loss: 2.5894 - val_acc: 0.5661\n",
            "Epoch 247/1000\n",
            "967/967 [==============================] - 1s 614us/sample - loss: 0.0474 - acc: 0.9845 - val_loss: 2.5820 - val_acc: 0.5661\n",
            "Epoch 248/1000\n",
            "967/967 [==============================] - 1s 566us/sample - loss: 0.0407 - acc: 0.9897 - val_loss: 2.6054 - val_acc: 0.5744\n",
            "Epoch 249/1000\n",
            "967/967 [==============================] - 0s 514us/sample - loss: 0.0474 - acc: 0.9824 - val_loss: 2.5969 - val_acc: 0.5579\n",
            "Epoch 250/1000\n",
            "967/967 [==============================] - 1s 563us/sample - loss: 0.0554 - acc: 0.9835 - val_loss: 2.6371 - val_acc: 0.5661\n",
            "Epoch 251/1000\n",
            "967/967 [==============================] - 1s 581us/sample - loss: 0.0332 - acc: 0.9855 - val_loss: 2.6405 - val_acc: 0.5702\n",
            "Epoch 252/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0460 - acc: 0.9845 - val_loss: 2.6282 - val_acc: 0.5620\n",
            "Epoch 253/1000\n",
            "967/967 [==============================] - 1s 587us/sample - loss: 0.0457 - acc: 0.9835 - val_loss: 2.6324 - val_acc: 0.5620\n",
            "Epoch 254/1000\n",
            "967/967 [==============================] - 1s 649us/sample - loss: 0.0418 - acc: 0.9845 - val_loss: 2.6108 - val_acc: 0.5661\n",
            "Epoch 255/1000\n",
            "967/967 [==============================] - 1s 627us/sample - loss: 0.0614 - acc: 0.9845 - val_loss: 2.6169 - val_acc: 0.5579\n",
            "Epoch 256/1000\n",
            "967/967 [==============================] - 1s 542us/sample - loss: 0.0580 - acc: 0.9804 - val_loss: 2.5940 - val_acc: 0.5537\n",
            "Epoch 257/1000\n",
            "967/967 [==============================] - 1s 549us/sample - loss: 0.0681 - acc: 0.9793 - val_loss: 2.5844 - val_acc: 0.5661\n",
            "Epoch 258/1000\n",
            "967/967 [==============================] - 0s 510us/sample - loss: 0.0432 - acc: 0.9866 - val_loss: 2.5613 - val_acc: 0.5702\n",
            "Epoch 259/1000\n",
            "967/967 [==============================] - 1s 559us/sample - loss: 0.0625 - acc: 0.9855 - val_loss: 2.5403 - val_acc: 0.5702\n",
            "Epoch 260/1000\n",
            "967/967 [==============================] - 0s 488us/sample - loss: 0.0494 - acc: 0.9876 - val_loss: 2.5428 - val_acc: 0.5702\n",
            "Epoch 261/1000\n",
            "967/967 [==============================] - 1s 569us/sample - loss: 0.0487 - acc: 0.9814 - val_loss: 2.5404 - val_acc: 0.5909\n",
            "Epoch 262/1000\n",
            "967/967 [==============================] - 1s 597us/sample - loss: 0.0485 - acc: 0.9824 - val_loss: 2.5361 - val_acc: 0.5868\n",
            "Epoch 263/1000\n",
            "967/967 [==============================] - 1s 559us/sample - loss: 0.0240 - acc: 0.9897 - val_loss: 2.5478 - val_acc: 0.5909\n",
            "Epoch 264/1000\n",
            "967/967 [==============================] - 1s 572us/sample - loss: 0.0276 - acc: 0.9897 - val_loss: 2.5860 - val_acc: 0.5868\n",
            "Epoch 265/1000\n",
            "967/967 [==============================] - 1s 572us/sample - loss: 0.0253 - acc: 0.9928 - val_loss: 2.6503 - val_acc: 0.5868\n",
            "Epoch 266/1000\n",
            "967/967 [==============================] - 1s 612us/sample - loss: 0.0452 - acc: 0.9845 - val_loss: 2.6372 - val_acc: 0.5826\n",
            "Epoch 267/1000\n",
            "967/967 [==============================] - 1s 561us/sample - loss: 0.0450 - acc: 0.9866 - val_loss: 2.6253 - val_acc: 0.5950\n",
            "Epoch 268/1000\n",
            "967/967 [==============================] - 1s 621us/sample - loss: 0.0316 - acc: 0.9876 - val_loss: 2.6436 - val_acc: 0.6033\n",
            "Epoch 269/1000\n",
            "967/967 [==============================] - 1s 605us/sample - loss: 0.0585 - acc: 0.9845 - val_loss: 2.6703 - val_acc: 0.6074\n",
            "Epoch 270/1000\n",
            "967/967 [==============================] - 1s 605us/sample - loss: 0.0379 - acc: 0.9866 - val_loss: 2.6743 - val_acc: 0.6033\n",
            "Epoch 271/1000\n",
            "967/967 [==============================] - 1s 629us/sample - loss: 0.0442 - acc: 0.9855 - val_loss: 2.6386 - val_acc: 0.6033\n",
            "Epoch 272/1000\n",
            "967/967 [==============================] - 1s 553us/sample - loss: 0.0418 - acc: 0.9845 - val_loss: 2.6676 - val_acc: 0.5950\n",
            "Epoch 273/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0485 - acc: 0.9845 - val_loss: 2.6194 - val_acc: 0.5826\n",
            "Epoch 274/1000\n",
            "967/967 [==============================] - 1s 582us/sample - loss: 0.0514 - acc: 0.9866 - val_loss: 2.6248 - val_acc: 0.5868\n",
            "Epoch 275/1000\n",
            "967/967 [==============================] - 1s 642us/sample - loss: 0.0443 - acc: 0.9876 - val_loss: 2.6351 - val_acc: 0.5826\n",
            "Epoch 276/1000\n",
            "967/967 [==============================] - 1s 553us/sample - loss: 0.0479 - acc: 0.9917 - val_loss: 2.6366 - val_acc: 0.5661\n",
            "Epoch 277/1000\n",
            "967/967 [==============================] - 1s 537us/sample - loss: 0.0212 - acc: 0.9897 - val_loss: 2.6171 - val_acc: 0.5744\n",
            "Epoch 278/1000\n",
            "967/967 [==============================] - 1s 558us/sample - loss: 0.0380 - acc: 0.9876 - val_loss: 2.6592 - val_acc: 0.5785\n",
            "Epoch 279/1000\n",
            "967/967 [==============================] - 1s 636us/sample - loss: 0.0364 - acc: 0.9855 - val_loss: 2.6710 - val_acc: 0.5826\n",
            "Epoch 280/1000\n",
            "967/967 [==============================] - 1s 598us/sample - loss: 0.0643 - acc: 0.9814 - val_loss: 2.6725 - val_acc: 0.5785\n",
            "Epoch 281/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0638 - acc: 0.9804 - val_loss: 2.6842 - val_acc: 0.5826\n",
            "Epoch 282/1000\n",
            "967/967 [==============================] - 1s 534us/sample - loss: 0.0689 - acc: 0.9855 - val_loss: 2.6922 - val_acc: 0.5826\n",
            "Epoch 283/1000\n",
            "967/967 [==============================] - 1s 560us/sample - loss: 0.0549 - acc: 0.9824 - val_loss: 2.6756 - val_acc: 0.5785\n",
            "Epoch 284/1000\n",
            "967/967 [==============================] - 1s 534us/sample - loss: 0.0262 - acc: 0.9917 - val_loss: 2.6612 - val_acc: 0.5702\n",
            "Epoch 285/1000\n",
            "967/967 [==============================] - 0s 508us/sample - loss: 0.0492 - acc: 0.9886 - val_loss: 2.6839 - val_acc: 0.5868\n",
            "Epoch 286/1000\n",
            "967/967 [==============================] - 1s 593us/sample - loss: 0.0334 - acc: 0.9845 - val_loss: 2.6798 - val_acc: 0.5826\n",
            "Epoch 287/1000\n",
            "967/967 [==============================] - 1s 549us/sample - loss: 0.0666 - acc: 0.9793 - val_loss: 2.6538 - val_acc: 0.5992\n",
            "Epoch 288/1000\n",
            "967/967 [==============================] - 1s 668us/sample - loss: 0.0634 - acc: 0.9824 - val_loss: 2.6668 - val_acc: 0.5909\n",
            "Epoch 289/1000\n",
            "967/967 [==============================] - 0s 484us/sample - loss: 0.0450 - acc: 0.9845 - val_loss: 2.6747 - val_acc: 0.5868\n",
            "Epoch 290/1000\n",
            "967/967 [==============================] - 0s 473us/sample - loss: 0.0345 - acc: 0.9876 - val_loss: 2.7038 - val_acc: 0.5826\n",
            "Epoch 291/1000\n",
            "967/967 [==============================] - 0s 510us/sample - loss: 0.0308 - acc: 0.9866 - val_loss: 2.7223 - val_acc: 0.5868\n",
            "Epoch 292/1000\n",
            "967/967 [==============================] - 0s 510us/sample - loss: 0.0477 - acc: 0.9866 - val_loss: 2.7393 - val_acc: 0.5992\n",
            "Epoch 293/1000\n",
            "967/967 [==============================] - 1s 559us/sample - loss: 0.0719 - acc: 0.9762 - val_loss: 2.6567 - val_acc: 0.5909\n",
            "Epoch 294/1000\n",
            "967/967 [==============================] - 1s 565us/sample - loss: 0.0625 - acc: 0.9814 - val_loss: 2.6124 - val_acc: 0.5950\n",
            "Epoch 295/1000\n",
            "967/967 [==============================] - 1s 519us/sample - loss: 0.0420 - acc: 0.9886 - val_loss: 2.6242 - val_acc: 0.6033\n",
            "Epoch 296/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0356 - acc: 0.9855 - val_loss: 2.6111 - val_acc: 0.5785\n",
            "Epoch 297/1000\n",
            "967/967 [==============================] - 1s 589us/sample - loss: 0.0303 - acc: 0.9907 - val_loss: 2.6784 - val_acc: 0.5785\n",
            "Epoch 298/1000\n",
            "967/967 [==============================] - 1s 592us/sample - loss: 0.0831 - acc: 0.9824 - val_loss: 2.6568 - val_acc: 0.5950\n",
            "Epoch 299/1000\n",
            "967/967 [==============================] - 1s 621us/sample - loss: 0.0366 - acc: 0.9855 - val_loss: 2.6328 - val_acc: 0.5826\n",
            "Epoch 300/1000\n",
            "967/967 [==============================] - 1s 576us/sample - loss: 0.0417 - acc: 0.9835 - val_loss: 2.6201 - val_acc: 0.5909\n",
            "Epoch 301/1000\n",
            "967/967 [==============================] - 1s 575us/sample - loss: 0.0336 - acc: 0.9876 - val_loss: 2.6737 - val_acc: 0.5909\n",
            "Epoch 302/1000\n",
            "967/967 [==============================] - 1s 533us/sample - loss: 0.0429 - acc: 0.9845 - val_loss: 2.6660 - val_acc: 0.5826\n",
            "Epoch 303/1000\n",
            "967/967 [==============================] - 0s 495us/sample - loss: 0.0244 - acc: 0.9928 - val_loss: 2.6717 - val_acc: 0.5744\n",
            "Epoch 304/1000\n",
            "967/967 [==============================] - 1s 589us/sample - loss: 0.0510 - acc: 0.9835 - val_loss: 2.6541 - val_acc: 0.5744\n",
            "Epoch 305/1000\n",
            "967/967 [==============================] - 0s 496us/sample - loss: 0.0496 - acc: 0.9835 - val_loss: 2.6936 - val_acc: 0.5826\n",
            "Epoch 306/1000\n",
            "967/967 [==============================] - 1s 544us/sample - loss: 0.0435 - acc: 0.9876 - val_loss: 2.6962 - val_acc: 0.5702\n",
            "Epoch 307/1000\n",
            "967/967 [==============================] - 0s 509us/sample - loss: 0.0665 - acc: 0.9804 - val_loss: 2.6794 - val_acc: 0.5826\n",
            "Epoch 308/1000\n",
            "967/967 [==============================] - 1s 544us/sample - loss: 0.0294 - acc: 0.9917 - val_loss: 2.6669 - val_acc: 0.5744\n",
            "Epoch 309/1000\n",
            "967/967 [==============================] - 1s 586us/sample - loss: 0.0523 - acc: 0.9824 - val_loss: 2.6548 - val_acc: 0.5826\n",
            "Epoch 310/1000\n",
            "967/967 [==============================] - 1s 525us/sample - loss: 0.0696 - acc: 0.9772 - val_loss: 2.6611 - val_acc: 0.5826\n",
            "Epoch 311/1000\n",
            "967/967 [==============================] - 1s 524us/sample - loss: 0.0498 - acc: 0.9814 - val_loss: 2.6734 - val_acc: 0.5826\n",
            "Epoch 312/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0405 - acc: 0.9876 - val_loss: 2.6671 - val_acc: 0.5868\n",
            "Epoch 313/1000\n",
            "967/967 [==============================] - 1s 517us/sample - loss: 0.0405 - acc: 0.9824 - val_loss: 2.6880 - val_acc: 0.5868\n",
            "Epoch 314/1000\n",
            "967/967 [==============================] - 1s 561us/sample - loss: 0.0272 - acc: 0.9907 - val_loss: 2.7212 - val_acc: 0.5785\n",
            "Epoch 315/1000\n",
            "967/967 [==============================] - 1s 562us/sample - loss: 0.0432 - acc: 0.9876 - val_loss: 2.7040 - val_acc: 0.5868\n",
            "Epoch 316/1000\n",
            "967/967 [==============================] - 1s 543us/sample - loss: 0.0409 - acc: 0.9845 - val_loss: 2.6930 - val_acc: 0.5909\n",
            "Epoch 317/1000\n",
            "967/967 [==============================] - 0s 476us/sample - loss: 0.0435 - acc: 0.9824 - val_loss: 2.7051 - val_acc: 0.5868\n",
            "Epoch 318/1000\n",
            "967/967 [==============================] - 1s 562us/sample - loss: 0.0750 - acc: 0.9793 - val_loss: 2.7184 - val_acc: 0.5909\n",
            "Epoch 319/1000\n",
            "967/967 [==============================] - 1s 550us/sample - loss: 0.0687 - acc: 0.9835 - val_loss: 2.7443 - val_acc: 0.5909\n",
            "Epoch 320/1000\n",
            "967/967 [==============================] - 1s 560us/sample - loss: 0.0251 - acc: 0.9876 - val_loss: 2.7328 - val_acc: 0.5909\n",
            "Epoch 321/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0600 - acc: 0.9897 - val_loss: 2.6782 - val_acc: 0.5826\n",
            "Epoch 322/1000\n",
            "967/967 [==============================] - 1s 587us/sample - loss: 0.0279 - acc: 0.9886 - val_loss: 2.6330 - val_acc: 0.5826\n",
            "Epoch 323/1000\n",
            "967/967 [==============================] - 1s 568us/sample - loss: 0.0606 - acc: 0.9835 - val_loss: 2.6480 - val_acc: 0.5785\n",
            "Epoch 324/1000\n",
            "967/967 [==============================] - 1s 539us/sample - loss: 0.0451 - acc: 0.9866 - val_loss: 2.6766 - val_acc: 0.5744\n",
            "Epoch 325/1000\n",
            "967/967 [==============================] - 0s 513us/sample - loss: 0.0378 - acc: 0.9876 - val_loss: 2.7020 - val_acc: 0.5785\n",
            "Epoch 326/1000\n",
            "967/967 [==============================] - 1s 529us/sample - loss: 0.0224 - acc: 0.9917 - val_loss: 2.7020 - val_acc: 0.5826\n",
            "Epoch 327/1000\n",
            "967/967 [==============================] - 0s 504us/sample - loss: 0.0514 - acc: 0.9835 - val_loss: 2.7371 - val_acc: 0.5909\n",
            "Epoch 328/1000\n",
            "967/967 [==============================] - 1s 527us/sample - loss: 0.0407 - acc: 0.9855 - val_loss: 2.7069 - val_acc: 0.5868\n",
            "Epoch 329/1000\n",
            "967/967 [==============================] - 1s 523us/sample - loss: 0.0325 - acc: 0.9855 - val_loss: 2.7614 - val_acc: 0.5826\n",
            "Epoch 330/1000\n",
            "967/967 [==============================] - 1s 577us/sample - loss: 0.0809 - acc: 0.9866 - val_loss: 2.7705 - val_acc: 0.5744\n",
            "Epoch 331/1000\n",
            "967/967 [==============================] - 1s 555us/sample - loss: 0.0393 - acc: 0.9835 - val_loss: 2.7601 - val_acc: 0.5826\n",
            "Epoch 332/1000\n",
            "967/967 [==============================] - 1s 580us/sample - loss: 0.0619 - acc: 0.9855 - val_loss: 2.7320 - val_acc: 0.5702\n",
            "Epoch 333/1000\n",
            "967/967 [==============================] - 1s 565us/sample - loss: 0.0353 - acc: 0.9907 - val_loss: 2.7099 - val_acc: 0.5702\n",
            "Epoch 334/1000\n",
            "967/967 [==============================] - 1s 521us/sample - loss: 0.0466 - acc: 0.9845 - val_loss: 2.6786 - val_acc: 0.5785\n",
            "Epoch 335/1000\n",
            "967/967 [==============================] - 1s 569us/sample - loss: 0.0588 - acc: 0.9845 - val_loss: 2.6497 - val_acc: 0.5702\n",
            "Epoch 336/1000\n",
            "967/967 [==============================] - 1s 581us/sample - loss: 0.0417 - acc: 0.9835 - val_loss: 2.6625 - val_acc: 0.5702\n",
            "Epoch 337/1000\n",
            "967/967 [==============================] - 1s 589us/sample - loss: 0.0721 - acc: 0.9752 - val_loss: 2.6054 - val_acc: 0.5868\n",
            "Epoch 338/1000\n",
            "967/967 [==============================] - 1s 561us/sample - loss: 0.0366 - acc: 0.9886 - val_loss: 2.5966 - val_acc: 0.5702\n",
            "Epoch 339/1000\n",
            "967/967 [==============================] - 1s 599us/sample - loss: 0.0593 - acc: 0.9866 - val_loss: 2.6077 - val_acc: 0.5785\n",
            "Epoch 340/1000\n",
            "967/967 [==============================] - 1s 568us/sample - loss: 0.0217 - acc: 0.9948 - val_loss: 2.6157 - val_acc: 0.5826\n",
            "Epoch 341/1000\n",
            "967/967 [==============================] - 1s 595us/sample - loss: 0.0438 - acc: 0.9855 - val_loss: 2.6292 - val_acc: 0.5826\n",
            "Epoch 342/1000\n",
            "967/967 [==============================] - 1s 588us/sample - loss: 0.0489 - acc: 0.9855 - val_loss: 2.6416 - val_acc: 0.5826\n",
            "Epoch 343/1000\n",
            "967/967 [==============================] - 1s 558us/sample - loss: 0.0271 - acc: 0.9886 - val_loss: 2.6551 - val_acc: 0.5702\n",
            "Epoch 344/1000\n",
            "967/967 [==============================] - 1s 553us/sample - loss: 0.0356 - acc: 0.9907 - val_loss: 2.6594 - val_acc: 0.5579\n",
            "Epoch 345/1000\n",
            "967/967 [==============================] - 1s 542us/sample - loss: 0.0397 - acc: 0.9876 - val_loss: 2.6408 - val_acc: 0.5785\n",
            "Epoch 346/1000\n",
            "967/967 [==============================] - 1s 619us/sample - loss: 0.0312 - acc: 0.9938 - val_loss: 2.6613 - val_acc: 0.5868\n",
            "Epoch 347/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0274 - acc: 0.9917 - val_loss: 2.6289 - val_acc: 0.5744\n",
            "Epoch 348/1000\n",
            "967/967 [==============================] - 1s 535us/sample - loss: 0.0408 - acc: 0.9855 - val_loss: 2.6254 - val_acc: 0.5950\n",
            "Epoch 349/1000\n",
            "967/967 [==============================] - 1s 551us/sample - loss: 0.0399 - acc: 0.9886 - val_loss: 2.6441 - val_acc: 0.5785\n",
            "Epoch 350/1000\n",
            "967/967 [==============================] - 1s 613us/sample - loss: 0.0469 - acc: 0.9814 - val_loss: 2.6312 - val_acc: 0.5826\n",
            "Epoch 351/1000\n",
            "967/967 [==============================] - 1s 596us/sample - loss: 0.0416 - acc: 0.9804 - val_loss: 2.6473 - val_acc: 0.5744\n",
            "Epoch 352/1000\n",
            "967/967 [==============================] - 1s 534us/sample - loss: 0.0575 - acc: 0.9886 - val_loss: 2.6338 - val_acc: 0.5661\n",
            "Epoch 353/1000\n",
            "967/967 [==============================] - 1s 594us/sample - loss: 0.0381 - acc: 0.9907 - val_loss: 2.6498 - val_acc: 0.5661\n",
            "Epoch 354/1000\n",
            "967/967 [==============================] - 1s 543us/sample - loss: 0.0462 - acc: 0.9845 - val_loss: 2.6428 - val_acc: 0.5537\n",
            "Epoch 355/1000\n",
            "967/967 [==============================] - 1s 529us/sample - loss: 0.0476 - acc: 0.9876 - val_loss: 2.6329 - val_acc: 0.5661\n",
            "Epoch 356/1000\n",
            "967/967 [==============================] - 0s 514us/sample - loss: 0.0596 - acc: 0.9866 - val_loss: 2.6735 - val_acc: 0.5620\n",
            "Epoch 357/1000\n",
            "967/967 [==============================] - 1s 596us/sample - loss: 0.0541 - acc: 0.9855 - val_loss: 2.6616 - val_acc: 0.5579\n",
            "Epoch 358/1000\n",
            "967/967 [==============================] - 1s 597us/sample - loss: 0.0251 - acc: 0.9928 - val_loss: 2.6772 - val_acc: 0.5579\n",
            "Epoch 359/1000\n",
            "967/967 [==============================] - 1s 558us/sample - loss: 0.0616 - acc: 0.9886 - val_loss: 2.6785 - val_acc: 0.5826\n",
            "Epoch 360/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0531 - acc: 0.9804 - val_loss: 2.6655 - val_acc: 0.5661\n",
            "Epoch 361/1000\n",
            "967/967 [==============================] - 1s 593us/sample - loss: 0.0348 - acc: 0.9886 - val_loss: 2.6132 - val_acc: 0.5744\n",
            "Epoch 362/1000\n",
            "967/967 [==============================] - 1s 541us/sample - loss: 0.0480 - acc: 0.9876 - val_loss: 2.6229 - val_acc: 0.5826\n",
            "Epoch 363/1000\n",
            "967/967 [==============================] - 1s 580us/sample - loss: 0.0371 - acc: 0.9897 - val_loss: 2.6232 - val_acc: 0.5744\n",
            "Epoch 364/1000\n",
            "967/967 [==============================] - 1s 544us/sample - loss: 0.1008 - acc: 0.9793 - val_loss: 2.6262 - val_acc: 0.5785\n",
            "Epoch 365/1000\n",
            "967/967 [==============================] - 0s 510us/sample - loss: 0.0457 - acc: 0.9845 - val_loss: 2.6201 - val_acc: 0.5785\n",
            "Epoch 366/1000\n",
            "967/967 [==============================] - 0s 472us/sample - loss: 0.0639 - acc: 0.9876 - val_loss: 2.5824 - val_acc: 0.5785\n",
            "Epoch 367/1000\n",
            "967/967 [==============================] - 1s 552us/sample - loss: 0.0236 - acc: 0.9917 - val_loss: 2.6051 - val_acc: 0.5702\n",
            "Epoch 368/1000\n",
            "967/967 [==============================] - 1s 548us/sample - loss: 0.0377 - acc: 0.9897 - val_loss: 2.6268 - val_acc: 0.5826\n",
            "Epoch 369/1000\n",
            "967/967 [==============================] - 1s 536us/sample - loss: 0.0412 - acc: 0.9845 - val_loss: 2.5966 - val_acc: 0.5868\n",
            "Epoch 370/1000\n",
            "967/967 [==============================] - 1s 588us/sample - loss: 0.0298 - acc: 0.9938 - val_loss: 2.6215 - val_acc: 0.5826\n",
            "Epoch 371/1000\n",
            "967/967 [==============================] - 1s 558us/sample - loss: 0.0525 - acc: 0.9897 - val_loss: 2.6141 - val_acc: 0.5950\n",
            "Epoch 372/1000\n",
            "967/967 [==============================] - 0s 485us/sample - loss: 0.0382 - acc: 0.9814 - val_loss: 2.6130 - val_acc: 0.5992\n",
            "Epoch 373/1000\n",
            "967/967 [==============================] - 1s 568us/sample - loss: 0.0388 - acc: 0.9866 - val_loss: 2.6106 - val_acc: 0.5826\n",
            "Epoch 374/1000\n",
            "967/967 [==============================] - 1s 618us/sample - loss: 0.0642 - acc: 0.9793 - val_loss: 2.6506 - val_acc: 0.5868\n",
            "Epoch 375/1000\n",
            "967/967 [==============================] - 1s 520us/sample - loss: 0.0380 - acc: 0.9855 - val_loss: 2.6830 - val_acc: 0.5868\n",
            "Epoch 376/1000\n",
            "967/967 [==============================] - 1s 585us/sample - loss: 0.0452 - acc: 0.9855 - val_loss: 2.7109 - val_acc: 0.5785\n",
            "Epoch 377/1000\n",
            "967/967 [==============================] - 1s 592us/sample - loss: 0.0325 - acc: 0.9876 - val_loss: 2.7170 - val_acc: 0.5785\n",
            "Epoch 378/1000\n",
            "967/967 [==============================] - 1s 600us/sample - loss: 0.0375 - acc: 0.9886 - val_loss: 2.7345 - val_acc: 0.5702\n",
            "Epoch 379/1000\n",
            "967/967 [==============================] - 1s 560us/sample - loss: 0.0343 - acc: 0.9897 - val_loss: 2.7490 - val_acc: 0.5702\n",
            "Epoch 380/1000\n",
            "967/967 [==============================] - 1s 614us/sample - loss: 0.0389 - acc: 0.9855 - val_loss: 2.6977 - val_acc: 0.5661\n",
            "Epoch 381/1000\n",
            "967/967 [==============================] - 1s 598us/sample - loss: 0.0391 - acc: 0.9876 - val_loss: 2.7146 - val_acc: 0.5826\n",
            "Epoch 382/1000\n",
            "967/967 [==============================] - 1s 597us/sample - loss: 0.0649 - acc: 0.9793 - val_loss: 2.6870 - val_acc: 0.5785\n",
            "Epoch 383/1000\n",
            "967/967 [==============================] - 1s 539us/sample - loss: 0.0475 - acc: 0.9917 - val_loss: 2.7137 - val_acc: 0.5826\n",
            "Epoch 384/1000\n",
            "967/967 [==============================] - 1s 595us/sample - loss: 0.0391 - acc: 0.9855 - val_loss: 2.7034 - val_acc: 0.5744\n",
            "Epoch 385/1000\n",
            "967/967 [==============================] - 1s 630us/sample - loss: 0.0475 - acc: 0.9886 - val_loss: 2.6801 - val_acc: 0.5744\n",
            "Epoch 386/1000\n",
            "967/967 [==============================] - 1s 539us/sample - loss: 0.0356 - acc: 0.9866 - val_loss: 2.6670 - val_acc: 0.5702\n",
            "Epoch 387/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0375 - acc: 0.9917 - val_loss: 2.6305 - val_acc: 0.5744\n",
            "Epoch 388/1000\n",
            "967/967 [==============================] - 1s 635us/sample - loss: 0.0412 - acc: 0.9876 - val_loss: 2.6082 - val_acc: 0.5661\n",
            "Epoch 389/1000\n",
            "967/967 [==============================] - 1s 605us/sample - loss: 0.0640 - acc: 0.9762 - val_loss: 2.6156 - val_acc: 0.5620\n",
            "Epoch 390/1000\n",
            "967/967 [==============================] - 1s 650us/sample - loss: 0.0570 - acc: 0.9824 - val_loss: 2.6010 - val_acc: 0.5785\n",
            "Epoch 391/1000\n",
            "967/967 [==============================] - 1s 617us/sample - loss: 0.0544 - acc: 0.9845 - val_loss: 2.5677 - val_acc: 0.5785\n",
            "Epoch 392/1000\n",
            "967/967 [==============================] - 1s 551us/sample - loss: 0.0456 - acc: 0.9855 - val_loss: 2.5708 - val_acc: 0.5661\n",
            "Epoch 393/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0476 - acc: 0.9804 - val_loss: 2.5845 - val_acc: 0.5661\n",
            "Epoch 394/1000\n",
            "967/967 [==============================] - 1s 577us/sample - loss: 0.0315 - acc: 0.9866 - val_loss: 2.6108 - val_acc: 0.5744\n",
            "Epoch 395/1000\n",
            "967/967 [==============================] - 1s 583us/sample - loss: 0.0339 - acc: 0.9897 - val_loss: 2.6122 - val_acc: 0.5909\n",
            "Epoch 396/1000\n",
            "967/967 [==============================] - 1s 579us/sample - loss: 0.0341 - acc: 0.9897 - val_loss: 2.6241 - val_acc: 0.5785\n",
            "Epoch 397/1000\n",
            "967/967 [==============================] - 1s 581us/sample - loss: 0.0404 - acc: 0.9866 - val_loss: 2.6182 - val_acc: 0.5661\n",
            "Epoch 398/1000\n",
            "967/967 [==============================] - 1s 614us/sample - loss: 0.0401 - acc: 0.9855 - val_loss: 2.6072 - val_acc: 0.5785\n",
            "Epoch 399/1000\n",
            "967/967 [==============================] - 1s 519us/sample - loss: 0.0275 - acc: 0.9897 - val_loss: 2.6253 - val_acc: 0.5826\n",
            "Epoch 400/1000\n",
            "967/967 [==============================] - 1s 575us/sample - loss: 0.0538 - acc: 0.9824 - val_loss: 2.6225 - val_acc: 0.5826\n",
            "Epoch 401/1000\n",
            "967/967 [==============================] - 1s 615us/sample - loss: 0.0206 - acc: 0.9948 - val_loss: 2.6372 - val_acc: 0.5826\n",
            "Epoch 402/1000\n",
            "967/967 [==============================] - 1s 639us/sample - loss: 0.0516 - acc: 0.9804 - val_loss: 2.6157 - val_acc: 0.5785\n",
            "Epoch 403/1000\n",
            "967/967 [==============================] - 1s 536us/sample - loss: 0.0656 - acc: 0.9845 - val_loss: 2.6760 - val_acc: 0.5826\n",
            "Epoch 404/1000\n",
            "967/967 [==============================] - 1s 585us/sample - loss: 0.0391 - acc: 0.9886 - val_loss: 2.7079 - val_acc: 0.5826\n",
            "Epoch 405/1000\n",
            "967/967 [==============================] - 1s 538us/sample - loss: 0.0419 - acc: 0.9824 - val_loss: 2.6736 - val_acc: 0.5702\n",
            "Epoch 406/1000\n",
            "967/967 [==============================] - 1s 555us/sample - loss: 0.0425 - acc: 0.9866 - val_loss: 2.6790 - val_acc: 0.5661\n",
            "Epoch 407/1000\n",
            "967/967 [==============================] - 1s 555us/sample - loss: 0.0341 - acc: 0.9886 - val_loss: 2.6627 - val_acc: 0.5702\n",
            "Epoch 408/1000\n",
            "967/967 [==============================] - 1s 581us/sample - loss: 0.0610 - acc: 0.9845 - val_loss: 2.6540 - val_acc: 0.5744\n",
            "Epoch 409/1000\n",
            "967/967 [==============================] - 1s 633us/sample - loss: 0.0554 - acc: 0.9855 - val_loss: 2.6540 - val_acc: 0.5744\n",
            "Epoch 410/1000\n",
            "967/967 [==============================] - 1s 544us/sample - loss: 0.0352 - acc: 0.9907 - val_loss: 2.6400 - val_acc: 0.5785\n",
            "Epoch 411/1000\n",
            "967/967 [==============================] - 1s 537us/sample - loss: 0.0566 - acc: 0.9886 - val_loss: 2.6566 - val_acc: 0.5868\n",
            "Epoch 412/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0307 - acc: 0.9917 - val_loss: 2.6114 - val_acc: 0.5826\n",
            "Epoch 413/1000\n",
            "967/967 [==============================] - 1s 576us/sample - loss: 0.0347 - acc: 0.9897 - val_loss: 2.5906 - val_acc: 0.5868\n",
            "Epoch 414/1000\n",
            "967/967 [==============================] - 1s 567us/sample - loss: 0.0299 - acc: 0.9907 - val_loss: 2.5764 - val_acc: 0.5785\n",
            "Epoch 415/1000\n",
            "967/967 [==============================] - 1s 564us/sample - loss: 0.0494 - acc: 0.9886 - val_loss: 2.5517 - val_acc: 0.5785\n",
            "Epoch 416/1000\n",
            "967/967 [==============================] - 1s 593us/sample - loss: 0.0371 - acc: 0.9855 - val_loss: 2.5586 - val_acc: 0.5785\n",
            "Epoch 417/1000\n",
            "967/967 [==============================] - 1s 599us/sample - loss: 0.0903 - acc: 0.9824 - val_loss: 2.5711 - val_acc: 0.5826\n",
            "Epoch 418/1000\n",
            "967/967 [==============================] - 1s 577us/sample - loss: 0.0603 - acc: 0.9804 - val_loss: 2.5569 - val_acc: 0.5868\n",
            "Epoch 419/1000\n",
            "967/967 [==============================] - 1s 541us/sample - loss: 0.0335 - acc: 0.9866 - val_loss: 2.5437 - val_acc: 0.5950\n",
            "Epoch 420/1000\n",
            "967/967 [==============================] - 1s 623us/sample - loss: 0.0567 - acc: 0.9814 - val_loss: 2.5959 - val_acc: 0.5868\n",
            "Epoch 421/1000\n",
            "967/967 [==============================] - 1s 548us/sample - loss: 0.0607 - acc: 0.9793 - val_loss: 2.6345 - val_acc: 0.5868\n",
            "Epoch 422/1000\n",
            "967/967 [==============================] - 1s 605us/sample - loss: 0.0493 - acc: 0.9835 - val_loss: 2.6130 - val_acc: 0.6033\n",
            "Epoch 423/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0271 - acc: 0.9886 - val_loss: 2.6058 - val_acc: 0.5868\n",
            "Epoch 424/1000\n",
            "967/967 [==============================] - 1s 573us/sample - loss: 0.0411 - acc: 0.9866 - val_loss: 2.6171 - val_acc: 0.5744\n",
            "Epoch 425/1000\n",
            "967/967 [==============================] - 1s 572us/sample - loss: 0.0381 - acc: 0.9855 - val_loss: 2.6210 - val_acc: 0.5744\n",
            "Epoch 426/1000\n",
            "967/967 [==============================] - 1s 588us/sample - loss: 0.0470 - acc: 0.9804 - val_loss: 2.6141 - val_acc: 0.5950\n",
            "Epoch 427/1000\n",
            "967/967 [==============================] - 1s 527us/sample - loss: 0.0517 - acc: 0.9793 - val_loss: 2.6330 - val_acc: 0.5785\n",
            "Epoch 428/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0421 - acc: 0.9835 - val_loss: 2.6829 - val_acc: 0.5785\n",
            "Epoch 429/1000\n",
            "967/967 [==============================] - 1s 608us/sample - loss: 0.0476 - acc: 0.9814 - val_loss: 2.6832 - val_acc: 0.5785\n",
            "Epoch 430/1000\n",
            "967/967 [==============================] - 1s 572us/sample - loss: 0.0632 - acc: 0.9793 - val_loss: 2.6324 - val_acc: 0.5620\n",
            "Epoch 431/1000\n",
            "967/967 [==============================] - 1s 655us/sample - loss: 0.0590 - acc: 0.9814 - val_loss: 2.6156 - val_acc: 0.5620\n",
            "Epoch 432/1000\n",
            "967/967 [==============================] - 1s 585us/sample - loss: 0.0497 - acc: 0.9866 - val_loss: 2.5974 - val_acc: 0.5620\n",
            "Epoch 433/1000\n",
            "967/967 [==============================] - 1s 563us/sample - loss: 0.0517 - acc: 0.9866 - val_loss: 2.6297 - val_acc: 0.5702\n",
            "Epoch 434/1000\n",
            "967/967 [==============================] - 1s 572us/sample - loss: 0.0570 - acc: 0.9804 - val_loss: 2.6072 - val_acc: 0.5702\n",
            "Epoch 435/1000\n",
            "967/967 [==============================] - 1s 625us/sample - loss: 0.0584 - acc: 0.9814 - val_loss: 2.5967 - val_acc: 0.5537\n",
            "Epoch 436/1000\n",
            "967/967 [==============================] - 1s 551us/sample - loss: 0.0300 - acc: 0.9917 - val_loss: 2.6051 - val_acc: 0.5496\n",
            "Epoch 437/1000\n",
            "967/967 [==============================] - 1s 547us/sample - loss: 0.0462 - acc: 0.9866 - val_loss: 2.6110 - val_acc: 0.5702\n",
            "Epoch 438/1000\n",
            "967/967 [==============================] - 1s 569us/sample - loss: 0.0517 - acc: 0.9866 - val_loss: 2.6273 - val_acc: 0.5661\n",
            "Epoch 439/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0455 - acc: 0.9835 - val_loss: 2.6204 - val_acc: 0.5702\n",
            "Epoch 440/1000\n",
            "967/967 [==============================] - 1s 537us/sample - loss: 0.0316 - acc: 0.9855 - val_loss: 2.6477 - val_acc: 0.5744\n",
            "Epoch 441/1000\n",
            "967/967 [==============================] - 0s 516us/sample - loss: 0.0857 - acc: 0.9824 - val_loss: 2.6186 - val_acc: 0.5744\n",
            "Epoch 442/1000\n",
            "967/967 [==============================] - 1s 615us/sample - loss: 0.0409 - acc: 0.9866 - val_loss: 2.5776 - val_acc: 0.5661\n",
            "Epoch 443/1000\n",
            "967/967 [==============================] - 1s 586us/sample - loss: 0.0469 - acc: 0.9886 - val_loss: 2.6001 - val_acc: 0.5661\n",
            "Epoch 444/1000\n",
            "967/967 [==============================] - 1s 531us/sample - loss: 0.0489 - acc: 0.9804 - val_loss: 2.5792 - val_acc: 0.5785\n",
            "Epoch 445/1000\n",
            "967/967 [==============================] - 1s 590us/sample - loss: 0.0449 - acc: 0.9855 - val_loss: 2.5852 - val_acc: 0.5826\n",
            "Epoch 446/1000\n",
            "967/967 [==============================] - 1s 606us/sample - loss: 0.0390 - acc: 0.9835 - val_loss: 2.5737 - val_acc: 0.5785\n",
            "Epoch 447/1000\n",
            "967/967 [==============================] - 1s 601us/sample - loss: 0.0263 - acc: 0.9897 - val_loss: 2.5860 - val_acc: 0.5702\n",
            "Epoch 448/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0450 - acc: 0.9897 - val_loss: 2.6080 - val_acc: 0.5661\n",
            "Epoch 449/1000\n",
            "967/967 [==============================] - 1s 539us/sample - loss: 0.0422 - acc: 0.9897 - val_loss: 2.5870 - val_acc: 0.5826\n",
            "Epoch 450/1000\n",
            "967/967 [==============================] - 0s 506us/sample - loss: 0.0352 - acc: 0.9866 - val_loss: 2.5804 - val_acc: 0.5826\n",
            "Epoch 451/1000\n",
            "967/967 [==============================] - 0s 516us/sample - loss: 0.0291 - acc: 0.9928 - val_loss: 2.5976 - val_acc: 0.5785\n",
            "Epoch 452/1000\n",
            "967/967 [==============================] - 1s 580us/sample - loss: 0.0617 - acc: 0.9814 - val_loss: 2.5969 - val_acc: 0.5744\n",
            "Epoch 453/1000\n",
            "967/967 [==============================] - 1s 587us/sample - loss: 0.0324 - acc: 0.9907 - val_loss: 2.5986 - val_acc: 0.5785\n",
            "Epoch 454/1000\n",
            "967/967 [==============================] - 1s 546us/sample - loss: 0.0318 - acc: 0.9876 - val_loss: 2.6171 - val_acc: 0.5785\n",
            "Epoch 455/1000\n",
            "967/967 [==============================] - 0s 494us/sample - loss: 0.0360 - acc: 0.9866 - val_loss: 2.5859 - val_acc: 0.5744\n",
            "Epoch 456/1000\n",
            "967/967 [==============================] - 1s 576us/sample - loss: 0.0613 - acc: 0.9824 - val_loss: 2.6122 - val_acc: 0.5785\n",
            "Epoch 457/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0468 - acc: 0.9876 - val_loss: 2.5767 - val_acc: 0.5868\n",
            "Epoch 458/1000\n",
            "967/967 [==============================] - 1s 521us/sample - loss: 0.0439 - acc: 0.9845 - val_loss: 2.5590 - val_acc: 0.5744\n",
            "Epoch 459/1000\n",
            "967/967 [==============================] - 0s 487us/sample - loss: 0.0432 - acc: 0.9855 - val_loss: 2.5481 - val_acc: 0.5744\n",
            "Epoch 460/1000\n",
            "967/967 [==============================] - 1s 642us/sample - loss: 0.0467 - acc: 0.9876 - val_loss: 2.5657 - val_acc: 0.5826\n",
            "Epoch 461/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0478 - acc: 0.9866 - val_loss: 2.5837 - val_acc: 0.5826\n",
            "Epoch 462/1000\n",
            "967/967 [==============================] - 1s 608us/sample - loss: 0.0454 - acc: 0.9855 - val_loss: 2.5951 - val_acc: 0.5868\n",
            "Epoch 463/1000\n",
            "967/967 [==============================] - 1s 596us/sample - loss: 0.0688 - acc: 0.9804 - val_loss: 2.5599 - val_acc: 0.5785\n",
            "Epoch 464/1000\n",
            "967/967 [==============================] - 1s 628us/sample - loss: 0.0667 - acc: 0.9804 - val_loss: 2.5553 - val_acc: 0.5868\n",
            "Epoch 465/1000\n",
            "967/967 [==============================] - 1s 621us/sample - loss: 0.0350 - acc: 0.9876 - val_loss: 2.5556 - val_acc: 0.5950\n",
            "Epoch 466/1000\n",
            "967/967 [==============================] - 0s 506us/sample - loss: 0.0404 - acc: 0.9855 - val_loss: 2.5851 - val_acc: 0.5868\n",
            "Epoch 467/1000\n",
            "967/967 [==============================] - 1s 553us/sample - loss: 0.0422 - acc: 0.9886 - val_loss: 2.5688 - val_acc: 0.5950\n",
            "Epoch 468/1000\n",
            "967/967 [==============================] - 1s 598us/sample - loss: 0.0509 - acc: 0.9824 - val_loss: 2.5537 - val_acc: 0.5702\n",
            "Epoch 469/1000\n",
            "967/967 [==============================] - 1s 562us/sample - loss: 0.0433 - acc: 0.9835 - val_loss: 2.5463 - val_acc: 0.5992\n",
            "Epoch 470/1000\n",
            "967/967 [==============================] - 1s 565us/sample - loss: 0.0304 - acc: 0.9845 - val_loss: 2.5434 - val_acc: 0.5909\n",
            "Epoch 471/1000\n",
            "967/967 [==============================] - 1s 634us/sample - loss: 0.0366 - acc: 0.9897 - val_loss: 2.5424 - val_acc: 0.5950\n",
            "Epoch 472/1000\n",
            "967/967 [==============================] - 1s 551us/sample - loss: 0.0435 - acc: 0.9804 - val_loss: 2.5356 - val_acc: 0.5868\n",
            "Epoch 473/1000\n",
            "967/967 [==============================] - 1s 590us/sample - loss: 0.0438 - acc: 0.9845 - val_loss: 2.5519 - val_acc: 0.5909\n",
            "Epoch 474/1000\n",
            "967/967 [==============================] - 1s 525us/sample - loss: 0.0314 - acc: 0.9876 - val_loss: 2.5766 - val_acc: 0.5909\n",
            "Epoch 475/1000\n",
            "967/967 [==============================] - 1s 649us/sample - loss: 0.0382 - acc: 0.9897 - val_loss: 2.5836 - val_acc: 0.5868\n",
            "Epoch 476/1000\n",
            "967/967 [==============================] - 1s 678us/sample - loss: 0.0237 - acc: 0.9917 - val_loss: 2.6014 - val_acc: 0.5909\n",
            "Epoch 477/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0357 - acc: 0.9886 - val_loss: 2.6145 - val_acc: 0.5909\n",
            "Epoch 478/1000\n",
            "967/967 [==============================] - 1s 619us/sample - loss: 0.0340 - acc: 0.9897 - val_loss: 2.5936 - val_acc: 0.5785\n",
            "Epoch 479/1000\n",
            "967/967 [==============================] - 1s 628us/sample - loss: 0.0387 - acc: 0.9855 - val_loss: 2.6058 - val_acc: 0.5868\n",
            "Epoch 480/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0309 - acc: 0.9876 - val_loss: 2.6036 - val_acc: 0.5868\n",
            "Epoch 481/1000\n",
            "967/967 [==============================] - 1s 560us/sample - loss: 0.0635 - acc: 0.9845 - val_loss: 2.5878 - val_acc: 0.5826\n",
            "Epoch 482/1000\n",
            "967/967 [==============================] - 1s 612us/sample - loss: 0.0328 - acc: 0.9886 - val_loss: 2.5624 - val_acc: 0.5826\n",
            "Epoch 483/1000\n",
            "967/967 [==============================] - 1s 584us/sample - loss: 0.0383 - acc: 0.9866 - val_loss: 2.5742 - val_acc: 0.5785\n",
            "Epoch 484/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0506 - acc: 0.9917 - val_loss: 2.5542 - val_acc: 0.5868\n",
            "Epoch 485/1000\n",
            "967/967 [==============================] - 0s 497us/sample - loss: 0.0916 - acc: 0.9783 - val_loss: 2.5183 - val_acc: 0.5785\n",
            "Epoch 486/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0548 - acc: 0.9824 - val_loss: 2.5065 - val_acc: 0.5702\n",
            "Epoch 487/1000\n",
            "967/967 [==============================] - 1s 595us/sample - loss: 0.0460 - acc: 0.9855 - val_loss: 2.5208 - val_acc: 0.5785\n",
            "Epoch 488/1000\n",
            "967/967 [==============================] - 1s 619us/sample - loss: 0.0442 - acc: 0.9876 - val_loss: 2.5673 - val_acc: 0.5785\n",
            "Epoch 489/1000\n",
            "967/967 [==============================] - 1s 564us/sample - loss: 0.0358 - acc: 0.9845 - val_loss: 2.5774 - val_acc: 0.5826\n",
            "Epoch 490/1000\n",
            "967/967 [==============================] - 1s 619us/sample - loss: 0.0259 - acc: 0.9876 - val_loss: 2.5890 - val_acc: 0.5744\n",
            "Epoch 491/1000\n",
            "967/967 [==============================] - 1s 571us/sample - loss: 0.0477 - acc: 0.9876 - val_loss: 2.5721 - val_acc: 0.5702\n",
            "Epoch 492/1000\n",
            "967/967 [==============================] - 1s 536us/sample - loss: 0.0490 - acc: 0.9804 - val_loss: 2.5624 - val_acc: 0.5826\n",
            "Epoch 493/1000\n",
            "967/967 [==============================] - 1s 561us/sample - loss: 0.0383 - acc: 0.9886 - val_loss: 2.5927 - val_acc: 0.5868\n",
            "Epoch 494/1000\n",
            "967/967 [==============================] - 1s 597us/sample - loss: 0.0521 - acc: 0.9866 - val_loss: 2.5818 - val_acc: 0.5868\n",
            "Epoch 495/1000\n",
            "967/967 [==============================] - 1s 621us/sample - loss: 0.0380 - acc: 0.9876 - val_loss: 2.5714 - val_acc: 0.5702\n",
            "Epoch 496/1000\n",
            "967/967 [==============================] - 1s 590us/sample - loss: 0.0358 - acc: 0.9866 - val_loss: 2.5781 - val_acc: 0.5826\n",
            "Epoch 497/1000\n",
            "967/967 [==============================] - 1s 550us/sample - loss: 0.0356 - acc: 0.9876 - val_loss: 2.5910 - val_acc: 0.5785\n",
            "Epoch 498/1000\n",
            "967/967 [==============================] - 1s 617us/sample - loss: 0.0322 - acc: 0.9917 - val_loss: 2.6229 - val_acc: 0.5702\n",
            "Epoch 499/1000\n",
            "967/967 [==============================] - 1s 601us/sample - loss: 0.0482 - acc: 0.9835 - val_loss: 2.6294 - val_acc: 0.5744\n",
            "Epoch 500/1000\n",
            "967/967 [==============================] - 1s 622us/sample - loss: 0.0388 - acc: 0.9897 - val_loss: 2.5648 - val_acc: 0.5909\n",
            "Epoch 501/1000\n",
            "967/967 [==============================] - 1s 613us/sample - loss: 0.0513 - acc: 0.9845 - val_loss: 2.5512 - val_acc: 0.5826\n",
            "Epoch 502/1000\n",
            "967/967 [==============================] - 1s 564us/sample - loss: 0.0388 - acc: 0.9845 - val_loss: 2.5655 - val_acc: 0.5826\n",
            "Epoch 503/1000\n",
            "967/967 [==============================] - 1s 566us/sample - loss: 0.0396 - acc: 0.9835 - val_loss: 2.5900 - val_acc: 0.5868\n",
            "Epoch 504/1000\n",
            "967/967 [==============================] - 1s 656us/sample - loss: 0.0535 - acc: 0.9866 - val_loss: 2.6038 - val_acc: 0.5950\n",
            "Epoch 505/1000\n",
            "967/967 [==============================] - 1s 576us/sample - loss: 0.0324 - acc: 0.9917 - val_loss: 2.6341 - val_acc: 0.5868\n",
            "Epoch 506/1000\n",
            "967/967 [==============================] - 1s 600us/sample - loss: 0.0431 - acc: 0.9845 - val_loss: 2.6300 - val_acc: 0.5909\n",
            "Epoch 507/1000\n",
            "967/967 [==============================] - 1s 597us/sample - loss: 0.0467 - acc: 0.9897 - val_loss: 2.6148 - val_acc: 0.5950\n",
            "Epoch 508/1000\n",
            "967/967 [==============================] - 1s 528us/sample - loss: 0.0650 - acc: 0.9835 - val_loss: 2.5895 - val_acc: 0.6033\n",
            "Epoch 509/1000\n",
            "967/967 [==============================] - 1s 544us/sample - loss: 0.0371 - acc: 0.9855 - val_loss: 2.5637 - val_acc: 0.5826\n",
            "Epoch 510/1000\n",
            "967/967 [==============================] - 0s 493us/sample - loss: 0.0182 - acc: 0.9917 - val_loss: 2.6100 - val_acc: 0.5868\n",
            "Epoch 511/1000\n",
            "967/967 [==============================] - 1s 591us/sample - loss: 0.0322 - acc: 0.9907 - val_loss: 2.6267 - val_acc: 0.5785\n",
            "Epoch 512/1000\n",
            "967/967 [==============================] - 1s 590us/sample - loss: 0.0371 - acc: 0.9897 - val_loss: 2.5942 - val_acc: 0.5702\n",
            "Epoch 513/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0316 - acc: 0.9897 - val_loss: 2.6139 - val_acc: 0.5785\n",
            "Epoch 514/1000\n",
            "967/967 [==============================] - 0s 476us/sample - loss: 0.0681 - acc: 0.9845 - val_loss: 2.6347 - val_acc: 0.5868\n",
            "Epoch 515/1000\n",
            "967/967 [==============================] - 1s 603us/sample - loss: 0.0328 - acc: 0.9897 - val_loss: 2.6333 - val_acc: 0.5950\n",
            "Epoch 516/1000\n",
            "967/967 [==============================] - 1s 613us/sample - loss: 0.0312 - acc: 0.9886 - val_loss: 2.6310 - val_acc: 0.5702\n",
            "Epoch 517/1000\n",
            "967/967 [==============================] - 1s 528us/sample - loss: 0.0526 - acc: 0.9845 - val_loss: 2.6560 - val_acc: 0.5744\n",
            "Epoch 518/1000\n",
            "967/967 [==============================] - 1s 628us/sample - loss: 0.0345 - acc: 0.9866 - val_loss: 2.6547 - val_acc: 0.5785\n",
            "Epoch 519/1000\n",
            "967/967 [==============================] - 1s 598us/sample - loss: 0.0467 - acc: 0.9855 - val_loss: 2.6810 - val_acc: 0.5744\n",
            "Epoch 520/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0493 - acc: 0.9866 - val_loss: 2.6664 - val_acc: 0.5826\n",
            "Epoch 521/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0320 - acc: 0.9845 - val_loss: 2.6410 - val_acc: 0.5744\n",
            "Epoch 522/1000\n",
            "967/967 [==============================] - 1s 546us/sample - loss: 0.0316 - acc: 0.9948 - val_loss: 2.6532 - val_acc: 0.5744\n",
            "Epoch 523/1000\n",
            "967/967 [==============================] - 1s 607us/sample - loss: 0.0446 - acc: 0.9886 - val_loss: 2.6769 - val_acc: 0.5826\n",
            "Epoch 524/1000\n",
            "967/967 [==============================] - 1s 592us/sample - loss: 0.0343 - acc: 0.9907 - val_loss: 2.6652 - val_acc: 0.5826\n",
            "Epoch 525/1000\n",
            "967/967 [==============================] - 0s 509us/sample - loss: 0.0317 - acc: 0.9897 - val_loss: 2.6568 - val_acc: 0.5744\n",
            "Epoch 526/1000\n",
            "967/967 [==============================] - 1s 548us/sample - loss: 0.0411 - acc: 0.9824 - val_loss: 2.6696 - val_acc: 0.5702\n",
            "Epoch 527/1000\n",
            "967/967 [==============================] - 1s 581us/sample - loss: 0.0623 - acc: 0.9824 - val_loss: 2.6807 - val_acc: 0.5661\n",
            "Epoch 528/1000\n",
            "967/967 [==============================] - 1s 582us/sample - loss: 0.0380 - acc: 0.9876 - val_loss: 2.6557 - val_acc: 0.5537\n",
            "Epoch 529/1000\n",
            "967/967 [==============================] - 1s 542us/sample - loss: 0.0409 - acc: 0.9835 - val_loss: 2.6851 - val_acc: 0.5620\n",
            "Epoch 530/1000\n",
            "967/967 [==============================] - 1s 573us/sample - loss: 0.0397 - acc: 0.9855 - val_loss: 2.6704 - val_acc: 0.5702\n",
            "Epoch 531/1000\n",
            "967/967 [==============================] - 0s 504us/sample - loss: 0.0594 - acc: 0.9762 - val_loss: 2.6832 - val_acc: 0.5661\n",
            "Epoch 532/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0447 - acc: 0.9824 - val_loss: 2.6817 - val_acc: 0.5661\n",
            "Epoch 533/1000\n",
            "967/967 [==============================] - 1s 595us/sample - loss: 0.0450 - acc: 0.9866 - val_loss: 2.6749 - val_acc: 0.5826\n",
            "Epoch 534/1000\n",
            "967/967 [==============================] - 0s 490us/sample - loss: 0.0303 - acc: 0.9886 - val_loss: 2.7031 - val_acc: 0.5702\n",
            "Epoch 535/1000\n",
            "967/967 [==============================] - 1s 600us/sample - loss: 0.0847 - acc: 0.9824 - val_loss: 2.7024 - val_acc: 0.5785\n",
            "Epoch 536/1000\n",
            "967/967 [==============================] - 1s 534us/sample - loss: 0.0338 - acc: 0.9886 - val_loss: 2.6668 - val_acc: 0.5702\n",
            "Epoch 537/1000\n",
            "967/967 [==============================] - 0s 507us/sample - loss: 0.0307 - acc: 0.9876 - val_loss: 2.6378 - val_acc: 0.5744\n",
            "Epoch 538/1000\n",
            "967/967 [==============================] - 1s 577us/sample - loss: 0.0283 - acc: 0.9897 - val_loss: 2.6511 - val_acc: 0.5661\n",
            "Epoch 539/1000\n",
            "967/967 [==============================] - 1s 610us/sample - loss: 0.0531 - acc: 0.9855 - val_loss: 2.6357 - val_acc: 0.5620\n",
            "Epoch 540/1000\n",
            "967/967 [==============================] - 1s 602us/sample - loss: 0.0404 - acc: 0.9866 - val_loss: 2.6273 - val_acc: 0.5702\n",
            "Epoch 541/1000\n",
            "967/967 [==============================] - 1s 605us/sample - loss: 0.0473 - acc: 0.9876 - val_loss: 2.6039 - val_acc: 0.5702\n",
            "Epoch 542/1000\n",
            "967/967 [==============================] - 1s 525us/sample - loss: 0.0342 - acc: 0.9866 - val_loss: 2.6326 - val_acc: 0.5661\n",
            "Epoch 543/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0427 - acc: 0.9855 - val_loss: 2.6325 - val_acc: 0.5661\n",
            "Epoch 544/1000\n",
            "967/967 [==============================] - 0s 491us/sample - loss: 0.0345 - acc: 0.9928 - val_loss: 2.6204 - val_acc: 0.5702\n",
            "Epoch 545/1000\n",
            "967/967 [==============================] - 1s 538us/sample - loss: 0.0420 - acc: 0.9866 - val_loss: 2.6648 - val_acc: 0.5826\n",
            "Epoch 546/1000\n",
            "967/967 [==============================] - 1s 618us/sample - loss: 0.0435 - acc: 0.9835 - val_loss: 2.6707 - val_acc: 0.5744\n",
            "Epoch 547/1000\n",
            "967/967 [==============================] - 0s 507us/sample - loss: 0.0582 - acc: 0.9876 - val_loss: 2.6544 - val_acc: 0.5744\n",
            "Epoch 548/1000\n",
            "967/967 [==============================] - 1s 520us/sample - loss: 0.0498 - acc: 0.9814 - val_loss: 2.6517 - val_acc: 0.5579\n",
            "Epoch 549/1000\n",
            "967/967 [==============================] - 1s 563us/sample - loss: 0.0281 - acc: 0.9917 - val_loss: 2.6861 - val_acc: 0.5661\n",
            "Epoch 550/1000\n",
            "967/967 [==============================] - 1s 547us/sample - loss: 0.0418 - acc: 0.9835 - val_loss: 2.7239 - val_acc: 0.5661\n",
            "Epoch 551/1000\n",
            "967/967 [==============================] - 1s 595us/sample - loss: 0.0441 - acc: 0.9855 - val_loss: 2.6933 - val_acc: 0.5826\n",
            "Epoch 552/1000\n",
            "967/967 [==============================] - 1s 531us/sample - loss: 0.0361 - acc: 0.9886 - val_loss: 2.6786 - val_acc: 0.5785\n",
            "Epoch 553/1000\n",
            "967/967 [==============================] - 1s 603us/sample - loss: 0.0332 - acc: 0.9886 - val_loss: 2.6613 - val_acc: 0.5744\n",
            "Epoch 554/1000\n",
            "967/967 [==============================] - 1s 594us/sample - loss: 0.0709 - acc: 0.9762 - val_loss: 2.6388 - val_acc: 0.5702\n",
            "Epoch 555/1000\n",
            "967/967 [==============================] - 1s 562us/sample - loss: 0.0392 - acc: 0.9855 - val_loss: 2.6420 - val_acc: 0.5826\n",
            "Epoch 556/1000\n",
            "967/967 [==============================] - 0s 516us/sample - loss: 0.0525 - acc: 0.9804 - val_loss: 2.6547 - val_acc: 0.5826\n",
            "Epoch 557/1000\n",
            "967/967 [==============================] - 1s 534us/sample - loss: 0.0339 - acc: 0.9917 - val_loss: 2.6562 - val_acc: 0.5785\n",
            "Epoch 558/1000\n",
            "967/967 [==============================] - 1s 626us/sample - loss: 0.0528 - acc: 0.9814 - val_loss: 2.6821 - val_acc: 0.5785\n",
            "Epoch 559/1000\n",
            "967/967 [==============================] - 1s 564us/sample - loss: 0.0386 - acc: 0.9886 - val_loss: 2.6573 - val_acc: 0.5785\n",
            "Epoch 560/1000\n",
            "967/967 [==============================] - 1s 634us/sample - loss: 0.0509 - acc: 0.9866 - val_loss: 2.6498 - val_acc: 0.5744\n",
            "Epoch 561/1000\n",
            "967/967 [==============================] - 1s 597us/sample - loss: 0.0279 - acc: 0.9907 - val_loss: 2.6380 - val_acc: 0.5744\n",
            "Epoch 562/1000\n",
            "967/967 [==============================] - 1s 567us/sample - loss: 0.0473 - acc: 0.9866 - val_loss: 2.6599 - val_acc: 0.5785\n",
            "Epoch 563/1000\n",
            "967/967 [==============================] - 0s 501us/sample - loss: 0.0641 - acc: 0.9845 - val_loss: 2.6588 - val_acc: 0.5620\n",
            "Epoch 564/1000\n",
            "967/967 [==============================] - 1s 652us/sample - loss: 0.0359 - acc: 0.9835 - val_loss: 2.6407 - val_acc: 0.5620\n",
            "Epoch 565/1000\n",
            "967/967 [==============================] - 1s 558us/sample - loss: 0.0490 - acc: 0.9907 - val_loss: 2.6463 - val_acc: 0.5620\n",
            "Epoch 566/1000\n",
            "967/967 [==============================] - 0s 488us/sample - loss: 0.0472 - acc: 0.9938 - val_loss: 2.6668 - val_acc: 0.5702\n",
            "Epoch 567/1000\n",
            "967/967 [==============================] - 1s 548us/sample - loss: 0.0574 - acc: 0.9814 - val_loss: 2.6467 - val_acc: 0.5620\n",
            "Epoch 568/1000\n",
            "967/967 [==============================] - 1s 551us/sample - loss: 0.0374 - acc: 0.9876 - val_loss: 2.6447 - val_acc: 0.5661\n",
            "Epoch 569/1000\n",
            "967/967 [==============================] - 0s 515us/sample - loss: 0.0421 - acc: 0.9907 - val_loss: 2.6402 - val_acc: 0.5702\n",
            "Epoch 570/1000\n",
            "967/967 [==============================] - 1s 528us/sample - loss: 0.0284 - acc: 0.9917 - val_loss: 2.6290 - val_acc: 0.5702\n",
            "Epoch 571/1000\n",
            "967/967 [==============================] - 1s 557us/sample - loss: 0.0832 - acc: 0.9804 - val_loss: 2.6208 - val_acc: 0.5785\n",
            "Epoch 572/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0244 - acc: 0.9907 - val_loss: 2.6096 - val_acc: 0.5826\n",
            "Epoch 573/1000\n",
            "967/967 [==============================] - 1s 536us/sample - loss: 0.0328 - acc: 0.9907 - val_loss: 2.6567 - val_acc: 0.5868\n",
            "Epoch 574/1000\n",
            "967/967 [==============================] - 1s 567us/sample - loss: 0.0457 - acc: 0.9835 - val_loss: 2.6798 - val_acc: 0.5744\n",
            "Epoch 575/1000\n",
            "967/967 [==============================] - 1s 632us/sample - loss: 0.0456 - acc: 0.9845 - val_loss: 2.6714 - val_acc: 0.5785\n",
            "Epoch 576/1000\n",
            "967/967 [==============================] - 1s 530us/sample - loss: 0.0535 - acc: 0.9845 - val_loss: 2.6912 - val_acc: 0.5702\n",
            "Epoch 577/1000\n",
            "967/967 [==============================] - 1s 542us/sample - loss: 0.0278 - acc: 0.9907 - val_loss: 2.7006 - val_acc: 0.5868\n",
            "Epoch 578/1000\n",
            "967/967 [==============================] - 1s 570us/sample - loss: 0.0476 - acc: 0.9824 - val_loss: 2.6620 - val_acc: 0.5826\n",
            "Epoch 579/1000\n",
            "967/967 [==============================] - 1s 606us/sample - loss: 0.0557 - acc: 0.9804 - val_loss: 2.6743 - val_acc: 0.5785\n",
            "Epoch 580/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0724 - acc: 0.9835 - val_loss: 2.6651 - val_acc: 0.5868\n",
            "Epoch 581/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0519 - acc: 0.9876 - val_loss: 2.6824 - val_acc: 0.5868\n",
            "Epoch 582/1000\n",
            "967/967 [==============================] - 1s 570us/sample - loss: 0.0475 - acc: 0.9907 - val_loss: 2.6759 - val_acc: 0.5909\n",
            "Epoch 583/1000\n",
            "967/967 [==============================] - 1s 555us/sample - loss: 0.0302 - acc: 0.9855 - val_loss: 2.6590 - val_acc: 0.5744\n",
            "Epoch 584/1000\n",
            "967/967 [==============================] - 1s 552us/sample - loss: 0.0420 - acc: 0.9886 - val_loss: 2.6756 - val_acc: 0.5702\n",
            "Epoch 585/1000\n",
            "967/967 [==============================] - 1s 581us/sample - loss: 0.0354 - acc: 0.9886 - val_loss: 2.6738 - val_acc: 0.5826\n",
            "Epoch 586/1000\n",
            "967/967 [==============================] - 0s 504us/sample - loss: 0.0540 - acc: 0.9866 - val_loss: 2.6705 - val_acc: 0.5868\n",
            "Epoch 587/1000\n",
            "967/967 [==============================] - 1s 553us/sample - loss: 0.0490 - acc: 0.9876 - val_loss: 2.6636 - val_acc: 0.5744\n",
            "Epoch 588/1000\n",
            "967/967 [==============================] - 1s 566us/sample - loss: 0.0145 - acc: 0.9948 - val_loss: 2.6704 - val_acc: 0.5661\n",
            "Epoch 589/1000\n",
            "967/967 [==============================] - 1s 591us/sample - loss: 0.0584 - acc: 0.9804 - val_loss: 2.6551 - val_acc: 0.5785\n",
            "Epoch 590/1000\n",
            "967/967 [==============================] - 1s 573us/sample - loss: 0.0295 - acc: 0.9907 - val_loss: 2.6708 - val_acc: 0.5785\n",
            "Epoch 591/1000\n",
            "967/967 [==============================] - 1s 551us/sample - loss: 0.0413 - acc: 0.9886 - val_loss: 2.6494 - val_acc: 0.5826\n",
            "Epoch 592/1000\n",
            "967/967 [==============================] - 1s 548us/sample - loss: 0.0381 - acc: 0.9907 - val_loss: 2.6748 - val_acc: 0.5868\n",
            "Epoch 593/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0391 - acc: 0.9866 - val_loss: 2.6634 - val_acc: 0.5785\n",
            "Epoch 594/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0333 - acc: 0.9897 - val_loss: 2.6572 - val_acc: 0.5785\n",
            "Epoch 595/1000\n",
            "967/967 [==============================] - 1s 564us/sample - loss: 0.0534 - acc: 0.9866 - val_loss: 2.6591 - val_acc: 0.5785\n",
            "Epoch 596/1000\n",
            "967/967 [==============================] - 1s 645us/sample - loss: 0.0401 - acc: 0.9835 - val_loss: 2.6670 - val_acc: 0.5826\n",
            "Epoch 597/1000\n",
            "967/967 [==============================] - 1s 519us/sample - loss: 0.0365 - acc: 0.9855 - val_loss: 2.6491 - val_acc: 0.5661\n",
            "Epoch 598/1000\n",
            "967/967 [==============================] - 1s 564us/sample - loss: 0.0483 - acc: 0.9855 - val_loss: 2.7026 - val_acc: 0.5950\n",
            "Epoch 599/1000\n",
            "967/967 [==============================] - 1s 560us/sample - loss: 0.0337 - acc: 0.9897 - val_loss: 2.6718 - val_acc: 0.5826\n",
            "Epoch 600/1000\n",
            "967/967 [==============================] - 1s 572us/sample - loss: 0.0247 - acc: 0.9907 - val_loss: 2.6855 - val_acc: 0.5826\n",
            "Epoch 601/1000\n",
            "967/967 [==============================] - 1s 629us/sample - loss: 0.0505 - acc: 0.9866 - val_loss: 2.6841 - val_acc: 0.5785\n",
            "Epoch 602/1000\n",
            "967/967 [==============================] - 1s 522us/sample - loss: 0.0319 - acc: 0.9876 - val_loss: 2.6590 - val_acc: 0.5702\n",
            "Epoch 603/1000\n",
            "967/967 [==============================] - 1s 621us/sample - loss: 0.0342 - acc: 0.9917 - val_loss: 2.6489 - val_acc: 0.5826\n",
            "Epoch 604/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0406 - acc: 0.9866 - val_loss: 2.6146 - val_acc: 0.5868\n",
            "Epoch 605/1000\n",
            "967/967 [==============================] - 1s 624us/sample - loss: 0.0355 - acc: 0.9824 - val_loss: 2.5696 - val_acc: 0.5868\n",
            "Epoch 606/1000\n",
            "967/967 [==============================] - 1s 615us/sample - loss: 0.0368 - acc: 0.9876 - val_loss: 2.5534 - val_acc: 0.5950\n",
            "Epoch 607/1000\n",
            "967/967 [==============================] - 1s 568us/sample - loss: 0.0386 - acc: 0.9866 - val_loss: 2.5447 - val_acc: 0.5909\n",
            "Epoch 608/1000\n",
            "967/967 [==============================] - 1s 566us/sample - loss: 0.0343 - acc: 0.9866 - val_loss: 2.5324 - val_acc: 0.5868\n",
            "Epoch 609/1000\n",
            "967/967 [==============================] - 1s 602us/sample - loss: 0.0646 - acc: 0.9814 - val_loss: 2.5652 - val_acc: 0.5744\n",
            "Epoch 610/1000\n",
            "967/967 [==============================] - 1s 555us/sample - loss: 0.0325 - acc: 0.9938 - val_loss: 2.5709 - val_acc: 0.5785\n",
            "Epoch 611/1000\n",
            "967/967 [==============================] - 1s 597us/sample - loss: 0.0396 - acc: 0.9866 - val_loss: 2.6083 - val_acc: 0.5744\n",
            "Epoch 612/1000\n",
            "967/967 [==============================] - 0s 514us/sample - loss: 0.0485 - acc: 0.9835 - val_loss: 2.6038 - val_acc: 0.5661\n",
            "Epoch 613/1000\n",
            "967/967 [==============================] - 1s 533us/sample - loss: 0.0351 - acc: 0.9897 - val_loss: 2.5809 - val_acc: 0.5785\n",
            "Epoch 614/1000\n",
            "967/967 [==============================] - 1s 544us/sample - loss: 0.0413 - acc: 0.9866 - val_loss: 2.5872 - val_acc: 0.5826\n",
            "Epoch 615/1000\n",
            "967/967 [==============================] - 1s 567us/sample - loss: 0.0327 - acc: 0.9866 - val_loss: 2.5875 - val_acc: 0.5661\n",
            "Epoch 616/1000\n",
            "967/967 [==============================] - 1s 581us/sample - loss: 0.0348 - acc: 0.9886 - val_loss: 2.6133 - val_acc: 0.5744\n",
            "Epoch 617/1000\n",
            "967/967 [==============================] - 1s 536us/sample - loss: 0.0589 - acc: 0.9886 - val_loss: 2.5768 - val_acc: 0.5785\n",
            "Epoch 618/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0354 - acc: 0.9876 - val_loss: 2.5768 - val_acc: 0.5826\n",
            "Epoch 619/1000\n",
            "967/967 [==============================] - 1s 584us/sample - loss: 0.0564 - acc: 0.9783 - val_loss: 2.5587 - val_acc: 0.5785\n",
            "Epoch 620/1000\n",
            "967/967 [==============================] - 1s 614us/sample - loss: 0.0792 - acc: 0.9783 - val_loss: 2.5641 - val_acc: 0.5785\n",
            "Epoch 621/1000\n",
            "967/967 [==============================] - 1s 614us/sample - loss: 0.0504 - acc: 0.9855 - val_loss: 2.5612 - val_acc: 0.5868\n",
            "Epoch 622/1000\n",
            "967/967 [==============================] - 1s 570us/sample - loss: 0.0472 - acc: 0.9845 - val_loss: 2.5662 - val_acc: 0.5785\n",
            "Epoch 623/1000\n",
            "967/967 [==============================] - 1s 536us/sample - loss: 0.0519 - acc: 0.9835 - val_loss: 2.5539 - val_acc: 0.5661\n",
            "Epoch 624/1000\n",
            "967/967 [==============================] - 1s 535us/sample - loss: 0.0429 - acc: 0.9793 - val_loss: 2.5861 - val_acc: 0.5702\n",
            "Epoch 625/1000\n",
            "967/967 [==============================] - 1s 565us/sample - loss: 0.0371 - acc: 0.9855 - val_loss: 2.6107 - val_acc: 0.5744\n",
            "Epoch 626/1000\n",
            "967/967 [==============================] - 1s 573us/sample - loss: 0.0429 - acc: 0.9835 - val_loss: 2.6206 - val_acc: 0.5950\n",
            "Epoch 627/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0401 - acc: 0.9855 - val_loss: 2.6077 - val_acc: 0.5785\n",
            "Epoch 628/1000\n",
            "967/967 [==============================] - 1s 577us/sample - loss: 0.0273 - acc: 0.9948 - val_loss: 2.6063 - val_acc: 0.5785\n",
            "Epoch 629/1000\n",
            "967/967 [==============================] - 0s 502us/sample - loss: 0.0389 - acc: 0.9928 - val_loss: 2.6292 - val_acc: 0.5661\n",
            "Epoch 630/1000\n",
            "967/967 [==============================] - 0s 504us/sample - loss: 0.0347 - acc: 0.9907 - val_loss: 2.6425 - val_acc: 0.5702\n",
            "Epoch 631/1000\n",
            "967/967 [==============================] - 1s 579us/sample - loss: 0.0424 - acc: 0.9835 - val_loss: 2.6341 - val_acc: 0.5702\n",
            "Epoch 632/1000\n",
            "967/967 [==============================] - 1s 609us/sample - loss: 0.0525 - acc: 0.9845 - val_loss: 2.5998 - val_acc: 0.5785\n",
            "Epoch 633/1000\n",
            "967/967 [==============================] - 1s 541us/sample - loss: 0.0456 - acc: 0.9886 - val_loss: 2.6014 - val_acc: 0.5868\n",
            "Epoch 634/1000\n",
            "967/967 [==============================] - 0s 506us/sample - loss: 0.0315 - acc: 0.9886 - val_loss: 2.6016 - val_acc: 0.5702\n",
            "Epoch 635/1000\n",
            "967/967 [==============================] - 1s 591us/sample - loss: 0.0704 - acc: 0.9793 - val_loss: 2.6181 - val_acc: 0.5826\n",
            "Epoch 636/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0388 - acc: 0.9886 - val_loss: 2.6612 - val_acc: 0.5744\n",
            "Epoch 637/1000\n",
            "967/967 [==============================] - 1s 600us/sample - loss: 0.0430 - acc: 0.9824 - val_loss: 2.6458 - val_acc: 0.5702\n",
            "Epoch 638/1000\n",
            "967/967 [==============================] - 1s 585us/sample - loss: 0.0327 - acc: 0.9855 - val_loss: 2.6789 - val_acc: 0.5826\n",
            "Epoch 639/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0274 - acc: 0.9886 - val_loss: 2.6985 - val_acc: 0.5950\n",
            "Epoch 640/1000\n",
            "967/967 [==============================] - 1s 621us/sample - loss: 0.0377 - acc: 0.9886 - val_loss: 2.6696 - val_acc: 0.5744\n",
            "Epoch 641/1000\n",
            "967/967 [==============================] - 1s 550us/sample - loss: 0.0604 - acc: 0.9855 - val_loss: 2.6490 - val_acc: 0.5702\n",
            "Epoch 642/1000\n",
            "967/967 [==============================] - 1s 619us/sample - loss: 0.0459 - acc: 0.9917 - val_loss: 2.6576 - val_acc: 0.5661\n",
            "Epoch 643/1000\n",
            "967/967 [==============================] - 1s 575us/sample - loss: 0.0479 - acc: 0.9876 - val_loss: 2.6670 - val_acc: 0.5620\n",
            "Epoch 644/1000\n",
            "967/967 [==============================] - 1s 607us/sample - loss: 0.0400 - acc: 0.9876 - val_loss: 2.6490 - val_acc: 0.5744\n",
            "Epoch 645/1000\n",
            "967/967 [==============================] - 1s 573us/sample - loss: 0.0420 - acc: 0.9824 - val_loss: 2.6447 - val_acc: 0.5744\n",
            "Epoch 646/1000\n",
            "967/967 [==============================] - 1s 563us/sample - loss: 0.0270 - acc: 0.9907 - val_loss: 2.6534 - val_acc: 0.5744\n",
            "Epoch 647/1000\n",
            "967/967 [==============================] - 1s 558us/sample - loss: 0.0258 - acc: 0.9897 - val_loss: 2.6384 - val_acc: 0.5785\n",
            "Epoch 648/1000\n",
            "967/967 [==============================] - 1s 584us/sample - loss: 0.0332 - acc: 0.9886 - val_loss: 2.6313 - val_acc: 0.5744\n",
            "Epoch 649/1000\n",
            "967/967 [==============================] - 1s 564us/sample - loss: 0.0613 - acc: 0.9845 - val_loss: 2.5905 - val_acc: 0.5744\n",
            "Epoch 650/1000\n",
            "967/967 [==============================] - 1s 588us/sample - loss: 0.0405 - acc: 0.9897 - val_loss: 2.5985 - val_acc: 0.5744\n",
            "Epoch 651/1000\n",
            "967/967 [==============================] - 1s 613us/sample - loss: 0.0442 - acc: 0.9886 - val_loss: 2.6377 - val_acc: 0.5661\n",
            "Epoch 652/1000\n",
            "967/967 [==============================] - 1s 595us/sample - loss: 0.0342 - acc: 0.9917 - val_loss: 2.6552 - val_acc: 0.5744\n",
            "Epoch 653/1000\n",
            "967/967 [==============================] - 1s 607us/sample - loss: 0.0443 - acc: 0.9886 - val_loss: 2.6725 - val_acc: 0.5702\n",
            "Epoch 654/1000\n",
            "967/967 [==============================] - 1s 603us/sample - loss: 0.0455 - acc: 0.9866 - val_loss: 2.7289 - val_acc: 0.5868\n",
            "Epoch 655/1000\n",
            "967/967 [==============================] - 1s 561us/sample - loss: 0.0716 - acc: 0.9835 - val_loss: 2.6323 - val_acc: 0.5785\n",
            "Epoch 656/1000\n",
            "967/967 [==============================] - 1s 523us/sample - loss: 0.0298 - acc: 0.9886 - val_loss: 2.6799 - val_acc: 0.5661\n",
            "Epoch 657/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0556 - acc: 0.9814 - val_loss: 2.6315 - val_acc: 0.5702\n",
            "Epoch 658/1000\n",
            "967/967 [==============================] - 1s 620us/sample - loss: 0.0318 - acc: 0.9897 - val_loss: 2.6182 - val_acc: 0.5826\n",
            "Epoch 659/1000\n",
            "967/967 [==============================] - 1s 637us/sample - loss: 0.0320 - acc: 0.9907 - val_loss: 2.6557 - val_acc: 0.5868\n",
            "Epoch 660/1000\n",
            "967/967 [==============================] - 1s 589us/sample - loss: 0.0303 - acc: 0.9907 - val_loss: 2.6363 - val_acc: 0.5661\n",
            "Epoch 661/1000\n",
            "967/967 [==============================] - 1s 616us/sample - loss: 0.0495 - acc: 0.9855 - val_loss: 2.6299 - val_acc: 0.5702\n",
            "Epoch 662/1000\n",
            "967/967 [==============================] - 1s 641us/sample - loss: 0.0429 - acc: 0.9855 - val_loss: 2.6063 - val_acc: 0.5661\n",
            "Epoch 663/1000\n",
            "967/967 [==============================] - 1s 525us/sample - loss: 0.0534 - acc: 0.9793 - val_loss: 2.5628 - val_acc: 0.5537\n",
            "Epoch 664/1000\n",
            "967/967 [==============================] - 1s 543us/sample - loss: 0.0380 - acc: 0.9897 - val_loss: 2.5670 - val_acc: 0.5579\n",
            "Epoch 665/1000\n",
            "967/967 [==============================] - 1s 525us/sample - loss: 0.0275 - acc: 0.9907 - val_loss: 2.5815 - val_acc: 0.5661\n",
            "Epoch 666/1000\n",
            "967/967 [==============================] - 1s 567us/sample - loss: 0.0270 - acc: 0.9897 - val_loss: 2.6190 - val_acc: 0.5661\n",
            "Epoch 667/1000\n",
            "967/967 [==============================] - 1s 606us/sample - loss: 0.0264 - acc: 0.9876 - val_loss: 2.5981 - val_acc: 0.5579\n",
            "Epoch 668/1000\n",
            "967/967 [==============================] - 1s 561us/sample - loss: 0.0456 - acc: 0.9866 - val_loss: 2.5951 - val_acc: 0.5702\n",
            "Epoch 669/1000\n",
            "967/967 [==============================] - 0s 487us/sample - loss: 0.0252 - acc: 0.9876 - val_loss: 2.5945 - val_acc: 0.5579\n",
            "Epoch 670/1000\n",
            "967/967 [==============================] - 1s 525us/sample - loss: 0.0305 - acc: 0.9876 - val_loss: 2.6142 - val_acc: 0.5620\n",
            "Epoch 671/1000\n",
            "967/967 [==============================] - 0s 499us/sample - loss: 0.0252 - acc: 0.9886 - val_loss: 2.6496 - val_acc: 0.5661\n",
            "Epoch 672/1000\n",
            "967/967 [==============================] - 1s 540us/sample - loss: 0.0413 - acc: 0.9866 - val_loss: 2.6670 - val_acc: 0.5702\n",
            "Epoch 673/1000\n",
            "967/967 [==============================] - 1s 553us/sample - loss: 0.0430 - acc: 0.9876 - val_loss: 2.6932 - val_acc: 0.5620\n",
            "Epoch 674/1000\n",
            "967/967 [==============================] - 1s 560us/sample - loss: 0.0347 - acc: 0.9886 - val_loss: 2.6954 - val_acc: 0.5579\n",
            "Epoch 675/1000\n",
            "967/967 [==============================] - 1s 586us/sample - loss: 0.0656 - acc: 0.9866 - val_loss: 2.6869 - val_acc: 0.5702\n",
            "Epoch 676/1000\n",
            "967/967 [==============================] - 1s 546us/sample - loss: 0.0422 - acc: 0.9876 - val_loss: 2.6551 - val_acc: 0.5579\n",
            "Epoch 677/1000\n",
            "967/967 [==============================] - 1s 538us/sample - loss: 0.0383 - acc: 0.9814 - val_loss: 2.6545 - val_acc: 0.5702\n",
            "Epoch 678/1000\n",
            "967/967 [==============================] - 1s 610us/sample - loss: 0.0448 - acc: 0.9886 - val_loss: 2.6892 - val_acc: 0.5868\n",
            "Epoch 679/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0241 - acc: 0.9886 - val_loss: 2.7079 - val_acc: 0.5661\n",
            "Epoch 680/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0423 - acc: 0.9876 - val_loss: 2.7043 - val_acc: 0.5537\n",
            "Epoch 681/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0224 - acc: 0.9938 - val_loss: 2.7000 - val_acc: 0.5455\n",
            "Epoch 682/1000\n",
            "967/967 [==============================] - 1s 530us/sample - loss: 0.0354 - acc: 0.9866 - val_loss: 2.6986 - val_acc: 0.5455\n",
            "Epoch 683/1000\n",
            "967/967 [==============================] - 0s 472us/sample - loss: 0.0446 - acc: 0.9876 - val_loss: 2.6832 - val_acc: 0.5455\n",
            "Epoch 684/1000\n",
            "967/967 [==============================] - 1s 539us/sample - loss: 0.0311 - acc: 0.9897 - val_loss: 2.6733 - val_acc: 0.5579\n",
            "Epoch 685/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0484 - acc: 0.9876 - val_loss: 2.6644 - val_acc: 0.5496\n",
            "Epoch 686/1000\n",
            "967/967 [==============================] - 1s 568us/sample - loss: 0.0497 - acc: 0.9866 - val_loss: 2.6710 - val_acc: 0.5661\n",
            "Epoch 687/1000\n",
            "967/967 [==============================] - 1s 523us/sample - loss: 0.0333 - acc: 0.9897 - val_loss: 2.6528 - val_acc: 0.5744\n",
            "Epoch 688/1000\n",
            "967/967 [==============================] - 1s 646us/sample - loss: 0.0366 - acc: 0.9876 - val_loss: 2.6582 - val_acc: 0.5661\n",
            "Epoch 689/1000\n",
            "967/967 [==============================] - 1s 562us/sample - loss: 0.0265 - acc: 0.9907 - val_loss: 2.6699 - val_acc: 0.5620\n",
            "Epoch 690/1000\n",
            "967/967 [==============================] - 1s 596us/sample - loss: 0.0300 - acc: 0.9928 - val_loss: 2.6601 - val_acc: 0.5620\n",
            "Epoch 691/1000\n",
            "967/967 [==============================] - 1s 587us/sample - loss: 0.0301 - acc: 0.9897 - val_loss: 2.6663 - val_acc: 0.5537\n",
            "Epoch 692/1000\n",
            "967/967 [==============================] - 1s 524us/sample - loss: 0.0329 - acc: 0.9855 - val_loss: 2.6621 - val_acc: 0.5579\n",
            "Epoch 693/1000\n",
            "967/967 [==============================] - 1s 538us/sample - loss: 0.0580 - acc: 0.9897 - val_loss: 2.6294 - val_acc: 0.5661\n",
            "Epoch 694/1000\n",
            "967/967 [==============================] - 1s 526us/sample - loss: 0.0498 - acc: 0.9897 - val_loss: 2.5774 - val_acc: 0.5537\n",
            "Epoch 695/1000\n",
            "967/967 [==============================] - 1s 624us/sample - loss: 0.0639 - acc: 0.9814 - val_loss: 2.5600 - val_acc: 0.5661\n",
            "Epoch 696/1000\n",
            "967/967 [==============================] - 1s 598us/sample - loss: 0.0248 - acc: 0.9886 - val_loss: 2.6206 - val_acc: 0.5661\n",
            "Epoch 697/1000\n",
            "967/967 [==============================] - 1s 537us/sample - loss: 0.0417 - acc: 0.9845 - val_loss: 2.6143 - val_acc: 0.5579\n",
            "Epoch 698/1000\n",
            "967/967 [==============================] - 0s 495us/sample - loss: 0.0559 - acc: 0.9845 - val_loss: 2.6056 - val_acc: 0.5579\n",
            "Epoch 699/1000\n",
            "967/967 [==============================] - 1s 577us/sample - loss: 0.0407 - acc: 0.9886 - val_loss: 2.5994 - val_acc: 0.5826\n",
            "Epoch 700/1000\n",
            "967/967 [==============================] - 1s 584us/sample - loss: 0.0268 - acc: 0.9928 - val_loss: 2.5958 - val_acc: 0.5702\n",
            "Epoch 701/1000\n",
            "967/967 [==============================] - 1s 526us/sample - loss: 0.0260 - acc: 0.9907 - val_loss: 2.6165 - val_acc: 0.5785\n",
            "Epoch 702/1000\n",
            "967/967 [==============================] - 1s 601us/sample - loss: 0.0252 - acc: 0.9897 - val_loss: 2.6396 - val_acc: 0.5661\n",
            "Epoch 703/1000\n",
            "967/967 [==============================] - 1s 632us/sample - loss: 0.0159 - acc: 0.9959 - val_loss: 2.6553 - val_acc: 0.5661\n",
            "Epoch 704/1000\n",
            "967/967 [==============================] - 1s 598us/sample - loss: 0.0268 - acc: 0.9907 - val_loss: 2.6706 - val_acc: 0.5537\n",
            "Epoch 705/1000\n",
            "967/967 [==============================] - 1s 589us/sample - loss: 0.0343 - acc: 0.9907 - val_loss: 2.6591 - val_acc: 0.5579\n",
            "Epoch 706/1000\n",
            "967/967 [==============================] - 1s 598us/sample - loss: 0.0292 - acc: 0.9897 - val_loss: 2.6506 - val_acc: 0.5537\n",
            "Epoch 707/1000\n",
            "967/967 [==============================] - 0s 504us/sample - loss: 0.0459 - acc: 0.9835 - val_loss: 2.6421 - val_acc: 0.5496\n",
            "Epoch 708/1000\n",
            "967/967 [==============================] - 1s 654us/sample - loss: 0.0423 - acc: 0.9855 - val_loss: 2.6375 - val_acc: 0.5579\n",
            "Epoch 709/1000\n",
            "967/967 [==============================] - 1s 567us/sample - loss: 0.0480 - acc: 0.9876 - val_loss: 2.6738 - val_acc: 0.5620\n",
            "Epoch 710/1000\n",
            "967/967 [==============================] - 1s 601us/sample - loss: 0.0404 - acc: 0.9876 - val_loss: 2.6560 - val_acc: 0.5785\n",
            "Epoch 711/1000\n",
            "967/967 [==============================] - 1s 566us/sample - loss: 0.0384 - acc: 0.9886 - val_loss: 2.6668 - val_acc: 0.5661\n",
            "Epoch 712/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0348 - acc: 0.9845 - val_loss: 2.6766 - val_acc: 0.5661\n",
            "Epoch 713/1000\n",
            "967/967 [==============================] - 1s 580us/sample - loss: 0.0246 - acc: 0.9928 - val_loss: 2.6746 - val_acc: 0.5661\n",
            "Epoch 714/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0373 - acc: 0.9897 - val_loss: 2.6968 - val_acc: 0.5868\n",
            "Epoch 715/1000\n",
            "967/967 [==============================] - 1s 608us/sample - loss: 0.0544 - acc: 0.9804 - val_loss: 2.7006 - val_acc: 0.5909\n",
            "Epoch 716/1000\n",
            "967/967 [==============================] - 1s 558us/sample - loss: 0.0502 - acc: 0.9824 - val_loss: 2.6706 - val_acc: 0.5744\n",
            "Epoch 717/1000\n",
            "967/967 [==============================] - 1s 549us/sample - loss: 0.0378 - acc: 0.9876 - val_loss: 2.6455 - val_acc: 0.5868\n",
            "Epoch 718/1000\n",
            "967/967 [==============================] - 1s 605us/sample - loss: 0.0439 - acc: 0.9845 - val_loss: 2.6594 - val_acc: 0.5785\n",
            "Epoch 719/1000\n",
            "967/967 [==============================] - 0s 509us/sample - loss: 0.0334 - acc: 0.9855 - val_loss: 2.6369 - val_acc: 0.5785\n",
            "Epoch 720/1000\n",
            "967/967 [==============================] - 1s 544us/sample - loss: 0.0296 - acc: 0.9866 - val_loss: 2.6168 - val_acc: 0.5744\n",
            "Epoch 721/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0492 - acc: 0.9855 - val_loss: 2.6372 - val_acc: 0.5537\n",
            "Epoch 722/1000\n",
            "967/967 [==============================] - 1s 567us/sample - loss: 0.0456 - acc: 0.9824 - val_loss: 2.6234 - val_acc: 0.5702\n",
            "Epoch 723/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0350 - acc: 0.9907 - val_loss: 2.6520 - val_acc: 0.5702\n",
            "Epoch 724/1000\n",
            "967/967 [==============================] - 0s 510us/sample - loss: 0.0482 - acc: 0.9907 - val_loss: 2.6775 - val_acc: 0.5868\n",
            "Epoch 725/1000\n",
            "967/967 [==============================] - 1s 555us/sample - loss: 0.0899 - acc: 0.9814 - val_loss: 2.6510 - val_acc: 0.5537\n",
            "Epoch 726/1000\n",
            "967/967 [==============================] - 1s 587us/sample - loss: 0.0359 - acc: 0.9866 - val_loss: 2.6549 - val_acc: 0.5537\n",
            "Epoch 727/1000\n",
            "967/967 [==============================] - 1s 590us/sample - loss: 0.0397 - acc: 0.9876 - val_loss: 2.6880 - val_acc: 0.5579\n",
            "Epoch 728/1000\n",
            "967/967 [==============================] - 1s 611us/sample - loss: 0.0304 - acc: 0.9907 - val_loss: 2.6891 - val_acc: 0.5496\n",
            "Epoch 729/1000\n",
            "967/967 [==============================] - 1s 559us/sample - loss: 0.0347 - acc: 0.9876 - val_loss: 2.6425 - val_acc: 0.5537\n",
            "Epoch 730/1000\n",
            "967/967 [==============================] - 0s 486us/sample - loss: 0.0300 - acc: 0.9938 - val_loss: 2.6347 - val_acc: 0.5537\n",
            "Epoch 731/1000\n",
            "967/967 [==============================] - 0s 515us/sample - loss: 0.0318 - acc: 0.9886 - val_loss: 2.6571 - val_acc: 0.5537\n",
            "Epoch 732/1000\n",
            "967/967 [==============================] - 1s 521us/sample - loss: 0.0391 - acc: 0.9866 - val_loss: 2.6780 - val_acc: 0.5785\n",
            "Epoch 733/1000\n",
            "967/967 [==============================] - 1s 607us/sample - loss: 0.0543 - acc: 0.9835 - val_loss: 2.6897 - val_acc: 0.5455\n",
            "Epoch 734/1000\n",
            "967/967 [==============================] - 1s 590us/sample - loss: 0.0130 - acc: 0.9969 - val_loss: 2.6905 - val_acc: 0.5702\n",
            "Epoch 735/1000\n",
            "967/967 [==============================] - 1s 582us/sample - loss: 0.0288 - acc: 0.9886 - val_loss: 2.7142 - val_acc: 0.5744\n",
            "Epoch 736/1000\n",
            "967/967 [==============================] - 0s 515us/sample - loss: 0.0295 - acc: 0.9897 - val_loss: 2.7343 - val_acc: 0.5661\n",
            "Epoch 737/1000\n",
            "967/967 [==============================] - 1s 537us/sample - loss: 0.0320 - acc: 0.9917 - val_loss: 2.7553 - val_acc: 0.5950\n",
            "Epoch 738/1000\n",
            "967/967 [==============================] - 1s 633us/sample - loss: 0.0356 - acc: 0.9897 - val_loss: 2.7419 - val_acc: 0.5826\n",
            "Epoch 739/1000\n",
            "967/967 [==============================] - 1s 539us/sample - loss: 0.0523 - acc: 0.9866 - val_loss: 2.7136 - val_acc: 0.5744\n",
            "Epoch 740/1000\n",
            "967/967 [==============================] - 1s 619us/sample - loss: 0.0511 - acc: 0.9855 - val_loss: 2.6786 - val_acc: 0.5868\n",
            "Epoch 741/1000\n",
            "967/967 [==============================] - 1s 523us/sample - loss: 0.0313 - acc: 0.9928 - val_loss: 2.6475 - val_acc: 0.5785\n",
            "Epoch 742/1000\n",
            "967/967 [==============================] - 1s 536us/sample - loss: 0.0534 - acc: 0.9855 - val_loss: 2.6640 - val_acc: 0.5744\n",
            "Epoch 743/1000\n",
            "967/967 [==============================] - 1s 568us/sample - loss: 0.0417 - acc: 0.9845 - val_loss: 2.6715 - val_acc: 0.5868\n",
            "Epoch 744/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0266 - acc: 0.9928 - val_loss: 2.6698 - val_acc: 0.5826\n",
            "Epoch 745/1000\n",
            "967/967 [==============================] - 1s 590us/sample - loss: 0.0394 - acc: 0.9907 - val_loss: 2.6554 - val_acc: 0.5868\n",
            "Epoch 746/1000\n",
            "967/967 [==============================] - 1s 555us/sample - loss: 0.0281 - acc: 0.9917 - val_loss: 2.6709 - val_acc: 0.5702\n",
            "Epoch 747/1000\n",
            "967/967 [==============================] - 1s 600us/sample - loss: 0.0458 - acc: 0.9824 - val_loss: 2.6883 - val_acc: 0.5826\n",
            "Epoch 748/1000\n",
            "967/967 [==============================] - 1s 606us/sample - loss: 0.0871 - acc: 0.9772 - val_loss: 2.6566 - val_acc: 0.5868\n",
            "Epoch 749/1000\n",
            "967/967 [==============================] - 1s 612us/sample - loss: 0.0401 - acc: 0.9866 - val_loss: 2.6803 - val_acc: 0.5992\n",
            "Epoch 750/1000\n",
            "967/967 [==============================] - 1s 552us/sample - loss: 0.0273 - acc: 0.9907 - val_loss: 2.6613 - val_acc: 0.5826\n",
            "Epoch 751/1000\n",
            "967/967 [==============================] - 1s 530us/sample - loss: 0.0420 - acc: 0.9835 - val_loss: 2.6686 - val_acc: 0.5909\n",
            "Epoch 752/1000\n",
            "967/967 [==============================] - 1s 542us/sample - loss: 0.0408 - acc: 0.9886 - val_loss: 2.6480 - val_acc: 0.5868\n",
            "Epoch 753/1000\n",
            "967/967 [==============================] - 1s 562us/sample - loss: 0.0261 - acc: 0.9917 - val_loss: 2.6402 - val_acc: 0.5744\n",
            "Epoch 754/1000\n",
            "967/967 [==============================] - 1s 562us/sample - loss: 0.0520 - acc: 0.9824 - val_loss: 2.6097 - val_acc: 0.5785\n",
            "Epoch 755/1000\n",
            "967/967 [==============================] - 1s 628us/sample - loss: 0.0658 - acc: 0.9804 - val_loss: 2.6118 - val_acc: 0.5702\n",
            "Epoch 756/1000\n",
            "967/967 [==============================] - 1s 593us/sample - loss: 0.0387 - acc: 0.9886 - val_loss: 2.6396 - val_acc: 0.5744\n",
            "Epoch 757/1000\n",
            "967/967 [==============================] - 1s 644us/sample - loss: 0.0371 - acc: 0.9876 - val_loss: 2.6361 - val_acc: 0.5992\n",
            "Epoch 758/1000\n",
            "967/967 [==============================] - 1s 592us/sample - loss: 0.0696 - acc: 0.9814 - val_loss: 2.6531 - val_acc: 0.5909\n",
            "Epoch 759/1000\n",
            "967/967 [==============================] - 1s 540us/sample - loss: 0.0624 - acc: 0.9855 - val_loss: 2.6395 - val_acc: 0.5868\n",
            "Epoch 760/1000\n",
            "967/967 [==============================] - 1s 540us/sample - loss: 0.0490 - acc: 0.9876 - val_loss: 2.5984 - val_acc: 0.5744\n",
            "Epoch 761/1000\n",
            "967/967 [==============================] - 0s 496us/sample - loss: 0.0256 - acc: 0.9928 - val_loss: 2.6007 - val_acc: 0.5744\n",
            "Epoch 762/1000\n",
            "967/967 [==============================] - 1s 529us/sample - loss: 0.0409 - acc: 0.9866 - val_loss: 2.6116 - val_acc: 0.5785\n",
            "Epoch 763/1000\n",
            "967/967 [==============================] - 1s 634us/sample - loss: 0.0422 - acc: 0.9917 - val_loss: 2.6322 - val_acc: 0.5950\n",
            "Epoch 764/1000\n",
            "967/967 [==============================] - 0s 508us/sample - loss: 0.0421 - acc: 0.9835 - val_loss: 2.6270 - val_acc: 0.6074\n",
            "Epoch 765/1000\n",
            "967/967 [==============================] - 1s 553us/sample - loss: 0.0249 - acc: 0.9897 - val_loss: 2.6127 - val_acc: 0.5909\n",
            "Epoch 766/1000\n",
            "967/967 [==============================] - 0s 489us/sample - loss: 0.0351 - acc: 0.9897 - val_loss: 2.6139 - val_acc: 0.5868\n",
            "Epoch 767/1000\n",
            "967/967 [==============================] - 1s 582us/sample - loss: 0.0235 - acc: 0.9886 - val_loss: 2.6291 - val_acc: 0.5785\n",
            "Epoch 768/1000\n",
            "967/967 [==============================] - 1s 569us/sample - loss: 0.0305 - acc: 0.9886 - val_loss: 2.6477 - val_acc: 0.5702\n",
            "Epoch 769/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0522 - acc: 0.9855 - val_loss: 2.6626 - val_acc: 0.5785\n",
            "Epoch 770/1000\n",
            "967/967 [==============================] - 1s 626us/sample - loss: 0.0503 - acc: 0.9907 - val_loss: 2.6575 - val_acc: 0.5785\n",
            "Epoch 771/1000\n",
            "967/967 [==============================] - 1s 593us/sample - loss: 0.0639 - acc: 0.9886 - val_loss: 2.6427 - val_acc: 0.5661\n",
            "Epoch 772/1000\n",
            "967/967 [==============================] - 1s 631us/sample - loss: 0.0283 - acc: 0.9917 - val_loss: 2.6692 - val_acc: 0.5702\n",
            "Epoch 773/1000\n",
            "967/967 [==============================] - 1s 579us/sample - loss: 0.0359 - acc: 0.9897 - val_loss: 2.6934 - val_acc: 0.5702\n",
            "Epoch 774/1000\n",
            "967/967 [==============================] - 1s 573us/sample - loss: 0.0462 - acc: 0.9855 - val_loss: 2.7243 - val_acc: 0.5744\n",
            "Epoch 775/1000\n",
            "967/967 [==============================] - 1s 606us/sample - loss: 0.0246 - acc: 0.9907 - val_loss: 2.7305 - val_acc: 0.5661\n",
            "Epoch 776/1000\n",
            "967/967 [==============================] - 1s 612us/sample - loss: 0.0250 - acc: 0.9897 - val_loss: 2.7209 - val_acc: 0.5744\n",
            "Epoch 777/1000\n",
            "967/967 [==============================] - 1s 581us/sample - loss: 0.0371 - acc: 0.9855 - val_loss: 2.7245 - val_acc: 0.5785\n",
            "Epoch 778/1000\n",
            "967/967 [==============================] - 1s 564us/sample - loss: 0.0496 - acc: 0.9845 - val_loss: 2.7421 - val_acc: 0.5826\n",
            "Epoch 779/1000\n",
            "967/967 [==============================] - 0s 507us/sample - loss: 0.0288 - acc: 0.9886 - val_loss: 2.7143 - val_acc: 0.5826\n",
            "Epoch 780/1000\n",
            "967/967 [==============================] - 1s 568us/sample - loss: 0.0522 - acc: 0.9855 - val_loss: 2.6613 - val_acc: 0.5868\n",
            "Epoch 781/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0368 - acc: 0.9938 - val_loss: 2.6170 - val_acc: 0.5868\n",
            "Epoch 782/1000\n",
            "967/967 [==============================] - 1s 557us/sample - loss: 0.0421 - acc: 0.9835 - val_loss: 2.6233 - val_acc: 0.5868\n",
            "Epoch 783/1000\n",
            "967/967 [==============================] - 1s 603us/sample - loss: 0.0322 - acc: 0.9876 - val_loss: 2.6447 - val_acc: 0.5826\n",
            "Epoch 784/1000\n",
            "967/967 [==============================] - 1s 597us/sample - loss: 0.0241 - acc: 0.9928 - val_loss: 2.6878 - val_acc: 0.5785\n",
            "Epoch 785/1000\n",
            "967/967 [==============================] - 1s 581us/sample - loss: 0.0481 - acc: 0.9845 - val_loss: 2.6621 - val_acc: 0.5785\n",
            "Epoch 786/1000\n",
            "967/967 [==============================] - 1s 606us/sample - loss: 0.0749 - acc: 0.9876 - val_loss: 2.6535 - val_acc: 0.5826\n",
            "Epoch 787/1000\n",
            "967/967 [==============================] - 1s 575us/sample - loss: 0.0249 - acc: 0.9907 - val_loss: 2.6644 - val_acc: 0.5785\n",
            "Epoch 788/1000\n",
            "967/967 [==============================] - 1s 620us/sample - loss: 0.0317 - acc: 0.9886 - val_loss: 2.6915 - val_acc: 0.5785\n",
            "Epoch 789/1000\n",
            "967/967 [==============================] - 1s 527us/sample - loss: 0.0310 - acc: 0.9876 - val_loss: 2.7175 - val_acc: 0.5702\n",
            "Epoch 790/1000\n",
            "967/967 [==============================] - 1s 534us/sample - loss: 0.0479 - acc: 0.9886 - val_loss: 2.7208 - val_acc: 0.5537\n",
            "Epoch 791/1000\n",
            "967/967 [==============================] - 1s 595us/sample - loss: 0.0410 - acc: 0.9886 - val_loss: 2.7566 - val_acc: 0.5785\n",
            "Epoch 792/1000\n",
            "967/967 [==============================] - 1s 590us/sample - loss: 0.0274 - acc: 0.9897 - val_loss: 2.7513 - val_acc: 0.5909\n",
            "Epoch 793/1000\n",
            "967/967 [==============================] - 1s 600us/sample - loss: 0.0660 - acc: 0.9866 - val_loss: 2.7342 - val_acc: 0.5826\n",
            "Epoch 794/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0323 - acc: 0.9897 - val_loss: 2.7567 - val_acc: 0.5702\n",
            "Epoch 795/1000\n",
            "967/967 [==============================] - 1s 532us/sample - loss: 0.0285 - acc: 0.9897 - val_loss: 2.7687 - val_acc: 0.5785\n",
            "Epoch 796/1000\n",
            "967/967 [==============================] - 1s 536us/sample - loss: 0.0270 - acc: 0.9928 - val_loss: 2.7571 - val_acc: 0.5702\n",
            "Epoch 797/1000\n",
            "967/967 [==============================] - 1s 632us/sample - loss: 0.0303 - acc: 0.9886 - val_loss: 2.7642 - val_acc: 0.5909\n",
            "Epoch 798/1000\n",
            "967/967 [==============================] - 1s 552us/sample - loss: 0.0432 - acc: 0.9845 - val_loss: 2.6873 - val_acc: 0.5868\n",
            "Epoch 799/1000\n",
            "967/967 [==============================] - 1s 608us/sample - loss: 0.0320 - acc: 0.9897 - val_loss: 2.6899 - val_acc: 0.5868\n",
            "Epoch 800/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0310 - acc: 0.9917 - val_loss: 2.7073 - val_acc: 0.5992\n",
            "Epoch 801/1000\n",
            "967/967 [==============================] - 1s 535us/sample - loss: 0.0412 - acc: 0.9897 - val_loss: 2.7067 - val_acc: 0.5868\n",
            "Epoch 802/1000\n",
            "967/967 [==============================] - 1s 533us/sample - loss: 0.0269 - acc: 0.9897 - val_loss: 2.7208 - val_acc: 0.5826\n",
            "Epoch 803/1000\n",
            "967/967 [==============================] - 1s 539us/sample - loss: 0.0179 - acc: 0.9917 - val_loss: 2.7326 - val_acc: 0.5785\n",
            "Epoch 804/1000\n",
            "967/967 [==============================] - 0s 504us/sample - loss: 0.0383 - acc: 0.9866 - val_loss: 2.7328 - val_acc: 0.5826\n",
            "Epoch 805/1000\n",
            "967/967 [==============================] - 0s 493us/sample - loss: 0.0326 - acc: 0.9876 - val_loss: 2.7500 - val_acc: 0.5992\n",
            "Epoch 806/1000\n",
            "967/967 [==============================] - 1s 538us/sample - loss: 0.0315 - acc: 0.9897 - val_loss: 2.7395 - val_acc: 0.5992\n",
            "Epoch 807/1000\n",
            "967/967 [==============================] - 1s 553us/sample - loss: 0.0563 - acc: 0.9866 - val_loss: 2.7293 - val_acc: 0.5868\n",
            "Epoch 808/1000\n",
            "967/967 [==============================] - 1s 615us/sample - loss: 0.0147 - acc: 0.9969 - val_loss: 2.7557 - val_acc: 0.5826\n",
            "Epoch 809/1000\n",
            "967/967 [==============================] - 1s 585us/sample - loss: 0.0397 - acc: 0.9866 - val_loss: 2.7767 - val_acc: 0.5785\n",
            "Epoch 810/1000\n",
            "967/967 [==============================] - 1s 559us/sample - loss: 0.0345 - acc: 0.9876 - val_loss: 2.7877 - val_acc: 0.5826\n",
            "Epoch 811/1000\n",
            "967/967 [==============================] - 1s 552us/sample - loss: 0.0737 - acc: 0.9772 - val_loss: 2.7337 - val_acc: 0.5950\n",
            "Epoch 812/1000\n",
            "967/967 [==============================] - 1s 536us/sample - loss: 0.0527 - acc: 0.9855 - val_loss: 2.6868 - val_acc: 0.5744\n",
            "Epoch 813/1000\n",
            "967/967 [==============================] - 1s 635us/sample - loss: 0.0508 - acc: 0.9876 - val_loss: 2.6926 - val_acc: 0.5744\n",
            "Epoch 814/1000\n",
            "967/967 [==============================] - 1s 559us/sample - loss: 0.0354 - acc: 0.9876 - val_loss: 2.6584 - val_acc: 0.5702\n",
            "Epoch 815/1000\n",
            "967/967 [==============================] - 1s 617us/sample - loss: 0.0305 - acc: 0.9907 - val_loss: 2.6666 - val_acc: 0.5950\n",
            "Epoch 816/1000\n",
            "967/967 [==============================] - 1s 601us/sample - loss: 0.0313 - acc: 0.9948 - val_loss: 2.6469 - val_acc: 0.6033\n",
            "Epoch 817/1000\n",
            "967/967 [==============================] - 1s 615us/sample - loss: 0.0100 - acc: 0.9990 - val_loss: 2.6820 - val_acc: 0.6074\n",
            "Epoch 818/1000\n",
            "967/967 [==============================] - 1s 617us/sample - loss: 0.0344 - acc: 0.9917 - val_loss: 2.7111 - val_acc: 0.5868\n",
            "Epoch 819/1000\n",
            "967/967 [==============================] - 1s 531us/sample - loss: 0.0395 - acc: 0.9907 - val_loss: 2.6928 - val_acc: 0.6033\n",
            "Epoch 820/1000\n",
            "967/967 [==============================] - 1s 540us/sample - loss: 0.0431 - acc: 0.9876 - val_loss: 2.6953 - val_acc: 0.5785\n",
            "Epoch 821/1000\n",
            "967/967 [==============================] - 0s 485us/sample - loss: 0.0285 - acc: 0.9917 - val_loss: 2.6885 - val_acc: 0.5909\n",
            "Epoch 822/1000\n",
            "967/967 [==============================] - 1s 612us/sample - loss: 0.0327 - acc: 0.9897 - val_loss: 2.6974 - val_acc: 0.5950\n",
            "Epoch 823/1000\n",
            "967/967 [==============================] - 1s 558us/sample - loss: 0.0254 - acc: 0.9907 - val_loss: 2.6930 - val_acc: 0.5868\n",
            "Epoch 824/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0493 - acc: 0.9835 - val_loss: 2.6909 - val_acc: 0.5992\n",
            "Epoch 825/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0476 - acc: 0.9845 - val_loss: 2.6692 - val_acc: 0.6074\n",
            "Epoch 826/1000\n",
            "967/967 [==============================] - 1s 584us/sample - loss: 0.0331 - acc: 0.9897 - val_loss: 2.6769 - val_acc: 0.6033\n",
            "Epoch 827/1000\n",
            "967/967 [==============================] - 0s 502us/sample - loss: 0.0531 - acc: 0.9814 - val_loss: 2.6697 - val_acc: 0.6116\n",
            "Epoch 828/1000\n",
            "967/967 [==============================] - 1s 551us/sample - loss: 0.0332 - acc: 0.9928 - val_loss: 2.6796 - val_acc: 0.6074\n",
            "Epoch 829/1000\n",
            "967/967 [==============================] - 1s 567us/sample - loss: 0.0435 - acc: 0.9866 - val_loss: 2.7181 - val_acc: 0.5744\n",
            "Epoch 830/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0266 - acc: 0.9938 - val_loss: 2.6870 - val_acc: 0.5744\n",
            "Epoch 831/1000\n",
            "967/967 [==============================] - 1s 586us/sample - loss: 0.0432 - acc: 0.9876 - val_loss: 2.6714 - val_acc: 0.5702\n",
            "Epoch 832/1000\n",
            "967/967 [==============================] - 1s 585us/sample - loss: 0.0578 - acc: 0.9907 - val_loss: 2.6584 - val_acc: 0.5661\n",
            "Epoch 833/1000\n",
            "967/967 [==============================] - 0s 506us/sample - loss: 0.0385 - acc: 0.9845 - val_loss: 2.6795 - val_acc: 0.5909\n",
            "Epoch 834/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0356 - acc: 0.9855 - val_loss: 2.7044 - val_acc: 0.5868\n",
            "Epoch 835/1000\n",
            "967/967 [==============================] - 1s 623us/sample - loss: 0.0373 - acc: 0.9876 - val_loss: 2.7376 - val_acc: 0.5744\n",
            "Epoch 836/1000\n",
            "967/967 [==============================] - 1s 626us/sample - loss: 0.0248 - acc: 0.9928 - val_loss: 2.7677 - val_acc: 0.5785\n",
            "Epoch 837/1000\n",
            "967/967 [==============================] - 0s 516us/sample - loss: 0.0327 - acc: 0.9886 - val_loss: 2.7565 - val_acc: 0.5702\n",
            "Epoch 838/1000\n",
            "967/967 [==============================] - 1s 534us/sample - loss: 0.0365 - acc: 0.9897 - val_loss: 2.7548 - val_acc: 0.5868\n",
            "Epoch 839/1000\n",
            "967/967 [==============================] - 1s 585us/sample - loss: 0.0418 - acc: 0.9876 - val_loss: 2.7321 - val_acc: 0.5826\n",
            "Epoch 840/1000\n",
            "967/967 [==============================] - 1s 604us/sample - loss: 0.0499 - acc: 0.9866 - val_loss: 2.6910 - val_acc: 0.5702\n",
            "Epoch 841/1000\n",
            "967/967 [==============================] - 1s 572us/sample - loss: 0.0200 - acc: 0.9917 - val_loss: 2.7145 - val_acc: 0.5744\n",
            "Epoch 842/1000\n",
            "967/967 [==============================] - 1s 580us/sample - loss: 0.0463 - acc: 0.9845 - val_loss: 2.7299 - val_acc: 0.5744\n",
            "Epoch 843/1000\n",
            "967/967 [==============================] - 1s 587us/sample - loss: 0.0558 - acc: 0.9855 - val_loss: 2.7043 - val_acc: 0.5785\n",
            "Epoch 844/1000\n",
            "967/967 [==============================] - 1s 583us/sample - loss: 0.0591 - acc: 0.9917 - val_loss: 2.7237 - val_acc: 0.5826\n",
            "Epoch 845/1000\n",
            "967/967 [==============================] - 0s 499us/sample - loss: 0.0582 - acc: 0.9814 - val_loss: 2.7523 - val_acc: 0.5909\n",
            "Epoch 846/1000\n",
            "967/967 [==============================] - 1s 584us/sample - loss: 0.0719 - acc: 0.9835 - val_loss: 2.7676 - val_acc: 0.5909\n",
            "Epoch 847/1000\n",
            "967/967 [==============================] - 1s 586us/sample - loss: 0.0455 - acc: 0.9855 - val_loss: 2.7173 - val_acc: 0.5826\n",
            "Epoch 848/1000\n",
            "967/967 [==============================] - 1s 593us/sample - loss: 0.0420 - acc: 0.9845 - val_loss: 2.7480 - val_acc: 0.5868\n",
            "Epoch 849/1000\n",
            "967/967 [==============================] - 1s 560us/sample - loss: 0.0384 - acc: 0.9897 - val_loss: 2.7094 - val_acc: 0.5868\n",
            "Epoch 850/1000\n",
            "967/967 [==============================] - 1s 590us/sample - loss: 0.0550 - acc: 0.9772 - val_loss: 2.7234 - val_acc: 0.5868\n",
            "Epoch 851/1000\n",
            "967/967 [==============================] - 1s 580us/sample - loss: 0.0592 - acc: 0.9855 - val_loss: 2.6979 - val_acc: 0.5868\n",
            "Epoch 852/1000\n",
            "967/967 [==============================] - 1s 569us/sample - loss: 0.0256 - acc: 0.9948 - val_loss: 2.7006 - val_acc: 0.5868\n",
            "Epoch 853/1000\n",
            "967/967 [==============================] - 0s 480us/sample - loss: 0.0438 - acc: 0.9886 - val_loss: 2.7103 - val_acc: 0.5826\n",
            "Epoch 854/1000\n",
            "967/967 [==============================] - 1s 550us/sample - loss: 0.0673 - acc: 0.9814 - val_loss: 2.7033 - val_acc: 0.5826\n",
            "Epoch 855/1000\n",
            "967/967 [==============================] - 1s 620us/sample - loss: 0.0274 - acc: 0.9917 - val_loss: 2.7038 - val_acc: 0.5826\n",
            "Epoch 856/1000\n",
            "967/967 [==============================] - 1s 548us/sample - loss: 0.0293 - acc: 0.9907 - val_loss: 2.7311 - val_acc: 0.5868\n",
            "Epoch 857/1000\n",
            "967/967 [==============================] - 1s 614us/sample - loss: 0.0303 - acc: 0.9876 - val_loss: 2.7296 - val_acc: 0.5950\n",
            "Epoch 858/1000\n",
            "967/967 [==============================] - 1s 538us/sample - loss: 0.0354 - acc: 0.9897 - val_loss: 2.7143 - val_acc: 0.5868\n",
            "Epoch 859/1000\n",
            "967/967 [==============================] - 1s 572us/sample - loss: 0.0226 - acc: 0.9917 - val_loss: 2.7291 - val_acc: 0.5909\n",
            "Epoch 860/1000\n",
            "967/967 [==============================] - 1s 551us/sample - loss: 0.0273 - acc: 0.9897 - val_loss: 2.7299 - val_acc: 0.5909\n",
            "Epoch 861/1000\n",
            "967/967 [==============================] - 1s 531us/sample - loss: 0.0333 - acc: 0.9866 - val_loss: 2.6971 - val_acc: 0.5950\n",
            "Epoch 862/1000\n",
            "967/967 [==============================] - 1s 539us/sample - loss: 0.0421 - acc: 0.9886 - val_loss: 2.6726 - val_acc: 0.5826\n",
            "Epoch 863/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0295 - acc: 0.9928 - val_loss: 2.6611 - val_acc: 0.5785\n",
            "Epoch 864/1000\n",
            "967/967 [==============================] - 1s 582us/sample - loss: 0.0314 - acc: 0.9917 - val_loss: 2.6661 - val_acc: 0.5868\n",
            "Epoch 865/1000\n",
            "967/967 [==============================] - 1s 608us/sample - loss: 0.0481 - acc: 0.9907 - val_loss: 2.6603 - val_acc: 0.5909\n",
            "Epoch 866/1000\n",
            "967/967 [==============================] - 1s 552us/sample - loss: 0.0374 - acc: 0.9876 - val_loss: 2.6672 - val_acc: 0.5950\n",
            "Epoch 867/1000\n",
            "967/967 [==============================] - 1s 562us/sample - loss: 0.0538 - acc: 0.9928 - val_loss: 2.6861 - val_acc: 0.5992\n",
            "Epoch 868/1000\n",
            "967/967 [==============================] - 1s 552us/sample - loss: 0.0287 - acc: 0.9928 - val_loss: 2.6922 - val_acc: 0.5909\n",
            "Epoch 869/1000\n",
            "967/967 [==============================] - 0s 503us/sample - loss: 0.0592 - acc: 0.9835 - val_loss: 2.6624 - val_acc: 0.5702\n",
            "Epoch 870/1000\n",
            "967/967 [==============================] - 1s 598us/sample - loss: 0.0413 - acc: 0.9907 - val_loss: 2.7062 - val_acc: 0.5661\n",
            "Epoch 871/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0227 - acc: 0.9897 - val_loss: 2.7192 - val_acc: 0.5702\n",
            "Epoch 872/1000\n",
            "967/967 [==============================] - 1s 561us/sample - loss: 0.0460 - acc: 0.9845 - val_loss: 2.7450 - val_acc: 0.5744\n",
            "Epoch 873/1000\n",
            "967/967 [==============================] - 1s 626us/sample - loss: 0.0417 - acc: 0.9876 - val_loss: 2.7577 - val_acc: 0.5702\n",
            "Epoch 874/1000\n",
            "967/967 [==============================] - 1s 643us/sample - loss: 0.0479 - acc: 0.9866 - val_loss: 2.7557 - val_acc: 0.5744\n",
            "Epoch 875/1000\n",
            "967/967 [==============================] - 0s 500us/sample - loss: 0.0403 - acc: 0.9886 - val_loss: 2.7187 - val_acc: 0.5868\n",
            "Epoch 876/1000\n",
            "967/967 [==============================] - 1s 601us/sample - loss: 0.0457 - acc: 0.9835 - val_loss: 2.6906 - val_acc: 0.5909\n",
            "Epoch 877/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0465 - acc: 0.9886 - val_loss: 2.7097 - val_acc: 0.5909\n",
            "Epoch 878/1000\n",
            "967/967 [==============================] - 1s 586us/sample - loss: 0.0300 - acc: 0.9897 - val_loss: 2.6946 - val_acc: 0.5661\n",
            "Epoch 879/1000\n",
            "967/967 [==============================] - 1s 559us/sample - loss: 0.0430 - acc: 0.9855 - val_loss: 2.6985 - val_acc: 0.5785\n",
            "Epoch 880/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0430 - acc: 0.9866 - val_loss: 2.7128 - val_acc: 0.5702\n",
            "Epoch 881/1000\n",
            "967/967 [==============================] - 1s 562us/sample - loss: 0.0413 - acc: 0.9886 - val_loss: 2.7014 - val_acc: 0.5702\n",
            "Epoch 882/1000\n",
            "967/967 [==============================] - 1s 531us/sample - loss: 0.0384 - acc: 0.9866 - val_loss: 2.6847 - val_acc: 0.5744\n",
            "Epoch 883/1000\n",
            "967/967 [==============================] - 0s 501us/sample - loss: 0.0242 - acc: 0.9948 - val_loss: 2.6791 - val_acc: 0.5661\n",
            "Epoch 884/1000\n",
            "967/967 [==============================] - 1s 549us/sample - loss: 0.0510 - acc: 0.9835 - val_loss: 2.6341 - val_acc: 0.5661\n",
            "Epoch 885/1000\n",
            "967/967 [==============================] - 1s 571us/sample - loss: 0.0407 - acc: 0.9897 - val_loss: 2.6595 - val_acc: 0.5702\n",
            "Epoch 886/1000\n",
            "967/967 [==============================] - 1s 573us/sample - loss: 0.0275 - acc: 0.9866 - val_loss: 2.7180 - val_acc: 0.5909\n",
            "Epoch 887/1000\n",
            "967/967 [==============================] - 1s 603us/sample - loss: 0.0400 - acc: 0.9855 - val_loss: 2.7497 - val_acc: 0.5785\n",
            "Epoch 888/1000\n",
            "967/967 [==============================] - 1s 553us/sample - loss: 0.0423 - acc: 0.9886 - val_loss: 2.7474 - val_acc: 0.5661\n",
            "Epoch 889/1000\n",
            "967/967 [==============================] - 1s 570us/sample - loss: 0.0263 - acc: 0.9928 - val_loss: 2.7863 - val_acc: 0.5620\n",
            "Epoch 890/1000\n",
            "967/967 [==============================] - 1s 574us/sample - loss: 0.0396 - acc: 0.9824 - val_loss: 2.7953 - val_acc: 0.5661\n",
            "Epoch 891/1000\n",
            "967/967 [==============================] - 1s 553us/sample - loss: 0.0423 - acc: 0.9845 - val_loss: 2.7909 - val_acc: 0.5702\n",
            "Epoch 892/1000\n",
            "967/967 [==============================] - 1s 566us/sample - loss: 0.0427 - acc: 0.9917 - val_loss: 2.7696 - val_acc: 0.5785\n",
            "Epoch 893/1000\n",
            "967/967 [==============================] - 1s 600us/sample - loss: 0.0431 - acc: 0.9855 - val_loss: 2.7571 - val_acc: 0.5744\n",
            "Epoch 894/1000\n",
            "967/967 [==============================] - 1s 535us/sample - loss: 0.0215 - acc: 0.9928 - val_loss: 2.7741 - val_acc: 0.5661\n",
            "Epoch 895/1000\n",
            "967/967 [==============================] - 1s 541us/sample - loss: 0.0326 - acc: 0.9897 - val_loss: 2.7645 - val_acc: 0.5661\n",
            "Epoch 896/1000\n",
            "967/967 [==============================] - 1s 564us/sample - loss: 0.0386 - acc: 0.9866 - val_loss: 2.7249 - val_acc: 0.5661\n",
            "Epoch 897/1000\n",
            "967/967 [==============================] - 1s 533us/sample - loss: 0.0314 - acc: 0.9876 - val_loss: 2.7325 - val_acc: 0.5785\n",
            "Epoch 898/1000\n",
            "967/967 [==============================] - 1s 642us/sample - loss: 0.0343 - acc: 0.9876 - val_loss: 2.7073 - val_acc: 0.5868\n",
            "Epoch 899/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0424 - acc: 0.9907 - val_loss: 2.7201 - val_acc: 0.5744\n",
            "Epoch 900/1000\n",
            "967/967 [==============================] - 0s 498us/sample - loss: 0.0251 - acc: 0.9907 - val_loss: 2.7300 - val_acc: 0.5785\n",
            "Epoch 901/1000\n",
            "967/967 [==============================] - 1s 518us/sample - loss: 0.0519 - acc: 0.9886 - val_loss: 2.7362 - val_acc: 0.5785\n",
            "Epoch 902/1000\n",
            "967/967 [==============================] - 1s 542us/sample - loss: 0.0497 - acc: 0.9845 - val_loss: 2.6844 - val_acc: 0.5661\n",
            "Epoch 903/1000\n",
            "967/967 [==============================] - 1s 594us/sample - loss: 0.0217 - acc: 0.9907 - val_loss: 2.7019 - val_acc: 0.5950\n",
            "Epoch 904/1000\n",
            "967/967 [==============================] - 1s 576us/sample - loss: 0.0338 - acc: 0.9907 - val_loss: 2.7356 - val_acc: 0.5785\n",
            "Epoch 905/1000\n",
            "967/967 [==============================] - 1s 549us/sample - loss: 0.0414 - acc: 0.9876 - val_loss: 2.7604 - val_acc: 0.5661\n",
            "Epoch 906/1000\n",
            "967/967 [==============================] - 1s 630us/sample - loss: 0.0451 - acc: 0.9845 - val_loss: 2.7639 - val_acc: 0.5702\n",
            "Epoch 907/1000\n",
            "967/967 [==============================] - 1s 609us/sample - loss: 0.0398 - acc: 0.9886 - val_loss: 2.7509 - val_acc: 0.5785\n",
            "Epoch 908/1000\n",
            "967/967 [==============================] - 1s 559us/sample - loss: 0.0287 - acc: 0.9907 - val_loss: 2.7711 - val_acc: 0.5826\n",
            "Epoch 909/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0591 - acc: 0.9824 - val_loss: 2.7213 - val_acc: 0.5826\n",
            "Epoch 910/1000\n",
            "967/967 [==============================] - 1s 550us/sample - loss: 0.0242 - acc: 0.9917 - val_loss: 2.7120 - val_acc: 0.5785\n",
            "Epoch 911/1000\n",
            "967/967 [==============================] - 1s 564us/sample - loss: 0.0413 - acc: 0.9845 - val_loss: 2.7213 - val_acc: 0.5702\n",
            "Epoch 912/1000\n",
            "967/967 [==============================] - 1s 562us/sample - loss: 0.0298 - acc: 0.9897 - val_loss: 2.7294 - val_acc: 0.5744\n",
            "Epoch 913/1000\n",
            "967/967 [==============================] - 1s 555us/sample - loss: 0.0350 - acc: 0.9855 - val_loss: 2.7410 - val_acc: 0.5579\n",
            "Epoch 914/1000\n",
            "967/967 [==============================] - 1s 543us/sample - loss: 0.0224 - acc: 0.9959 - val_loss: 2.7529 - val_acc: 0.5537\n",
            "Epoch 915/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0258 - acc: 0.9928 - val_loss: 2.7848 - val_acc: 0.5620\n",
            "Epoch 916/1000\n",
            "967/967 [==============================] - 1s 526us/sample - loss: 0.0349 - acc: 0.9897 - val_loss: 2.7951 - val_acc: 0.5620\n",
            "Epoch 917/1000\n",
            "967/967 [==============================] - 1s 583us/sample - loss: 0.0372 - acc: 0.9845 - val_loss: 2.7858 - val_acc: 0.5702\n",
            "Epoch 918/1000\n",
            "967/967 [==============================] - 1s 628us/sample - loss: 0.0529 - acc: 0.9835 - val_loss: 2.7832 - val_acc: 0.5537\n",
            "Epoch 919/1000\n",
            "967/967 [==============================] - 1s 598us/sample - loss: 0.0423 - acc: 0.9876 - val_loss: 2.8038 - val_acc: 0.5537\n",
            "Epoch 920/1000\n",
            "967/967 [==============================] - 0s 516us/sample - loss: 0.0269 - acc: 0.9897 - val_loss: 2.8054 - val_acc: 0.5537\n",
            "Epoch 921/1000\n",
            "967/967 [==============================] - 1s 589us/sample - loss: 0.0389 - acc: 0.9866 - val_loss: 2.7927 - val_acc: 0.5702\n",
            "Epoch 922/1000\n",
            "967/967 [==============================] - 0s 510us/sample - loss: 0.0413 - acc: 0.9845 - val_loss: 2.7870 - val_acc: 0.5661\n",
            "Epoch 923/1000\n",
            "967/967 [==============================] - 1s 531us/sample - loss: 0.0538 - acc: 0.9835 - val_loss: 2.7921 - val_acc: 0.5620\n",
            "Epoch 924/1000\n",
            "967/967 [==============================] - 1s 575us/sample - loss: 0.0396 - acc: 0.9835 - val_loss: 2.8011 - val_acc: 0.5744\n",
            "Epoch 925/1000\n",
            "967/967 [==============================] - 1s 555us/sample - loss: 0.0514 - acc: 0.9855 - val_loss: 2.8155 - val_acc: 0.5785\n",
            "Epoch 926/1000\n",
            "967/967 [==============================] - 1s 555us/sample - loss: 0.0302 - acc: 0.9866 - val_loss: 2.8121 - val_acc: 0.5744\n",
            "Epoch 927/1000\n",
            "967/967 [==============================] - 1s 580us/sample - loss: 0.0325 - acc: 0.9917 - val_loss: 2.8153 - val_acc: 0.5702\n",
            "Epoch 928/1000\n",
            "967/967 [==============================] - 0s 504us/sample - loss: 0.0471 - acc: 0.9835 - val_loss: 2.8283 - val_acc: 0.5661\n",
            "Epoch 929/1000\n",
            "967/967 [==============================] - 1s 571us/sample - loss: 0.0446 - acc: 0.9845 - val_loss: 2.7828 - val_acc: 0.5826\n",
            "Epoch 930/1000\n",
            "967/967 [==============================] - 1s 566us/sample - loss: 0.0515 - acc: 0.9824 - val_loss: 2.7483 - val_acc: 0.5702\n",
            "Epoch 931/1000\n",
            "967/967 [==============================] - 1s 594us/sample - loss: 0.0327 - acc: 0.9907 - val_loss: 2.7378 - val_acc: 0.5826\n",
            "Epoch 932/1000\n",
            "967/967 [==============================] - 1s 588us/sample - loss: 0.0507 - acc: 0.9835 - val_loss: 2.7408 - val_acc: 0.5785\n",
            "Epoch 933/1000\n",
            "967/967 [==============================] - 1s 567us/sample - loss: 0.0332 - acc: 0.9897 - val_loss: 2.7659 - val_acc: 0.5785\n",
            "Epoch 934/1000\n",
            "967/967 [==============================] - 1s 520us/sample - loss: 0.0312 - acc: 0.9886 - val_loss: 2.7887 - val_acc: 0.5785\n",
            "Epoch 935/1000\n",
            "967/967 [==============================] - 1s 534us/sample - loss: 0.0251 - acc: 0.9938 - val_loss: 2.7927 - val_acc: 0.5826\n",
            "Epoch 936/1000\n",
            "967/967 [==============================] - 1s 525us/sample - loss: 0.0456 - acc: 0.9866 - val_loss: 2.8315 - val_acc: 0.5785\n",
            "Epoch 937/1000\n",
            "967/967 [==============================] - 1s 573us/sample - loss: 0.0570 - acc: 0.9845 - val_loss: 2.8393 - val_acc: 0.5744\n",
            "Epoch 938/1000\n",
            "967/967 [==============================] - 1s 628us/sample - loss: 0.0433 - acc: 0.9876 - val_loss: 2.8167 - val_acc: 0.5868\n",
            "Epoch 939/1000\n",
            "967/967 [==============================] - 1s 575us/sample - loss: 0.0381 - acc: 0.9876 - val_loss: 2.8422 - val_acc: 0.5702\n",
            "Epoch 940/1000\n",
            "967/967 [==============================] - 1s 603us/sample - loss: 0.0321 - acc: 0.9876 - val_loss: 2.8193 - val_acc: 0.5868\n",
            "Epoch 941/1000\n",
            "967/967 [==============================] - 1s 521us/sample - loss: 0.0458 - acc: 0.9886 - val_loss: 2.7821 - val_acc: 0.5826\n",
            "Epoch 942/1000\n",
            "967/967 [==============================] - 1s 520us/sample - loss: 0.0544 - acc: 0.9845 - val_loss: 2.7532 - val_acc: 0.5826\n",
            "Epoch 943/1000\n",
            "967/967 [==============================] - 1s 553us/sample - loss: 0.0673 - acc: 0.9866 - val_loss: 2.7656 - val_acc: 0.5868\n",
            "Epoch 944/1000\n",
            "967/967 [==============================] - 1s 597us/sample - loss: 0.0444 - acc: 0.9845 - val_loss: 2.7540 - val_acc: 0.5826\n",
            "Epoch 945/1000\n",
            "967/967 [==============================] - 1s 583us/sample - loss: 0.0365 - acc: 0.9917 - val_loss: 2.7684 - val_acc: 0.5785\n",
            "Epoch 946/1000\n",
            "967/967 [==============================] - 1s 592us/sample - loss: 0.0502 - acc: 0.9855 - val_loss: 2.7817 - val_acc: 0.6033\n",
            "Epoch 947/1000\n",
            "967/967 [==============================] - 1s 529us/sample - loss: 0.0442 - acc: 0.9824 - val_loss: 2.7913 - val_acc: 0.5950\n",
            "Epoch 948/1000\n",
            "967/967 [==============================] - 1s 536us/sample - loss: 0.0609 - acc: 0.9804 - val_loss: 2.7565 - val_acc: 0.5826\n",
            "Epoch 949/1000\n",
            "967/967 [==============================] - 1s 617us/sample - loss: 0.0474 - acc: 0.9886 - val_loss: 2.7292 - val_acc: 0.5826\n",
            "Epoch 950/1000\n",
            "967/967 [==============================] - 1s 546us/sample - loss: 0.0515 - acc: 0.9814 - val_loss: 2.7322 - val_acc: 0.5826\n",
            "Epoch 951/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0322 - acc: 0.9897 - val_loss: 2.7519 - val_acc: 0.5909\n",
            "Epoch 952/1000\n",
            "967/967 [==============================] - 1s 575us/sample - loss: 0.0542 - acc: 0.9876 - val_loss: 2.7114 - val_acc: 0.5826\n",
            "Epoch 953/1000\n",
            "967/967 [==============================] - 1s 611us/sample - loss: 0.0347 - acc: 0.9897 - val_loss: 2.7186 - val_acc: 0.5826\n",
            "Epoch 954/1000\n",
            "967/967 [==============================] - 1s 603us/sample - loss: 0.0537 - acc: 0.9886 - val_loss: 2.7281 - val_acc: 0.5785\n",
            "Epoch 955/1000\n",
            "967/967 [==============================] - 0s 507us/sample - loss: 0.0344 - acc: 0.9917 - val_loss: 2.7438 - val_acc: 0.5909\n",
            "Epoch 956/1000\n",
            "967/967 [==============================] - 1s 560us/sample - loss: 0.0314 - acc: 0.9866 - val_loss: 2.7665 - val_acc: 0.5744\n",
            "Epoch 957/1000\n",
            "967/967 [==============================] - 1s 575us/sample - loss: 0.0491 - acc: 0.9855 - val_loss: 2.7672 - val_acc: 0.5661\n",
            "Epoch 958/1000\n",
            "967/967 [==============================] - 0s 517us/sample - loss: 0.0317 - acc: 0.9886 - val_loss: 2.7701 - val_acc: 0.5702\n",
            "Epoch 959/1000\n",
            "967/967 [==============================] - 1s 558us/sample - loss: 0.0465 - acc: 0.9866 - val_loss: 2.7238 - val_acc: 0.5826\n",
            "Epoch 960/1000\n",
            "967/967 [==============================] - 1s 652us/sample - loss: 0.0642 - acc: 0.9835 - val_loss: 2.7023 - val_acc: 0.5785\n",
            "Epoch 961/1000\n",
            "967/967 [==============================] - 1s 529us/sample - loss: 0.0284 - acc: 0.9917 - val_loss: 2.7128 - val_acc: 0.5785\n",
            "Epoch 962/1000\n",
            "967/967 [==============================] - 1s 572us/sample - loss: 0.0472 - acc: 0.9897 - val_loss: 2.7347 - val_acc: 0.5785\n",
            "Epoch 963/1000\n",
            "967/967 [==============================] - 1s 578us/sample - loss: 0.0258 - acc: 0.9876 - val_loss: 2.7557 - val_acc: 0.5826\n",
            "Epoch 964/1000\n",
            "967/967 [==============================] - 1s 614us/sample - loss: 0.0383 - acc: 0.9886 - val_loss: 2.7663 - val_acc: 0.5826\n",
            "Epoch 965/1000\n",
            "967/967 [==============================] - 1s 592us/sample - loss: 0.0532 - acc: 0.9824 - val_loss: 2.7357 - val_acc: 0.5826\n",
            "Epoch 966/1000\n",
            "967/967 [==============================] - 1s 555us/sample - loss: 0.0326 - acc: 0.9886 - val_loss: 2.7357 - val_acc: 0.5992\n",
            "Epoch 967/1000\n",
            "967/967 [==============================] - 1s 587us/sample - loss: 0.0385 - acc: 0.9886 - val_loss: 2.7343 - val_acc: 0.5909\n",
            "Epoch 968/1000\n",
            "967/967 [==============================] - 0s 479us/sample - loss: 0.0306 - acc: 0.9886 - val_loss: 2.7064 - val_acc: 0.5744\n",
            "Epoch 969/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0511 - acc: 0.9835 - val_loss: 2.7016 - val_acc: 0.5826\n",
            "Epoch 970/1000\n",
            "967/967 [==============================] - 1s 605us/sample - loss: 0.0310 - acc: 0.9866 - val_loss: 2.6739 - val_acc: 0.5744\n",
            "Epoch 971/1000\n",
            "967/967 [==============================] - 0s 505us/sample - loss: 0.0273 - acc: 0.9886 - val_loss: 2.7047 - val_acc: 0.5785\n",
            "Epoch 972/1000\n",
            "967/967 [==============================] - 1s 524us/sample - loss: 0.0391 - acc: 0.9876 - val_loss: 2.7142 - val_acc: 0.5909\n",
            "Epoch 973/1000\n",
            "967/967 [==============================] - 0s 487us/sample - loss: 0.0490 - acc: 0.9835 - val_loss: 2.7480 - val_acc: 0.5785\n",
            "Epoch 974/1000\n",
            "967/967 [==============================] - 1s 623us/sample - loss: 0.0342 - acc: 0.9876 - val_loss: 2.7653 - val_acc: 0.5868\n",
            "Epoch 975/1000\n",
            "967/967 [==============================] - 1s 605us/sample - loss: 0.0289 - acc: 0.9907 - val_loss: 2.7433 - val_acc: 0.5744\n",
            "Epoch 976/1000\n",
            "967/967 [==============================] - 1s 636us/sample - loss: 0.0392 - acc: 0.9866 - val_loss: 2.7647 - val_acc: 0.5826\n",
            "Epoch 977/1000\n",
            "967/967 [==============================] - 1s 542us/sample - loss: 0.0360 - acc: 0.9876 - val_loss: 2.7360 - val_acc: 0.5661\n",
            "Epoch 978/1000\n",
            "967/967 [==============================] - 1s 608us/sample - loss: 0.0258 - acc: 0.9938 - val_loss: 2.7531 - val_acc: 0.5744\n",
            "Epoch 979/1000\n",
            "967/967 [==============================] - 0s 488us/sample - loss: 0.0454 - acc: 0.9835 - val_loss: 2.7428 - val_acc: 0.5661\n",
            "Epoch 980/1000\n",
            "967/967 [==============================] - 1s 569us/sample - loss: 0.0334 - acc: 0.9855 - val_loss: 2.7276 - val_acc: 0.5702\n",
            "Epoch 981/1000\n",
            "967/967 [==============================] - 1s 546us/sample - loss: 0.0283 - acc: 0.9886 - val_loss: 2.7393 - val_acc: 0.5826\n",
            "Epoch 982/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0598 - acc: 0.9752 - val_loss: 2.7412 - val_acc: 0.5744\n",
            "Epoch 983/1000\n",
            "967/967 [==============================] - 1s 545us/sample - loss: 0.0536 - acc: 0.9855 - val_loss: 2.7441 - val_acc: 0.5785\n",
            "Epoch 984/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0487 - acc: 0.9907 - val_loss: 2.7195 - val_acc: 0.5744\n",
            "Epoch 985/1000\n",
            "967/967 [==============================] - 1s 533us/sample - loss: 0.0322 - acc: 0.9907 - val_loss: 2.7072 - val_acc: 0.5744\n",
            "Epoch 986/1000\n",
            "967/967 [==============================] - 1s 642us/sample - loss: 0.0635 - acc: 0.9855 - val_loss: 2.6857 - val_acc: 0.5661\n",
            "Epoch 987/1000\n",
            "967/967 [==============================] - 1s 631us/sample - loss: 0.0301 - acc: 0.9938 - val_loss: 2.6950 - val_acc: 0.5785\n",
            "Epoch 988/1000\n",
            "967/967 [==============================] - 1s 604us/sample - loss: 0.0304 - acc: 0.9824 - val_loss: 2.7186 - val_acc: 0.5785\n",
            "Epoch 989/1000\n",
            "967/967 [==============================] - 1s 612us/sample - loss: 0.0411 - acc: 0.9886 - val_loss: 2.7379 - val_acc: 0.5826\n",
            "Epoch 990/1000\n",
            "967/967 [==============================] - 1s 556us/sample - loss: 0.0192 - acc: 0.9938 - val_loss: 2.7593 - val_acc: 0.5620\n",
            "Epoch 991/1000\n",
            "967/967 [==============================] - 1s 613us/sample - loss: 0.0295 - acc: 0.9907 - val_loss: 2.7849 - val_acc: 0.5620\n",
            "Epoch 992/1000\n",
            "967/967 [==============================] - 0s 516us/sample - loss: 0.0562 - acc: 0.9866 - val_loss: 2.8031 - val_acc: 0.5744\n",
            "Epoch 993/1000\n",
            "967/967 [==============================] - 0s 511us/sample - loss: 0.0289 - acc: 0.9897 - val_loss: 2.8188 - val_acc: 0.5785\n",
            "Epoch 994/1000\n",
            "967/967 [==============================] - 1s 597us/sample - loss: 0.0387 - acc: 0.9866 - val_loss: 2.8336 - val_acc: 0.5785\n",
            "Epoch 995/1000\n",
            "967/967 [==============================] - 1s 570us/sample - loss: 0.0432 - acc: 0.9897 - val_loss: 2.8362 - val_acc: 0.5826\n",
            "Epoch 996/1000\n",
            "967/967 [==============================] - 1s 547us/sample - loss: 0.0386 - acc: 0.9886 - val_loss: 2.8352 - val_acc: 0.5744\n",
            "Epoch 997/1000\n",
            "967/967 [==============================] - 1s 554us/sample - loss: 0.0363 - acc: 0.9876 - val_loss: 2.7871 - val_acc: 0.5826\n",
            "Epoch 998/1000\n",
            "967/967 [==============================] - 1s 570us/sample - loss: 0.0531 - acc: 0.9814 - val_loss: 2.7872 - val_acc: 0.5868\n",
            "Epoch 999/1000\n",
            "967/967 [==============================] - 1s 557us/sample - loss: 0.0494 - acc: 0.9845 - val_loss: 2.7908 - val_acc: 0.5868\n",
            "Epoch 1000/1000\n",
            "967/967 [==============================] - 1s 609us/sample - loss: 0.0334 - acc: 0.9876 - val_loss: 2.7726 - val_acc: 0.5909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7fb63192e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj8kPC55C_G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}